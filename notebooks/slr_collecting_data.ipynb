{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up for data collection\n",
    "\n",
    "Reference for how to do the sign language on [youtube](https://www.youtube.com/watch?v=0FcwzMq4iWg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for saving the dataset\n",
    "DATASET_PATH = os.path.join(\"../storage/datasets/raw\")\n",
    "\n",
    "# actions to be detected\n",
    "ACTIONS = [\n",
    "    \"_\", \"hello\", \"thanks\", \"i-love-you\", \"I\", \"Yes\", \"No\", \"Help\", \"Please\",\n",
    "    \"Want\", \"Eat\", \"More\", \"Bathroom\", \"Learn\", \"Sign\",\n",
    "]\n",
    "\n",
    "# limit to first x actions for testing\n",
    "ACTIONS = ACTIONS[4:8]\n",
    "\n",
    "# number of videos and actions per video\n",
    "videos_per_label = 60\n",
    "frames_per_video = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CREATED] I\n",
      "[CREATED] Yes\n",
      "[CREATED] No\n",
      "[CREATED] Help\n"
     ]
    }
   ],
   "source": [
    "# create dataset directories if they do not exist\n",
    "try:\n",
    "    try:\n",
    "        shutil.rmtree(DATASET_PATH)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    os.makedirs(DATASET_PATH)\n",
    "except FileExistsError:\n",
    "    print(\"Dataset folder exists, skipping creation.\")\n",
    "\n",
    "# create directories for each action\n",
    "for action in ACTIONS:\n",
    "    try:\n",
    "        os.makedirs(os.path.join(DATASET_PATH, action))\n",
    "        print(f\"[CREATED] {action}\")\n",
    "    except FileExistsError:\n",
    "        print(f\"[SKIPPED] {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the landmarker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_path(action, sequence):\n",
    "    return os.path.join(DATASET_PATH, action, f\"{sequence}.avi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recording the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_starting_text(\n",
    "    img,\n",
    "):\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        \"STARTING COLLECTION\",\n",
    "        (120, 200),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1,\n",
    "        (0, 255, 0),\n",
    "        4,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "\n",
    "\n",
    "def display_collecting_text(img, act, seq, pos=(15, 12)):\n",
    "    cv2.putText(\n",
    "        img,\n",
    "        f\"Collecting frames for {act} Video Number {seq}\",\n",
    "        pos,\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.5,\n",
    "        (0, 0, 255),\n",
    "        1,\n",
    "        cv2.LINE_AA,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "\n",
    "start_time = time.time()\n",
    "frames = 0\n",
    "is_quit = False\n",
    "\n",
    "# define the codec for VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: It's take total of 14 minutes or more to capture 60 video for all 4 action/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while the video capture is opened (i.e., the camera is functioning)\n",
    "while cap.isOpened():\n",
    "    # loop through each action in the predefined ACTIONS list\n",
    "    for action in ACTIONS:\n",
    "        # loop through the number of video sequences per label\n",
    "        for sequence in range(videos_per_label):\n",
    "            # initialize VideoWriter for each video sequence\n",
    "            out = cv2.VideoWriter(\n",
    "                video_path(action, sequence),  # path for saving the video\n",
    "                fourcc,                        # codec used for compression\n",
    "                60.0,                          # frames per second\n",
    "                (640, 480)                     # frame/image size (width, height)\n",
    "            )\n",
    "\n",
    "            # loop through each frame in the sequence\n",
    "            for action_length in range(frames_per_video + 1):\n",
    "                success, frame = cap.read()\n",
    "                # create a black image for pauses or displaying text\n",
    "                pause_image = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "\n",
    "                # if frame capture fails, ignore and continue\n",
    "                if not success:\n",
    "                    print(\"Ignoring empty camera frame\")\n",
    "                    continue\n",
    "\n",
    "                image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # for the first frame (per each sequence), display starting and collecting text\n",
    "                # this gives time for the user to adjust to the next sign language action\n",
    "                if action_length == 0:\n",
    "                    display_starting_text(pause_image)\n",
    "                    display_collecting_text(pause_image, action, sequence)\n",
    "                    cv2.imshow(\"Detecting Sign Language\", pause_image)\n",
    "                    cv2.waitKey(1500)  # wait for 1.5 seconds to give time for adjustment\n",
    "\n",
    "                # if frame reaches 60 (59 since the frame started from 0), break out of the loop\n",
    "                # NOTE: this might needed since using the last code\n",
    "                #       it only gives us only 58 frame also adding + 1\n",
    "                #       in frames_per_video loop is crucial\n",
    "                elif action_length == 60:\n",
    "                    out.write(frame)\n",
    "                    break\n",
    "\n",
    "                # for other frames, display collecting text and show the frame\n",
    "                else:\n",
    "                    display_collecting_text(image_rgb, action, sequence)\n",
    "                    cv2.imshow(\"Detecting Sign Language\", cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB))\n",
    "                    # write the frame to the video file\n",
    "                    out.write(frame)\n",
    "\n",
    "                # break the loop if 'q' key is pressed\n",
    "                if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "                    is_quit = True\n",
    "                    break\n",
    "\n",
    "            # break out of the action sequence loop\n",
    "            if is_quit:\n",
    "                break\n",
    "\n",
    "        # break out of the action loop\n",
    "        if is_quit:\n",
    "            break\n",
    "\n",
    "    # release the opencv related video object\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
