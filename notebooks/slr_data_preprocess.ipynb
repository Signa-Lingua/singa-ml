{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "\n",
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import tensorflow as tf # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for saving the data (numpy array)\n",
    "DATA_PATH = os.path.join(\"../datasets\")\n",
    "\n",
    "# sign action to be detected\n",
    "ACTIONS = np.array(\n",
    "    [\n",
    "        \"hello\",\n",
    "        \"thanks\",\n",
    "        \"i-love-you\",\n",
    "        \"see-you-later\",\n",
    "        \"I\",\n",
    "        \"Father\",\n",
    "        \"Mother\",\n",
    "        \"Yes\",\n",
    "        \"No\",\n",
    "        \"Help\",\n",
    "        \"Please\",\n",
    "        \"Want\",\n",
    "        \"What\",\n",
    "        \"Again\",\n",
    "        \"Eat\",\n",
    "        \"Milk\",\n",
    "        \"More\",\n",
    "        \"Go To\",\n",
    "        \"Bathroom\",\n",
    "        \"Fine\",\n",
    "        \"Like\",\n",
    "        \"Learn\",\n",
    "        \"Sign\",\n",
    "        \"Done\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "ACTIONS = ACTIONS[:6] # per the current dataset we have rign now\n",
    "\n",
    "# 60 videos worth of data (per label)\n",
    "videos_per_label = 60\n",
    "\n",
    "# 30 action per videos\n",
    "# NOTE: This does not affect how much the frame is\n",
    "action_per_video = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "\n",
    "labels_map = {label: index for index, label in enumerate(ACTIONS)}\n",
    "\n",
    "total_keypoints = ((478 * 3) + (33 * 4) + (21 * 3 * 2))\n",
    "total_keypoints_per_label = total_keypoints * action_per_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further information regarding keypoints for [task vision (face, pose, and hand)](https://ai.google.dev/edge/mediapipe/solutions/guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1692, 50760)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_keypoints, total_keypoints_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in ACTIONS:\n",
    "\n",
    "    \"\"\"Iterates over each sequence for the current action\"\"\"\n",
    "    for sequence in range(videos_per_label):\n",
    "        # empty list (window) to hold the frames of the current sequence.\n",
    "        sequence_actions = []\n",
    "\n",
    "        \"\"\"\n",
    "        Frame Processing\n",
    "\n",
    "        Iterates over each frame in the current sequence, then constructs the file path to the numpy array for the current frame.\n",
    "        Prints the path to verify correctness, then loads the frame data from the numpy file.\n",
    "        \"\"\"\n",
    "        for frame_num in range(action_per_video):\n",
    "            # construct the path to the numpy file for the current frame\n",
    "            npy_path = os.path.join(\n",
    "                DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)\n",
    "            )\n",
    "\n",
    "            # load the frame data from the numpy file\n",
    "            result = np.load(npy_path)\n",
    "\n",
    "            if not (len(result) == total_keypoints):\n",
    "                # Check if the total keypoints of the file match the target total keypoints.\n",
    "                print(\n",
    "                    f\"Action '{action}' for video {str(sequence)} does not have matched total_keypoints : {len(result)}\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "            # append the frame data to the current sequence (window)\n",
    "            sequence_actions.append(result)\n",
    "\n",
    "        # append the completed sequence to the sequences list\n",
    "        sequences.append(sequence_actions)\n",
    "\n",
    "        labels.append(labels_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1692"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result) # the last frame of the last frame of the last action video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the total of the labels are same as the length of total actions videos\n",
    "len(labels) == len(ACTIONS) * videos_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See how much data we can use for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "\n",
    "# convert labels list to a one-hot encoded NumPy array\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 30, 1692), (72, 30, 1692), (288, 6), (72, 6))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
