{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIONS = np.array(\n",
    "    [\n",
    "        \"hello\",\n",
    "        \"thanks\",\n",
    "        \"i-love-you\",\n",
    "        \"see-you-later\",\n",
    "        \"I\",\n",
    "        \"Father\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# prepare the window of frames\n",
    "window = []\n",
    "for i in range(30):\n",
    "    npy_path = os.path.join(\"../../datasets\", \"I\", \"5\", f\"{i}.npy\")\n",
    "\n",
    "    # load the frame data from the numpy file\n",
    "    seq = np.load(npy_path)\n",
    "\n",
    "    window.append(seq)\n",
    "\n",
    "# convert the window to a numpy array\n",
    "action = np.array(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_batch_normalization_input:0', 'index': 0, 'shape': array([   1,   30, 1692]), 'shape_signature': array([  -1,   30, 1692]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details: [{'name': 'StatefulPartitionedCall:0', 'index': 97, 'shape': array([1, 6]), 'shape_signature': array([-1,  6]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# load the TFLite model and allocate tensors\n",
    "interpreter = tf.lite.Interpreter(\n",
    "    model_path=\"../../drive/models/tflite/asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e5-1.2M.tflite\"\n",
    ")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# print input and output tensor details\n",
    "print(\"Input details:\", input_details)\n",
    "print(\"Output details:\", output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected input shape: [   1   30 1692]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "input_shape = input_details[0]['shape']\n",
    "print(\"Expected input shape:\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand dimensions to match the batch size of 1\n",
    "action = action.astype(np.float32)\n",
    "\n",
    "action = np.expand_dims(action, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.54302716,  0.47076157, -0.02970532, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.5437715 ,  0.4679922 , -0.02995613, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.546769  ,  0.46607926, -0.03016827, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.54244214,  0.4655904 , -0.03017098, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.54249424,  0.46554026, -0.03017088, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.542535  ,  0.46530834, -0.03017675, ...,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the 3D array to 2D\n",
    "array_2d = action.reshape(-1, action.shape[-1])\n",
    "\n",
    "# Save the 2D array to a plain text file\n",
    "np.savetxt(\"array_3d_as_2d.txt\", array_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], action)\n",
    "\n",
    "# run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# get the output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n"
     ]
    }
   ],
   "source": [
    "# determine the predicted action\n",
    "pred = output_data[0]\n",
    "\n",
    "print(ACTIONS[np.argmax(pred)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
