{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models  # type: ignore\n",
    "from tensorflow.keras.callbacks import (Callback,  # type: ignore\n",
    "                                        EarlyStopping, ReduceLROnPlateau,\n",
    "                                        TensorBoard)\n",
    "from tensorflow.keras.optimizers import Adam  # type: ignore\n",
    "from tensorflow.keras.regularizers import l2  # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up for data training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocssed dataset path\n",
    "DATASET_PATH = os.path.join(\"../storage/datasets/cleaned\")\n",
    "\n",
    "# actions to be detected\n",
    "ACTIONS = [\n",
    "    \"_\", \"hello\", \"thanks\", \"i-love-you\", \"see-you-later\", \"I\", \"Father\", \"Mother\", \"Yes\",\n",
    "    \"No\", \"Help\", \"Please\", \"Want\", \"What\", \"Again\", \"Eat\", \"Milk\", \"More\", \"Go To\",\n",
    "    \"Bathroom\", \"Fine\", \"Like\", \"Learn\", \"Sign\", \"Done\"\n",
    "]\n",
    "\n",
    "# limit to first x actions for testing\n",
    "ACTIONS = np.array(ACTIONS[:4])\n",
    "\n",
    "# number of videos and actions per video\n",
    "videos_per_label = 120\n",
    "frames_per_video = 60\n",
    "\n",
    "# data labels\n",
    "labels_map = {label: index for index, label in enumerate(ACTIONS)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(landmarks, noise_level, shape=(60, 225)):\n",
    "    noise = np.random.normal(loc=0, scale=noise_level, size=shape)\n",
    "    return landmarks + noise\n",
    "\n",
    "\n",
    "def shift_landmarks(landmarks, shift_factor, shape=(60, 225)):\n",
    "    shift = np.random.uniform(-shift_factor, shift_factor, size=shape[1:])\n",
    "    return landmarks + shift\n",
    "\n",
    "\n",
    "def augment_landmarks(landmarks, noise_level=0.01, shift_factor=0.1):\n",
    "    if random.random() > 0.5:\n",
    "        landmarks = add_noise(landmarks, noise_level)\n",
    "\n",
    "    if random.random() > 0.5:\n",
    "        landmarks = shift_landmarks(landmarks, shift_factor)\n",
    "\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_path = os.path.join(\"./data\", \"sequences.npy\")\n",
    "lab_path = os.path.join(\"./data\", \"labels.npy\")\n",
    "\n",
    "sequences, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA IS BEING LOADED\n"
     ]
    }
   ],
   "source": [
    "def generate_bulk_dataset_and_load(augment=True):\n",
    "    sequences, labels = [], []\n",
    "\n",
    "    for action in ACTIONS:\n",
    "        window = []\n",
    "        window_labels = []\n",
    "\n",
    "        \"\"\"Iterates over each sequence for the current action\"\"\"\n",
    "        for sequence in range(videos_per_label):\n",
    "            \"\"\"\n",
    "            Frame Processing\n",
    "\n",
    "            Iterates over each frame in the current sequence, then constructs the file path to the numpy array for the current frame.\n",
    "            Prints the path to verify correctness, then loads the frame data from the numpy file.\n",
    "            \"\"\"\n",
    "            # construct the path to the numpy file for the current frame\n",
    "            npy_path = os.path.join(DATASET_PATH, action, \"{}.npy\".format(sequence))\n",
    "\n",
    "            # load the frame data from the numpy file\n",
    "            result = np.load(npy_path)\n",
    "\n",
    "            # append the completed sequence to the sequences list\n",
    "            window.append(result)\n",
    "\n",
    "            # append the corresponding label to the labels list\n",
    "            window_labels.append(labels_map[action])\n",
    "\n",
    "            if not augment:\n",
    "                continue\n",
    "\n",
    "            # number of augmented window to create per original sequence\n",
    "            num_augmented_sequences = int(0.1 * 60)  # 10% of total of video\n",
    "\n",
    "            for _ in range(num_augmented_sequences):\n",
    "                augmented_sequence = [\n",
    "                    augment_landmarks(frame, noise_level=0.047, shift_factor=0.47)\n",
    "                    for frame in window\n",
    "                ]\n",
    "\n",
    "                # append the augmented to the window list\n",
    "                window.append(augmented_sequence[0])\n",
    "\n",
    "                window_labels.append(labels_map[action])\n",
    "\n",
    "            print(f\"{action} - {sequence}\")\n",
    "\n",
    "        sequences.append(window)\n",
    "        labels.append(window_labels)\n",
    "\n",
    "    keypoints = np.concatenate([s for s in sequences])\n",
    "    key_label = np.concatenate([l for l in labels])\n",
    "\n",
    "    # save the original sequences and labels\n",
    "    np.save(seq_path, keypoints)\n",
    "    np.save(lab_path, key_label)\n",
    "\n",
    "    return keypoints, key_label\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    if os.path.exists(seq_path) and os.path.exists(lab_path):\n",
    "        print(\"DATA IS BEING LOADED\")\n",
    "\n",
    "        sequences = np.load(seq_path, allow_pickle=True)\n",
    "        labels = np.load(lab_path, allow_pickle=True)\n",
    "\n",
    "        return sequences, labels\n",
    "\n",
    "    print(\"DATA IS BEING GENERATED AND LOADED\")\n",
    "\n",
    "    return generate_bulk_dataset_and_load(augment=True)\n",
    "\n",
    "\n",
    "sequences, labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 3360)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjusting the Augmentation Factor**\n",
    "\n",
    "If you want to achieve a specific total number of sequences, you can adjust N<sub>augmented_per_original</sub>\n",
    "\n",
    "- Desired N<sub>total</sub> = 1920\n",
    "- Original N<sub>original</sub> = 480 (without augmentation)\n",
    "\n",
    "Using the formula to find N<sub>augmented_per_original</sub> :\n",
    "- 1920 = 480 + (480 × N<sub>augmented_per_original</sub>)\n",
    "\n",
    "Subtract 480 from both sides :\n",
    "- 1440 = 480 × N<sub>augmented_per_original</sub>\n",
    "\n",
    "Divide both sides by 480 :\n",
    "- N<sub>augmented_per_original</sub> = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "datas = np.array(sequences)\n",
    "\n",
    "# convert labels list to a one-hot encoded NumPy array\n",
    "labels = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 3360)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the length of the datas and labels should be the same\n",
    "len(datas), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of the datasets depend on the total number of sequences and the sequence length. Here we processes 120 sequence of videos for each of the 4 actions, we have:\n",
    "\n",
    "    Total sequences = 120 sequences/action × 4 actions = 480 sequences\n",
    "\n",
    "Given a test_size of 0.2, 20% of the data (approximately 96 sequences) will be in the test set, and 80% (approximately 384 sequences) will be in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2688, 60, 225) (672, 60, 225) (2688, 4) (672, 4)\n"
     ]
    }
   ],
   "source": [
    "# splits the dataset into training and testing sets\n",
    "\n",
    "# specifies that 20% of the data should be used as the test set,\n",
    "# and the remaining 80% should be used as the training set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(datas, labels, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong Output Example : `(384, 60, 225) (96, 60, 225) (384, 4, 2) (96, 4, 2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # augment the training data\n",
    "# X_train_augmented, y_train_augmented = augment_train_test_data(X_train, y_train)\n",
    "\n",
    "# # convert the test data to the required format\n",
    "# X_test = np.array(X_test)\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "# print(X_train_augmented.shape, X_test.shape, y_train_augmented.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">900</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m225\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m225\u001b[0m)        │           \u001b[38;5;34m900\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m43,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,688</span> (561.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m143,688\u001b[0m (561.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,238</span> (559.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m143,238\u001b[0m (559.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> (1.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m450\u001b[0m (1.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_cnn_rnn_model(input_shape, num_classes):\n",
    "    # the input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # BatchNormalization layer to normalize input data\n",
    "    batch = tf.keras.layers.BatchNormalization()(inputs)\n",
    "\n",
    "    # CNN tf.keras.layers to extract spatial features\n",
    "    cnn = tf.keras.layers.Conv1D(64, 3, activation=\"relu\", kernel_regularizer=l2(0.02))(\n",
    "        batch\n",
    "    )\n",
    "    x = tf.keras.layers.MaxPooling1D(2)(cnn)\n",
    "\n",
    "    # CNN tf.keras.layers to extract spatial features\n",
    "    cnn = tf.keras.layers.Conv1D(\n",
    "        128, 3, activation=\"relu\", kernel_regularizer=l2(0.02)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(cnn)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=l2(0.02))(cnn)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    rnn = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation=\"relu\"))(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=l2(0.02))(rnn)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=l2(0.02))(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(rnn)\n",
    "\n",
    "    # create the model\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# where 60 is the sequence length\n",
    "# and 225 is the number of features (keypoints) per frame\n",
    "input_shape = (60, 225)\n",
    "num_classes = ACTIONS.shape[0]  # N gesture classes\n",
    "\n",
    "# Create the model\n",
    "model = create_cnn_rnn_model(input_shape, num_classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up callbacks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new log directory: ../storage/logs\\train-20240609-204447\n"
     ]
    }
   ],
   "source": [
    "def create_log_dir(base_dir, use_time=False):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # check existing log directories\n",
    "    existing_logs = [\n",
    "        d\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"train-\")\n",
    "    ]\n",
    "\n",
    "    # determine the new log directory name\n",
    "    if existing_logs and not use_time:\n",
    "        latest_log = max(existing_logs)\n",
    "        log_num = int(latest_log.split(\"-\")[1]) + 1\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{str(log_num).zfill(3)}\")\n",
    "\n",
    "    if not existing_logs and not use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-001\")\n",
    "\n",
    "    if use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{current_time}\")\n",
    "\n",
    "    # create the new log directory\n",
    "    os.makedirs(new_log_dir)\n",
    "    print(f\"Created new log directory: {new_log_dir}\")\n",
    "\n",
    "    return new_log_dir\n",
    "\n",
    "\n",
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor=\"val_loss\", value=0.001, verbose=0, patience=20):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            raise ValueError(f\"Early stopping requires {self.monitor} available!\")\n",
    "\n",
    "        if current <= self.value:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                if self.verbose > 0:\n",
    "                    print(\n",
    "                        f\"Epoch {epoch}: early stopping threshold reached with {self.monitor} = {current}\"\n",
    "                    )\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0  # reset wait if the condition is not met\n",
    "\n",
    "\n",
    "# callback for logging\n",
    "log_dir = os.path.join(create_log_dir(os.path.join(\"../storage/logs\"), True))\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the optimizer with an initial learning rate\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "# compile the model with the optimizer\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=50, restore_best_weights=True\n",
    ")\n",
    "\n",
    "es_acc = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=50,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.3903 - loss: 6.6353 - val_accuracy: 0.5848 - val_loss: 6.1559 - learning_rate: 1.0000e-04\n",
      "Epoch 2/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6769 - loss: 5.8099 - val_accuracy: 0.6667 - val_loss: 5.4340 - learning_rate: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8134 - loss: 4.9917 - val_accuracy: 0.8363 - val_loss: 4.7756 - learning_rate: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8852 - loss: 4.4296 - val_accuracy: 0.8586 - val_loss: 4.3335 - learning_rate: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9147 - loss: 4.1097 - val_accuracy: 0.9003 - val_loss: 4.0974 - learning_rate: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9475 - loss: 3.8653 - val_accuracy: 0.9018 - val_loss: 3.9136 - learning_rate: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9575 - loss: 3.6720 - val_accuracy: 0.8929 - val_loss: 3.7525 - learning_rate: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 3.4848 - val_accuracy: 0.9107 - val_loss: 3.6450 - learning_rate: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9730 - loss: 3.3180 - val_accuracy: 0.9092 - val_loss: 3.5269 - learning_rate: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9720 - loss: 3.1903 - val_accuracy: 0.9152 - val_loss: 3.3986 - learning_rate: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9884 - loss: 3.0378 - val_accuracy: 0.9211 - val_loss: 3.2928 - learning_rate: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9863 - loss: 2.9200 - val_accuracy: 0.9241 - val_loss: 3.1564 - learning_rate: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9850 - loss: 2.8117 - val_accuracy: 0.9137 - val_loss: 3.0834 - learning_rate: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 2.7056 - val_accuracy: 0.9271 - val_loss: 2.9493 - learning_rate: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 2.5767 - val_accuracy: 0.9271 - val_loss: 2.8974 - learning_rate: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9884 - loss: 2.4815 - val_accuracy: 0.9301 - val_loss: 2.7984 - learning_rate: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9949 - loss: 2.3686 - val_accuracy: 0.9301 - val_loss: 2.7998 - learning_rate: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9936 - loss: 2.2819 - val_accuracy: 0.9182 - val_loss: 2.7050 - learning_rate: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9901 - loss: 2.2006 - val_accuracy: 0.9271 - val_loss: 2.5760 - learning_rate: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9863 - loss: 2.1237 - val_accuracy: 0.9315 - val_loss: 2.4689 - learning_rate: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9880 - loss: 2.0429 - val_accuracy: 0.9256 - val_loss: 2.3593 - learning_rate: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9932 - loss: 1.9567 - val_accuracy: 0.9211 - val_loss: 2.2882 - learning_rate: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9958 - loss: 1.8687 - val_accuracy: 0.9241 - val_loss: 2.2943 - learning_rate: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9956 - loss: 1.7985 - val_accuracy: 0.9286 - val_loss: 2.1865 - learning_rate: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 1.7245 - val_accuracy: 0.9286 - val_loss: 2.1035 - learning_rate: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9943 - loss: 1.6587 - val_accuracy: 0.9226 - val_loss: 2.0869 - learning_rate: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9865 - loss: 1.6184 - val_accuracy: 0.9211 - val_loss: 1.9661 - learning_rate: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9942 - loss: 1.5342 - val_accuracy: 0.9196 - val_loss: 2.0024 - learning_rate: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 1.4687 - val_accuracy: 0.9241 - val_loss: 1.9792 - learning_rate: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9912 - loss: 1.4232 - val_accuracy: 0.9241 - val_loss: 1.8445 - learning_rate: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9934 - loss: 1.3598 - val_accuracy: 0.9167 - val_loss: 1.8906 - learning_rate: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 1.2976 - val_accuracy: 0.9241 - val_loss: 1.7881 - learning_rate: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 1.2443 - val_accuracy: 0.9286 - val_loss: 1.7336 - learning_rate: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 1.1878 - val_accuracy: 0.9226 - val_loss: 1.7721 - learning_rate: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9903 - loss: 1.1584 - val_accuracy: 0.9196 - val_loss: 1.6212 - learning_rate: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9983 - loss: 1.0975 - val_accuracy: 0.9345 - val_loss: 1.5315 - learning_rate: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 1.0559 - val_accuracy: 0.9152 - val_loss: 1.6019 - learning_rate: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9986 - loss: 1.0070 - val_accuracy: 0.9241 - val_loss: 1.4818 - learning_rate: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9947 - loss: 0.9745 - val_accuracy: 0.9196 - val_loss: 1.5005 - learning_rate: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9915 - loss: 0.9446 - val_accuracy: 0.9196 - val_loss: 1.3624 - learning_rate: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.9120 - val_accuracy: 0.9167 - val_loss: 1.3590 - learning_rate: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9961 - loss: 0.8626 - val_accuracy: 0.9137 - val_loss: 1.3849 - learning_rate: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9956 - loss: 0.8295 - val_accuracy: 0.9182 - val_loss: 1.3106 - learning_rate: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9972 - loss: 0.7925 - val_accuracy: 0.9167 - val_loss: 1.2753 - learning_rate: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9947 - loss: 0.7682 - val_accuracy: 0.9137 - val_loss: 1.2237 - learning_rate: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9965 - loss: 0.7366 - val_accuracy: 0.9167 - val_loss: 1.2185 - learning_rate: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9937 - loss: 0.7248 - val_accuracy: 0.9330 - val_loss: 1.0975 - learning_rate: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9935 - loss: 0.6867 - val_accuracy: 0.9315 - val_loss: 1.0695 - learning_rate: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9996 - loss: 0.6494 - val_accuracy: 0.9271 - val_loss: 1.0975 - learning_rate: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9948 - loss: 0.6277 - val_accuracy: 0.9271 - val_loss: 1.1281 - learning_rate: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9950 - loss: 0.6098 - val_accuracy: 0.9211 - val_loss: 1.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.5784 - val_accuracy: 0.9256 - val_loss: 1.0677 - learning_rate: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9972 - loss: 0.5590 - val_accuracy: 0.9211 - val_loss: 1.0423 - learning_rate: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9962 - loss: 0.5403 - val_accuracy: 0.9301 - val_loss: 1.0338 - learning_rate: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9952 - loss: 0.5196 - val_accuracy: 0.9330 - val_loss: 0.9627 - learning_rate: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9983 - loss: 0.4960 - val_accuracy: 0.9315 - val_loss: 0.9783 - learning_rate: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 0.4795 - val_accuracy: 0.9122 - val_loss: 1.0034 - learning_rate: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9931 - loss: 0.4800 - val_accuracy: 0.9271 - val_loss: 0.8680 - learning_rate: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9961 - loss: 0.4570 - val_accuracy: 0.9241 - val_loss: 0.9198 - learning_rate: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.4296 - val_accuracy: 0.9345 - val_loss: 0.8663 - learning_rate: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.4116 - val_accuracy: 0.9286 - val_loss: 0.8480 - learning_rate: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9957 - loss: 0.4036 - val_accuracy: 0.9330 - val_loss: 0.8572 - learning_rate: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9995 - loss: 0.3776 - val_accuracy: 0.9360 - val_loss: 0.8118 - learning_rate: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9970 - loss: 0.3688 - val_accuracy: 0.9271 - val_loss: 0.7969 - learning_rate: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9973 - loss: 0.3593 - val_accuracy: 0.9345 - val_loss: 0.7352 - learning_rate: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9968 - loss: 0.3483 - val_accuracy: 0.9256 - val_loss: 0.7298 - learning_rate: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9974 - loss: 0.3338 - val_accuracy: 0.9345 - val_loss: 0.7488 - learning_rate: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9968 - loss: 0.3227 - val_accuracy: 0.9271 - val_loss: 0.6857 - learning_rate: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9927 - loss: 0.3164 - val_accuracy: 0.9301 - val_loss: 0.7198 - learning_rate: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9936 - loss: 0.3047 - val_accuracy: 0.9226 - val_loss: 0.7570 - learning_rate: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9962 - loss: 0.2908 - val_accuracy: 0.9301 - val_loss: 0.7772 - learning_rate: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9920 - loss: 0.2949 - val_accuracy: 0.9226 - val_loss: 0.6836 - learning_rate: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9953 - loss: 0.2835 - val_accuracy: 0.9167 - val_loss: 0.7742 - learning_rate: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9939 - loss: 0.2741 - val_accuracy: 0.9256 - val_loss: 0.6674 - learning_rate: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9983 - loss: 0.2582 - val_accuracy: 0.9241 - val_loss: 0.6849 - learning_rate: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9957 - loss: 0.2607 - val_accuracy: 0.9211 - val_loss: 0.7041 - learning_rate: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9982 - loss: 0.2407 - val_accuracy: 0.9301 - val_loss: 0.7298 - learning_rate: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 0.2362 - val_accuracy: 0.9033 - val_loss: 0.7719 - learning_rate: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9880 - loss: 0.2541 - val_accuracy: 0.9226 - val_loss: 0.6451 - learning_rate: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9954 - loss: 0.2312 - val_accuracy: 0.9271 - val_loss: 0.6240 - learning_rate: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9961 - loss: 0.2229 - val_accuracy: 0.9360 - val_loss: 0.5986 - learning_rate: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.2116 - val_accuracy: 0.9420 - val_loss: 0.6022 - learning_rate: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9984 - loss: 0.2047 - val_accuracy: 0.9330 - val_loss: 0.6006 - learning_rate: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9953 - loss: 0.2062 - val_accuracy: 0.9196 - val_loss: 0.6609 - learning_rate: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9981 - loss: 0.1925 - val_accuracy: 0.9301 - val_loss: 0.6099 - learning_rate: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9985 - loss: 0.1882 - val_accuracy: 0.9256 - val_loss: 0.6308 - learning_rate: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.1766 - val_accuracy: 0.9271 - val_loss: 0.6430 - learning_rate: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9978 - loss: 0.1756 - val_accuracy: 0.9315 - val_loss: 0.5803 - learning_rate: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9982 - loss: 0.1697 - val_accuracy: 0.9330 - val_loss: 0.6179 - learning_rate: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9971 - loss: 0.1700 - val_accuracy: 0.9301 - val_loss: 0.6014 - learning_rate: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9869 - loss: 0.2022 - val_accuracy: 0.9211 - val_loss: 0.5426 - learning_rate: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.1629 - val_accuracy: 0.9196 - val_loss: 0.6264 - learning_rate: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9936 - loss: 0.1638 - val_accuracy: 0.9345 - val_loss: 0.5401 - learning_rate: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9934 - loss: 0.1640 - val_accuracy: 0.9271 - val_loss: 0.5600 - learning_rate: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9962 - loss: 0.1541 - val_accuracy: 0.9256 - val_loss: 0.5944 - learning_rate: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9934 - loss: 0.1627 - val_accuracy: 0.9182 - val_loss: 0.6357 - learning_rate: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9982 - loss: 0.1435 - val_accuracy: 0.9301 - val_loss: 0.5649 - learning_rate: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9967 - loss: 0.1427 - val_accuracy: 0.9330 - val_loss: 0.6225 - learning_rate: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 0.1382 - val_accuracy: 0.9271 - val_loss: 0.6699 - learning_rate: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9988 - loss: 0.1358 - val_accuracy: 0.9211 - val_loss: 0.6600 - learning_rate: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9977 - loss: 0.1328 - val_accuracy: 0.9286 - val_loss: 0.6349 - learning_rate: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9912 - loss: 0.1465 - val_accuracy: 0.9315 - val_loss: 0.5412 - learning_rate: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9955 - loss: 0.1368 - val_accuracy: 0.9241 - val_loss: 0.6016 - learning_rate: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9984 - loss: 0.1262 - val_accuracy: 0.9330 - val_loss: 0.5248 - learning_rate: 5.0000e-05\n",
      "Epoch 105/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9999 - loss: 0.1207 - val_accuracy: 0.9360 - val_loss: 0.5650 - learning_rate: 5.0000e-05\n",
      "Epoch 106/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9954 - loss: 0.1233 - val_accuracy: 0.9315 - val_loss: 0.5490 - learning_rate: 5.0000e-05\n",
      "Epoch 107/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9992 - loss: 0.1193 - val_accuracy: 0.9271 - val_loss: 0.5454 - learning_rate: 5.0000e-05\n",
      "Epoch 108/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.1155 - val_accuracy: 0.9301 - val_loss: 0.5457 - learning_rate: 5.0000e-05\n",
      "Epoch 109/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.1133 - val_accuracy: 0.9286 - val_loss: 0.5614 - learning_rate: 5.0000e-05\n",
      "Epoch 110/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.1115 - val_accuracy: 0.9301 - val_loss: 0.5694 - learning_rate: 5.0000e-05\n",
      "Epoch 111/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.1091 - val_accuracy: 0.9345 - val_loss: 0.6041 - learning_rate: 5.0000e-05\n",
      "Epoch 112/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.1085 - val_accuracy: 0.9301 - val_loss: 0.5991 - learning_rate: 5.0000e-05\n",
      "Epoch 113/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9960 - loss: 0.1140 - val_accuracy: 0.9301 - val_loss: 0.5519 - learning_rate: 5.0000e-05\n",
      "Epoch 114/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9959 - loss: 0.1144 - val_accuracy: 0.9256 - val_loss: 0.5555 - learning_rate: 5.0000e-05\n",
      "Epoch 115/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9995 - loss: 0.1031 - val_accuracy: 0.9226 - val_loss: 0.5574 - learning_rate: 2.5000e-05\n",
      "Epoch 116/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9995 - loss: 0.1015 - val_accuracy: 0.9271 - val_loss: 0.5737 - learning_rate: 2.5000e-05\n",
      "Epoch 117/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9992 - loss: 0.1018 - val_accuracy: 0.9301 - val_loss: 0.5671 - learning_rate: 2.5000e-05\n",
      "Epoch 118/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9989 - loss: 0.1027 - val_accuracy: 0.9301 - val_loss: 0.5569 - learning_rate: 2.5000e-05\n",
      "Epoch 119/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9999 - loss: 0.0990 - val_accuracy: 0.9271 - val_loss: 0.5502 - learning_rate: 2.5000e-05\n",
      "Epoch 120/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9984 - loss: 0.1000 - val_accuracy: 0.9315 - val_loss: 0.5605 - learning_rate: 2.5000e-05\n",
      "Epoch 121/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9993 - loss: 0.0977 - val_accuracy: 0.9286 - val_loss: 0.5843 - learning_rate: 2.5000e-05\n",
      "Epoch 122/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9971 - loss: 0.0981 - val_accuracy: 0.9256 - val_loss: 0.5482 - learning_rate: 2.5000e-05\n",
      "Epoch 123/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9999 - loss: 0.0949 - val_accuracy: 0.9226 - val_loss: 0.5935 - learning_rate: 2.5000e-05\n",
      "Epoch 124/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0941 - val_accuracy: 0.9315 - val_loss: 0.5511 - learning_rate: 2.5000e-05\n",
      "Epoch 125/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9988 - loss: 0.0956 - val_accuracy: 0.9271 - val_loss: 0.5539 - learning_rate: 1.2500e-05\n",
      "Epoch 126/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0919 - val_accuracy: 0.9286 - val_loss: 0.5473 - learning_rate: 1.2500e-05\n",
      "Epoch 127/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0919 - val_accuracy: 0.9301 - val_loss: 0.5458 - learning_rate: 1.2500e-05\n",
      "Epoch 128/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0911 - val_accuracy: 0.9301 - val_loss: 0.5559 - learning_rate: 1.2500e-05\n",
      "Epoch 129/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0904 - val_accuracy: 0.9315 - val_loss: 0.5564 - learning_rate: 1.2500e-05\n",
      "Epoch 130/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0914 - val_accuracy: 0.9315 - val_loss: 0.5541 - learning_rate: 1.2500e-05\n",
      "Epoch 131/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0898 - val_accuracy: 0.9271 - val_loss: 0.6067 - learning_rate: 1.2500e-05\n",
      "Epoch 132/1000\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0891 - val_accuracy: 0.9301 - val_loss: 0.5731 - learning_rate: 1.2500e-05\n",
      "Epoch 132: early stopping\n",
      "Restoring model weights from the end of the best epoch: 82.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# train the model with the callbacks\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[logging, early_stopping, es_acc, lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2015\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_train, y_train)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9419642857142857\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(ACTIONS))\n",
    "plt.xticks(tick_marks, ACTIONS, rotation=45)\n",
    "plt.yticks(tick_marks, ACTIONS)\n",
    "\n",
    "# add labels\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# compute and print accuracy score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_filename(directory, base_name, extension):\n",
    "    # list all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # filter files that start with the base_name and end with the extension\n",
    "    versions = [f for f in files if f.startswith(base_name) and f.endswith(extension)]\n",
    "\n",
    "    # if the models directory is empty, then use the\n",
    "    # default start version (001)\n",
    "    if not versions and base_name == \"singa_slr_v_\":\n",
    "        return f\"{base_name}001.{extension}\"\n",
    "\n",
    "    # if the fiven basename is different than the actual basename\n",
    "    # then save the model with given name\n",
    "    if not base_name == \"singa_slr_v_\":\n",
    "        return f\"{base_name}.{extension}\"\n",
    "\n",
    "    # extract version numbers from filenames\n",
    "    versions = [file.split(\"_\")[-1] for file in versions]\n",
    "\n",
    "    # convert version numbers to tuples of integers for comparison\n",
    "    versions_int = [int(v.split(\".\")[0]) for v in versions]\n",
    "\n",
    "    next_version = max(versions_int) + 1\n",
    "\n",
    "    # format the next number with leading zeros to maintain the same length\n",
    "    next_filename = f\"{base_name}{next_version:03d}.{extension}\"\n",
    "\n",
    "    return next_filename\n",
    "\n",
    "\n",
    "def save_as_tflite(_model, model_path):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(_model)\n",
    "\n",
    "    # See issue here:\n",
    "    # - https://github.com/tensorflow/tensorflow/issues/26869\n",
    "    # - https://github.com/tensorflow/tensorflow/issues/26869#issuecomment-474984631\n",
    "    # - https://github.com/tensorflow/tensorflow/issues/61662\n",
    "    # - https://stackoverflow.com/a/67252118/14182545\n",
    "    converter.target_spec.supported_ops = [\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "        tf.lite.OpsSet.SELECT_TF_OPS,  # enable TensorFlow ops.\n",
    "    ]\n",
    "\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def save_as_keras(_model, model_path):\n",
    "    _model.save(model_path)\n",
    "\n",
    "\n",
    "def save_model(_model, extension=\"keras\", base_name=\"singa_slr_v_\"):\n",
    "    model_dir = \"../storage/models/\" + extension\n",
    "\n",
    "    next_filename = get_next_filename(model_dir, base_name, extension)\n",
    "    model_path = os.path.join(model_dir, next_filename)\n",
    "\n",
    "    match extension:\n",
    "        case \"tflite\":\n",
    "            save_as_tflite(_model, model_path)\n",
    "            print(f\"saved as tflite at {model_path}\")\n",
    "\n",
    "        case \"keras\":\n",
    "            save_as_keras(_model, model_path)\n",
    "            print(f\"saved as keras at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as keras at ../storage/models/keras\\signa_slr_v_002.keras\n"
     ]
    }
   ],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, extension=\"tflite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
