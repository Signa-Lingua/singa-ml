{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import tensorflow as tf # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for saving the data (numpy array)\n",
    "DATA_PATH = os.path.join(\"../datasets\")\n",
    "\n",
    "# sign action to be detected\n",
    "ACTIONS = np.array(\n",
    "    [\n",
    "        \"hello\",\n",
    "        \"thanks\",\n",
    "        \"i-love-you\",\n",
    "        \"see-you-later\",\n",
    "        \"I\",\n",
    "        \"Father\",\n",
    "        \"Mother\",\n",
    "        \"Yes\",\n",
    "        \"No\",\n",
    "        \"Help\",\n",
    "        \"Please\",\n",
    "        \"Want\",\n",
    "        \"What\",\n",
    "        \"Again\",\n",
    "        \"Eat\",\n",
    "        \"Milk\",\n",
    "        \"More\",\n",
    "        \"Go To\",\n",
    "        \"Bathroom\",\n",
    "        \"Fine\",\n",
    "        \"Like\",\n",
    "        \"Learn\",\n",
    "        \"Sign\",\n",
    "        \"Done\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# NOTE: use the first 6 since we only have 6 label only for now\n",
    "ACTIONS = ACTIONS[:12]\n",
    "\n",
    "# x videos worth of data (per label)\n",
    "videos_per_label = np.max(np.array(os.listdir(os.path.join(DATA_PATH, ACTIONS[0]))).astype(int)) + 1\n",
    "\n",
    "# 30 action per videos\n",
    "# NOTE: This does not affect how much the frame is\n",
    "action_per_video = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', 'thanks', 'i-love-you', 'see-you-later', 'I', 'Father',\n",
       "       'Mother', 'Yes', 'No', 'Help', 'Please', 'Want'], dtype='<U13')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output example:\n",
    "# {'hello': 0, 'thanks': 1, 'i-love-you': 2, ...}\n",
    "labels_map = {label: index for index, label in enumerate(ACTIONS)}\n",
    "\n",
    "sequences, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'hello': 0,\n",
       "  'thanks': 1,\n",
       "  'i-love-you': 2,\n",
       "  'see-you-later': 3,\n",
       "  'I': 4,\n",
       "  'Father': 5,\n",
       "  'Mother': 6,\n",
       "  'Yes': 7,\n",
       "  'No': 8,\n",
       "  'Help': 9,\n",
       "  'Please': 10,\n",
       "  'Want': 11},\n",
       " 60)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_map, videos_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterates over each action in the ACTIONS list.\n",
    "\n",
    "For each action, it will process multiple sequences of frames.\n",
    "\"\"\"\n",
    "for action in ACTIONS:\n",
    "\n",
    "    \"\"\"Iterates over each sequence for the current action\"\"\"\n",
    "    for sequence in range(videos_per_label):\n",
    "        # empty list (window) to hold the frames of the current sequence.\n",
    "        sequence_actions = []\n",
    "\n",
    "        \"\"\"\n",
    "        Frame Processing\n",
    "\n",
    "        Iterates over each frame in the current sequence, then constructs the file path to the numpy array for the current frame.\n",
    "        Prints the path to verify correctness, then loads the frame data from the numpy file.\n",
    "        \"\"\"\n",
    "        for frame_num in range(action_per_video):\n",
    "            # construct the path to the numpy file for the current frame\n",
    "            npy_path = os.path.join(\n",
    "                DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)\n",
    "            )\n",
    "\n",
    "            # load the frame data from the numpy file\n",
    "            result = np.load(npy_path)\n",
    "\n",
    "            # append the frame data to the current sequence (window)\n",
    "            sequence_actions.append(result)\n",
    "\n",
    "        # append the completed sequence to the sequences list\n",
    "        sequences.append(sequence_actions)\n",
    "\n",
    "        # append the corresponding label to the labels list\n",
    "        labels.append(labels_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sequences and labels lists into NumPy arrays that are suitable for use as input (X) and output (y) in machine learning models, particularly for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "\n",
    "# convert labels list to a one-hot encoded NumPy array\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 720)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the dataset into training and testing sets\n",
    "# specifies that 10% of the data should be used as the test set, and the remaining 90% should be used as the training set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of the datasets depend on the total number of sequences and the sequence length. Assuming the code processes 60 sequences for each of the 3 actions, we have:\n",
    "\n",
    "    Total sequences = 60 sequences/action × 6 actions = 360 sequences\n",
    "\n",
    "Given a test_size of 0.2, 20% of the data (approximately 72 sequences) will be in the test set, and 80% (approximately 288 sequences) will be in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((576, 30, 1692), (144, 30, 1692), (576, 12), (144, 12))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, save_model  # type: ignore\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv1D, MaxPooling1D, Dense, Dropout, LSTM, Bidirectional  # type: ignore\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau  # type: ignore\n",
    "from tensorflow.keras.regularizers import l2  # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input shape (30, 1692) where 30 is the sequence length and 1692 is the number of features per frame\n",
    "input_shape = (30, 1692)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic regarding TimeDistributed\n",
    "\n",
    "- https://stackoverflow.com/a/76796778/14182545\n",
    "- https://medium.com/smileinnovation/how-to-work-with-time-distributed-data-in-a-neural-network-b8b39aa4ce00\n",
    "\n",
    "    Another kind of layer that is the famous \"LSTM\" (or GRU). It is not mandatory but it will finalize the chronological resolution of inputs.\n",
    "\n",
    "    Dense without TimeDistributed computes perBatch.\n",
    "    TimeDistributed with Dense computes per Timestep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture CNN-LSTM_1L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\OneDrive\\DOKUMEN\\JO\\myenv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\DOKUMEN\\JO\\myenv\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:143: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# asl-action-cnn-lstm_1l-2.9M\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# data normalization\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "# first Conv1D layer with L2 regularization\n",
    "model.add(\n",
    "    Conv1D(filters=64, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.01))\n",
    ")  # changed kernel size and filters\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# second Conv1D layer with L2 regularization\n",
    "model.add(\n",
    "    Conv1D(filters=128, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.01))\n",
    ")  # changed kernel size and filters\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# third Conv1D layer with L2 regularization\n",
    "model.add(\n",
    "    Conv1D(filters=256, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.01))\n",
    ")  # changed kernel size and filters\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# dense layer for feature extraction with L2 regularization\n",
    "model.add(Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# bidirectional LSTM layer with L2 regularization\n",
    "model.add(\n",
    "    Bidirectional(\n",
    "        LSTM(512, return_sequences=False, activation=\"relu\", kernel_regularizer=l2(0.01))\n",
    "    )\n",
    ")\n",
    "\n",
    "# dense layers for classification with dropout for regularization\n",
    "model.add(Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))  # slightly higher dropout rate, so it's not overfitting\n",
    "model.add(Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))  # slightly higher dropout rate, so it's not overfitting\n",
    "\n",
    "model.add(Dense(ACTIONS.shape[0], activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1692</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,768</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">324,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,363,392</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1692\u001b[0m)       │         \u001b[38;5;34m6,768\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │       \u001b[38;5;34m324,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m98,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,363,392\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m780\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,975,036</span> (11.35 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,975,036\u001b[0m (11.35 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,971,652</span> (11.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,971,652\u001b[0m (11.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,384</span> (13.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,384\u001b[0m (13.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_dir(base_dir, use_time=False):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # check existing log directories\n",
    "    existing_logs = [\n",
    "        d\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"train-\")\n",
    "    ]\n",
    "\n",
    "    # determine the new log directory name\n",
    "    if existing_logs and not use_time:\n",
    "        latest_log = max(existing_logs)\n",
    "        log_num = int(latest_log.split(\"-\")[1]) + 1\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{str(log_num).zfill(3)}\")\n",
    "\n",
    "    if not existing_logs and not use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-001\")\n",
    "\n",
    "    if use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{current_time}\")\n",
    "\n",
    "    # create the new log directory\n",
    "    os.makedirs(new_log_dir)\n",
    "    print(f\"Created new log directory: {new_log_dir}\")\n",
    "\n",
    "    return new_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback  # type: ignore\n",
    "\n",
    "\n",
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor=\"val_loss\", value=0.001, verbose=0, patience=20):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            raise ValueError(f\"Early stopping requires {self.monitor} available!\")\n",
    "\n",
    "        if current <= self.value:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                if self.verbose > 0:\n",
    "                    print(\n",
    "                        f\"Epoch {epoch}: early stopping threshold reached with {self.monitor} = {current}\"\n",
    "                    )\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0  # reset wait if the condition is not met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the optimizer with an initial learning rate\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "# compile the model with the optimizer\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\"\"\"\n",
    "Define the EarlyStopping callback with adjusted patience\n",
    "\n",
    "monitor  : monitor the `val_loss` for training.\n",
    "patience : sets the number of epochs to wait for an improvement,\n",
    "           in the monitored metric before stopping the training.\n",
    "           `patience=10` means that if the validation loss does not improve for 10 consecutive epochs,\n",
    "           the training will be stopped.\n",
    "\"\"\"\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "early_stopping_by_loss_val = EarlyStoppingByLossVal(monitor='val_loss', value=0.001, verbose=1, patience=20)\n",
    "\n",
    "\"\"\"\n",
    "Define the ReduceLROnPlateau callback with adjusted factor and patience\n",
    "\n",
    "monitor  : monitor the `val_loss` for training.\n",
    "factor   : which the learning rate will be reduced. A factor=0.5 means the\n",
    "           learning rate will be halved when the metric has stopped improving.\n",
    "patience : sets the number of epochs with no improvement after which the learning rate will be reduced.\n",
    "           `patience=10` means if the validation loss does not improve for 10 consecutive epochs,\n",
    "           the learning rate will be reduced.\n",
    "min_lr   : lower bound on the learning rate, learning rate will not be reduced below `0.00001`,\n",
    "           ensuring it doesn't become too small.\n",
    "\"\"\"\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new log directory: ../logs\\train-20240610-020002\n",
      "Epoch 1/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - accuracy: 0.0908 - loss: 12.7567 - val_accuracy: 0.0764 - val_loss: 12.2670 - learning_rate: 1.0000e-04\n",
      "Epoch 2/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.1093 - loss: 12.0840 - val_accuracy: 0.1319 - val_loss: 11.6610 - learning_rate: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.1093 - loss: 11.4462 - val_accuracy: 0.0764 - val_loss: 11.0965 - learning_rate: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.1443 - loss: 10.8822 - val_accuracy: 0.0833 - val_loss: 10.5944 - learning_rate: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.1634 - loss: 10.3712 - val_accuracy: 0.1042 - val_loss: 10.1431 - learning_rate: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.1654 - loss: 9.9072 - val_accuracy: 0.1597 - val_loss: 9.7029 - learning_rate: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.1596 - loss: 9.4767 - val_accuracy: 0.1736 - val_loss: 9.3106 - learning_rate: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.2188 - loss: 9.0552 - val_accuracy: 0.1736 - val_loss: 8.9311 - learning_rate: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.2041 - loss: 8.6982 - val_accuracy: 0.1806 - val_loss: 8.5824 - learning_rate: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.1674 - loss: 8.4331 - val_accuracy: 0.1944 - val_loss: 8.2530 - learning_rate: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.1673 - loss: 8.1302 - val_accuracy: 0.2153 - val_loss: 7.9556 - learning_rate: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2207 - loss: 7.7643 - val_accuracy: 0.2500 - val_loss: 7.6428 - learning_rate: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.2623 - loss: 7.5052 - val_accuracy: 0.2500 - val_loss: 7.3462 - learning_rate: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.2356 - loss: 7.2647 - val_accuracy: 0.3681 - val_loss: 7.1232 - learning_rate: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.2724 - loss: 7.0099 - val_accuracy: 0.3611 - val_loss: 6.8464 - learning_rate: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.3214 - loss: 6.7855 - val_accuracy: 0.4097 - val_loss: 6.6120 - learning_rate: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.3071 - loss: 6.5428 - val_accuracy: 0.4722 - val_loss: 6.3962 - learning_rate: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.2993 - loss: 6.3869 - val_accuracy: 0.4375 - val_loss: 6.1843 - learning_rate: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.3037 - loss: 6.1555 - val_accuracy: 0.4444 - val_loss: 5.9850 - learning_rate: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.3356 - loss: 6.0223 - val_accuracy: 0.4375 - val_loss: 5.7630 - learning_rate: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.3877 - loss: 5.7783 - val_accuracy: 0.4792 - val_loss: 5.5597 - learning_rate: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.4150 - loss: 5.5993 - val_accuracy: 0.4722 - val_loss: 5.3621 - learning_rate: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.4254 - loss: 5.4395 - val_accuracy: 0.4861 - val_loss: 5.1955 - learning_rate: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.4288 - loss: 5.3206 - val_accuracy: 0.5417 - val_loss: 5.1179 - learning_rate: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.4152 - loss: 5.2783 - val_accuracy: 0.4931 - val_loss: 4.9679 - learning_rate: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.4167 - loss: 5.2036 - val_accuracy: 0.4931 - val_loss: 4.8998 - learning_rate: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.4341 - loss: 4.9957 - val_accuracy: 0.5069 - val_loss: 4.8339 - learning_rate: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.4780 - loss: 4.9030 - val_accuracy: 0.5069 - val_loss: 4.6284 - learning_rate: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.4665 - loss: 4.7850 - val_accuracy: 0.5625 - val_loss: 4.5564 - learning_rate: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.4911 - loss: 4.6881 - val_accuracy: 0.5625 - val_loss: 4.4419 - learning_rate: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.4322 - loss: 4.7831 - val_accuracy: 0.5694 - val_loss: 4.3499 - learning_rate: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.4844 - loss: 4.5745 - val_accuracy: 0.5347 - val_loss: 4.3137 - learning_rate: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.4738 - loss: 4.4227 - val_accuracy: 0.5347 - val_loss: 4.2098 - learning_rate: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.4825 - loss: 4.4477 - val_accuracy: 0.5625 - val_loss: 4.1618 - learning_rate: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.4944 - loss: 4.3080 - val_accuracy: 0.5903 - val_loss: 4.0565 - learning_rate: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5368 - loss: 4.1769 - val_accuracy: 0.5694 - val_loss: 3.9724 - learning_rate: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5529 - loss: 4.1127 - val_accuracy: 0.5556 - val_loss: 3.9949 - learning_rate: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.5160 - loss: 4.1755 - val_accuracy: 0.5694 - val_loss: 3.9344 - learning_rate: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.5251 - loss: 4.0440 - val_accuracy: 0.5556 - val_loss: 3.8256 - learning_rate: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.5371 - loss: 4.0079 - val_accuracy: 0.5833 - val_loss: 3.7382 - learning_rate: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5680 - loss: 3.9000 - val_accuracy: 0.5903 - val_loss: 3.7233 - learning_rate: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5596 - loss: 3.9053 - val_accuracy: 0.5833 - val_loss: 3.6494 - learning_rate: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.5659 - loss: 3.7902 - val_accuracy: 0.6042 - val_loss: 3.5782 - learning_rate: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5647 - loss: 3.7591 - val_accuracy: 0.5972 - val_loss: 3.5271 - learning_rate: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5150 - loss: 3.7708 - val_accuracy: 0.5903 - val_loss: 3.4727 - learning_rate: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5991 - loss: 3.5740 - val_accuracy: 0.5972 - val_loss: 3.4321 - learning_rate: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6121 - loss: 3.6667 - val_accuracy: 0.5972 - val_loss: 3.4332 - learning_rate: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6174 - loss: 3.5628 - val_accuracy: 0.5972 - val_loss: 3.3300 - learning_rate: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.5587 - loss: 3.4991 - val_accuracy: 0.6111 - val_loss: 3.2980 - learning_rate: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5415 - loss: 3.5338 - val_accuracy: 0.6042 - val_loss: 3.2254 - learning_rate: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6072 - loss: 3.3912 - val_accuracy: 0.6250 - val_loss: 3.1712 - learning_rate: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.5822 - loss: 3.3420 - val_accuracy: 0.5833 - val_loss: 3.1728 - learning_rate: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.5727 - loss: 3.3396 - val_accuracy: 0.6319 - val_loss: 3.1161 - learning_rate: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.5503 - loss: 3.3803 - val_accuracy: 0.6181 - val_loss: 3.0265 - learning_rate: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6179 - loss: 3.1912 - val_accuracy: 0.6181 - val_loss: 2.9520 - learning_rate: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.5899 - loss: 3.2286 - val_accuracy: 0.6389 - val_loss: 2.9149 - learning_rate: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6123 - loss: 3.1558 - val_accuracy: 0.5972 - val_loss: 2.9022 - learning_rate: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6158 - loss: 3.0731 - val_accuracy: 0.6181 - val_loss: 2.8767 - learning_rate: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.5996 - loss: 3.1040 - val_accuracy: 0.6597 - val_loss: 2.8535 - learning_rate: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.5804 - loss: 3.0461 - val_accuracy: 0.6250 - val_loss: 2.8081 - learning_rate: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6359 - loss: 3.0254 - val_accuracy: 0.6458 - val_loss: 2.7384 - learning_rate: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6481 - loss: 3.0073 - val_accuracy: 0.6042 - val_loss: 2.7451 - learning_rate: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6108 - loss: 3.0048 - val_accuracy: 0.6667 - val_loss: 2.6571 - learning_rate: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6448 - loss: 2.8518 - val_accuracy: 0.6806 - val_loss: 2.6800 - learning_rate: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6140 - loss: 2.9028 - val_accuracy: 0.6597 - val_loss: 2.6794 - learning_rate: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6213 - loss: 2.8820 - val_accuracy: 0.6528 - val_loss: 2.5996 - learning_rate: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6495 - loss: 2.7371 - val_accuracy: 0.6944 - val_loss: 2.5517 - learning_rate: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6452 - loss: 2.7940 - val_accuracy: 0.7014 - val_loss: 2.4932 - learning_rate: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5779 - loss: 2.7633 - val_accuracy: 0.6667 - val_loss: 2.5440 - learning_rate: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6451 - loss: 2.7272 - val_accuracy: 0.6875 - val_loss: 2.4548 - learning_rate: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6575 - loss: 2.6812 - val_accuracy: 0.7083 - val_loss: 2.4481 - learning_rate: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6586 - loss: 2.7121 - val_accuracy: 0.7014 - val_loss: 2.4371 - learning_rate: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6476 - loss: 2.6776 - val_accuracy: 0.7083 - val_loss: 2.3684 - learning_rate: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.6491 - loss: 2.6224 - val_accuracy: 0.7431 - val_loss: 2.3324 - learning_rate: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6641 - loss: 2.5988 - val_accuracy: 0.7153 - val_loss: 2.3557 - learning_rate: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6341 - loss: 2.5666 - val_accuracy: 0.7639 - val_loss: 2.2847 - learning_rate: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.6386 - loss: 2.6265 - val_accuracy: 0.7639 - val_loss: 2.2402 - learning_rate: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6395 - loss: 2.5325 - val_accuracy: 0.7153 - val_loss: 2.2701 - learning_rate: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7075 - loss: 2.4626 - val_accuracy: 0.7361 - val_loss: 2.2326 - learning_rate: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.6710 - loss: 2.4426 - val_accuracy: 0.7361 - val_loss: 2.1789 - learning_rate: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.6830 - loss: 2.4430 - val_accuracy: 0.7431 - val_loss: 2.2128 - learning_rate: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6341 - loss: 2.4428 - val_accuracy: 0.7292 - val_loss: 2.1611 - learning_rate: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7040 - loss: 2.3796 - val_accuracy: 0.7292 - val_loss: 2.1454 - learning_rate: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7039 - loss: 2.3453 - val_accuracy: 0.7292 - val_loss: 2.1734 - learning_rate: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.6875 - loss: 2.3811 - val_accuracy: 0.7431 - val_loss: 2.0967 - learning_rate: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6589 - loss: 2.3403 - val_accuracy: 0.7222 - val_loss: 2.1224 - learning_rate: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7486 - loss: 2.2678 - val_accuracy: 0.7153 - val_loss: 2.1112 - learning_rate: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7315 - loss: 2.2531 - val_accuracy: 0.7431 - val_loss: 2.0665 - learning_rate: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7321 - loss: 2.2142 - val_accuracy: 0.7431 - val_loss: 2.0200 - learning_rate: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7173 - loss: 2.2299 - val_accuracy: 0.7222 - val_loss: 2.0462 - learning_rate: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7400 - loss: 2.1555 - val_accuracy: 0.7153 - val_loss: 1.9940 - learning_rate: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7041 - loss: 2.1802 - val_accuracy: 0.7222 - val_loss: 2.0190 - learning_rate: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7050 - loss: 2.1721 - val_accuracy: 0.7153 - val_loss: 1.9595 - learning_rate: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7417 - loss: 2.1295 - val_accuracy: 0.7083 - val_loss: 1.9560 - learning_rate: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7109 - loss: 2.1166 - val_accuracy: 0.7500 - val_loss: 1.9424 - learning_rate: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7021 - loss: 2.1615 - val_accuracy: 0.7431 - val_loss: 1.9886 - learning_rate: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6875 - loss: 2.1335 - val_accuracy: 0.7153 - val_loss: 1.9631 - learning_rate: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7017 - loss: 2.1228 - val_accuracy: 0.7292 - val_loss: 1.9304 - learning_rate: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7000 - loss: 2.1236 - val_accuracy: 0.7222 - val_loss: 1.9463 - learning_rate: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6789 - loss: 2.1396 - val_accuracy: 0.7500 - val_loss: 1.8935 - learning_rate: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7160 - loss: 2.0771 - val_accuracy: 0.7569 - val_loss: 1.9213 - learning_rate: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.6868 - loss: 2.0813 - val_accuracy: 0.7361 - val_loss: 1.9528 - learning_rate: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7002 - loss: 2.0100 - val_accuracy: 0.7569 - val_loss: 1.8408 - learning_rate: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7141 - loss: 2.0469 - val_accuracy: 0.7431 - val_loss: 1.8349 - learning_rate: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7226 - loss: 1.9986 - val_accuracy: 0.7361 - val_loss: 1.8570 - learning_rate: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7067 - loss: 2.0094 - val_accuracy: 0.7639 - val_loss: 1.8722 - learning_rate: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7058 - loss: 2.0198 - val_accuracy: 0.7708 - val_loss: 1.8300 - learning_rate: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7647 - loss: 1.9369 - val_accuracy: 0.7986 - val_loss: 1.8094 - learning_rate: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7245 - loss: 1.9954 - val_accuracy: 0.7569 - val_loss: 1.8160 - learning_rate: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7223 - loss: 1.9760 - val_accuracy: 0.7708 - val_loss: 1.7685 - learning_rate: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7343 - loss: 1.9365 - val_accuracy: 0.7431 - val_loss: 1.8011 - learning_rate: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7246 - loss: 1.9377 - val_accuracy: 0.8194 - val_loss: 1.7655 - learning_rate: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7223 - loss: 1.8957 - val_accuracy: 0.7569 - val_loss: 1.7934 - learning_rate: 1.0000e-04\n",
      "Epoch 114/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7295 - loss: 2.0193 - val_accuracy: 0.7639 - val_loss: 1.7294 - learning_rate: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7461 - loss: 1.8898 - val_accuracy: 0.7153 - val_loss: 1.7692 - learning_rate: 1.0000e-04\n",
      "Epoch 116/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7880 - loss: 1.8309 - val_accuracy: 0.8056 - val_loss: 1.7032 - learning_rate: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7042 - loss: 1.9386 - val_accuracy: 0.8333 - val_loss: 1.7368 - learning_rate: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7286 - loss: 1.9496 - val_accuracy: 0.7778 - val_loss: 1.6990 - learning_rate: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7485 - loss: 1.8320 - val_accuracy: 0.7500 - val_loss: 1.7122 - learning_rate: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7469 - loss: 1.8100 - val_accuracy: 0.7847 - val_loss: 1.6929 - learning_rate: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7537 - loss: 1.8189 - val_accuracy: 0.8264 - val_loss: 1.7161 - learning_rate: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7608 - loss: 1.7534 - val_accuracy: 0.8125 - val_loss: 1.6659 - learning_rate: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7619 - loss: 1.7978 - val_accuracy: 0.8125 - val_loss: 1.6843 - learning_rate: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7753 - loss: 1.7851 - val_accuracy: 0.8194 - val_loss: 1.6875 - learning_rate: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7312 - loss: 1.8028 - val_accuracy: 0.8403 - val_loss: 1.6123 - learning_rate: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7585 - loss: 1.7909 - val_accuracy: 0.7778 - val_loss: 1.6565 - learning_rate: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7232 - loss: 1.8463 - val_accuracy: 0.7778 - val_loss: 1.6751 - learning_rate: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7267 - loss: 1.8021 - val_accuracy: 0.7500 - val_loss: 1.7073 - learning_rate: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7558 - loss: 1.7224 - val_accuracy: 0.8333 - val_loss: 1.6259 - learning_rate: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7047 - loss: 1.8555 - val_accuracy: 0.7639 - val_loss: 1.7090 - learning_rate: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7535 - loss: 1.7595 - val_accuracy: 0.7222 - val_loss: 1.6225 - learning_rate: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7194 - loss: 1.7591 - val_accuracy: 0.7986 - val_loss: 1.6375 - learning_rate: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7232 - loss: 1.7719 - val_accuracy: 0.7431 - val_loss: 1.5972 - learning_rate: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7482 - loss: 1.6903 - val_accuracy: 0.7639 - val_loss: 1.6239 - learning_rate: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7234 - loss: 1.6749 - val_accuracy: 0.8403 - val_loss: 1.5665 - learning_rate: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7500 - loss: 1.7061 - val_accuracy: 0.7778 - val_loss: 1.5776 - learning_rate: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.7915 - loss: 1.6379 - val_accuracy: 0.7639 - val_loss: 1.5667 - learning_rate: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7713 - loss: 1.7272 - val_accuracy: 0.7361 - val_loss: 1.5434 - learning_rate: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.6991 - loss: 1.7286 - val_accuracy: 0.8125 - val_loss: 1.5520 - learning_rate: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7848 - loss: 1.6303 - val_accuracy: 0.7917 - val_loss: 1.5611 - learning_rate: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7613 - loss: 1.6694 - val_accuracy: 0.8056 - val_loss: 1.5123 - learning_rate: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7313 - loss: 1.6542 - val_accuracy: 0.8194 - val_loss: 1.5729 - learning_rate: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.7491 - loss: 1.6415 - val_accuracy: 0.7639 - val_loss: 1.5378 - learning_rate: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7360 - loss: 1.6449 - val_accuracy: 0.8333 - val_loss: 1.5376 - learning_rate: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7395 - loss: 1.6737 - val_accuracy: 0.7569 - val_loss: 1.6289 - learning_rate: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7830 - loss: 1.6206 - val_accuracy: 0.7847 - val_loss: 1.5001 - learning_rate: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7921 - loss: 1.5671 - val_accuracy: 0.8125 - val_loss: 1.4809 - learning_rate: 1.0000e-04\n",
      "Epoch 148/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.7326 - loss: 1.5998 - val_accuracy: 0.7986 - val_loss: 1.5230 - learning_rate: 1.0000e-04\n",
      "Epoch 149/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7218 - loss: 1.6303 - val_accuracy: 0.8056 - val_loss: 1.4840 - learning_rate: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7722 - loss: 1.5571 - val_accuracy: 0.8056 - val_loss: 1.5110 - learning_rate: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7581 - loss: 1.5858 - val_accuracy: 0.8125 - val_loss: 1.4824 - learning_rate: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7535 - loss: 1.5885 - val_accuracy: 0.8264 - val_loss: 1.4772 - learning_rate: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7451 - loss: 1.5519 - val_accuracy: 0.8403 - val_loss: 1.4389 - learning_rate: 1.0000e-04\n",
      "Epoch 154/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7815 - loss: 1.5131 - val_accuracy: 0.7778 - val_loss: 1.4805 - learning_rate: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8115 - loss: 1.5259 - val_accuracy: 0.8403 - val_loss: 1.4773 - learning_rate: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.7509 - loss: 1.5658 - val_accuracy: 0.8125 - val_loss: 1.4718 - learning_rate: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7653 - loss: 1.5058 - val_accuracy: 0.8681 - val_loss: 1.4457 - learning_rate: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7803 - loss: 1.5750 - val_accuracy: 0.8333 - val_loss: 1.4299 - learning_rate: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7796 - loss: 1.5051 - val_accuracy: 0.8056 - val_loss: 1.4257 - learning_rate: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7687 - loss: 1.5075 - val_accuracy: 0.8403 - val_loss: 1.4233 - learning_rate: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7762 - loss: 1.5192 - val_accuracy: 0.8542 - val_loss: 1.4011 - learning_rate: 1.0000e-04\n",
      "Epoch 162/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.7699 - loss: 1.4994 - val_accuracy: 0.8819 - val_loss: 1.4294 - learning_rate: 1.0000e-04\n",
      "Epoch 163/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7788 - loss: 1.5336 - val_accuracy: 0.8056 - val_loss: 1.4192 - learning_rate: 1.0000e-04\n",
      "Epoch 164/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7885 - loss: 1.4899 - val_accuracy: 0.8403 - val_loss: 1.3598 - learning_rate: 1.0000e-04\n",
      "Epoch 165/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.7722 - loss: 1.5032 - val_accuracy: 0.8056 - val_loss: 1.3854 - learning_rate: 1.0000e-04\n",
      "Epoch 166/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7608 - loss: 1.4993 - val_accuracy: 0.8264 - val_loss: 1.5062 - learning_rate: 1.0000e-04\n",
      "Epoch 167/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7673 - loss: 1.4898 - val_accuracy: 0.8333 - val_loss: 1.3702 - learning_rate: 1.0000e-04\n",
      "Epoch 168/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.7439 - loss: 1.5177 - val_accuracy: 0.8056 - val_loss: 1.4293 - learning_rate: 1.0000e-04\n",
      "Epoch 169/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8007 - loss: 1.5228 - val_accuracy: 0.8958 - val_loss: 1.3117 - learning_rate: 1.0000e-04\n",
      "Epoch 170/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8118 - loss: 1.4311 - val_accuracy: 0.8264 - val_loss: 1.3512 - learning_rate: 1.0000e-04\n",
      "Epoch 171/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8568 - loss: 1.3705 - val_accuracy: 0.8819 - val_loss: 1.3168 - learning_rate: 1.0000e-04\n",
      "Epoch 172/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7908 - loss: 1.5010 - val_accuracy: 0.8403 - val_loss: 1.3192 - learning_rate: 1.0000e-04\n",
      "Epoch 173/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8052 - loss: 1.4458 - val_accuracy: 0.8750 - val_loss: 1.3290 - learning_rate: 1.0000e-04\n",
      "Epoch 174/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8173 - loss: 1.4143 - val_accuracy: 0.8958 - val_loss: 1.2799 - learning_rate: 1.0000e-04\n",
      "Epoch 175/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8020 - loss: 1.4480 - val_accuracy: 0.7847 - val_loss: 1.4054 - learning_rate: 1.0000e-04\n",
      "Epoch 176/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8284 - loss: 1.4036 - val_accuracy: 0.8542 - val_loss: 1.3530 - learning_rate: 1.0000e-04\n",
      "Epoch 177/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8244 - loss: 1.3581 - val_accuracy: 0.8681 - val_loss: 1.3467 - learning_rate: 1.0000e-04\n",
      "Epoch 178/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.7991 - loss: 1.4294 - val_accuracy: 0.8542 - val_loss: 1.2876 - learning_rate: 1.0000e-04\n",
      "Epoch 179/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8263 - loss: 1.4040 - val_accuracy: 0.8403 - val_loss: 1.3587 - learning_rate: 1.0000e-04\n",
      "Epoch 180/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.8055 - loss: 1.3667 - val_accuracy: 0.8750 - val_loss: 1.3115 - learning_rate: 1.0000e-04\n",
      "Epoch 181/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7957 - loss: 1.3927 - val_accuracy: 0.8194 - val_loss: 1.3162 - learning_rate: 1.0000e-04\n",
      "Epoch 182/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8086 - loss: 1.3585 - val_accuracy: 0.8889 - val_loss: 1.2390 - learning_rate: 1.0000e-04\n",
      "Epoch 183/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8236 - loss: 1.3512 - val_accuracy: 0.8403 - val_loss: 1.2707 - learning_rate: 1.0000e-04\n",
      "Epoch 184/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8101 - loss: 1.3537 - val_accuracy: 0.8542 - val_loss: 1.2514 - learning_rate: 1.0000e-04\n",
      "Epoch 185/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8363 - loss: 1.3590 - val_accuracy: 0.8403 - val_loss: 1.2794 - learning_rate: 1.0000e-04\n",
      "Epoch 186/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8377 - loss: 1.3125 - val_accuracy: 0.8542 - val_loss: 1.2643 - learning_rate: 1.0000e-04\n",
      "Epoch 187/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8373 - loss: 1.3396 - val_accuracy: 0.8750 - val_loss: 1.2418 - learning_rate: 1.0000e-04\n",
      "Epoch 188/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7765 - loss: 1.5155 - val_accuracy: 0.8194 - val_loss: 1.3128 - learning_rate: 1.0000e-04\n",
      "Epoch 189/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8369 - loss: 1.3966 - val_accuracy: 0.8819 - val_loss: 1.2489 - learning_rate: 1.0000e-04\n",
      "Epoch 190/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.7952 - loss: 1.3709 - val_accuracy: 0.8819 - val_loss: 1.2542 - learning_rate: 1.0000e-04\n",
      "Epoch 191/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8459 - loss: 1.2974 - val_accuracy: 0.8611 - val_loss: 1.2445 - learning_rate: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8102 - loss: 1.3678 - val_accuracy: 0.9028 - val_loss: 1.2231 - learning_rate: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8564 - loss: 1.2768 - val_accuracy: 0.9306 - val_loss: 1.2005 - learning_rate: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8508 - loss: 1.3085 - val_accuracy: 0.9028 - val_loss: 1.1836 - learning_rate: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8150 - loss: 1.3734 - val_accuracy: 0.8681 - val_loss: 1.2158 - learning_rate: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8276 - loss: 1.3037 - val_accuracy: 0.9028 - val_loss: 1.1687 - learning_rate: 1.0000e-04\n",
      "Epoch 197/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8741 - loss: 1.2160 - val_accuracy: 0.8889 - val_loss: 1.1785 - learning_rate: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7991 - loss: 1.3183 - val_accuracy: 0.8472 - val_loss: 1.2213 - learning_rate: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.7873 - loss: 1.3515 - val_accuracy: 0.8889 - val_loss: 1.2118 - learning_rate: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8353 - loss: 1.2730 - val_accuracy: 0.8889 - val_loss: 1.1955 - learning_rate: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8671 - loss: 1.2456 - val_accuracy: 0.8472 - val_loss: 1.2065 - learning_rate: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8680 - loss: 1.2810 - val_accuracy: 0.8819 - val_loss: 1.1878 - learning_rate: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8516 - loss: 1.2481 - val_accuracy: 0.8889 - val_loss: 1.1917 - learning_rate: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8408 - loss: 1.2660 - val_accuracy: 0.8819 - val_loss: 1.1959 - learning_rate: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8639 - loss: 1.2195 - val_accuracy: 0.9028 - val_loss: 1.1621 - learning_rate: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8400 - loss: 1.2883 - val_accuracy: 0.8889 - val_loss: 1.1645 - learning_rate: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8596 - loss: 1.2331 - val_accuracy: 0.8889 - val_loss: 1.1939 - learning_rate: 1.0000e-04\n",
      "Epoch 208/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8904 - loss: 1.1792 - val_accuracy: 0.8819 - val_loss: 1.1667 - learning_rate: 1.0000e-04\n",
      "Epoch 209/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8146 - loss: 1.3840 - val_accuracy: 0.9306 - val_loss: 1.1543 - learning_rate: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8804 - loss: 1.2001 - val_accuracy: 0.8889 - val_loss: 1.1600 - learning_rate: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8564 - loss: 1.2237 - val_accuracy: 0.9444 - val_loss: 1.1053 - learning_rate: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8935 - loss: 1.1557 - val_accuracy: 0.9097 - val_loss: 1.1368 - learning_rate: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8978 - loss: 1.1557 - val_accuracy: 0.9028 - val_loss: 1.1515 - learning_rate: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9020 - loss: 1.1291 - val_accuracy: 0.8958 - val_loss: 1.1684 - learning_rate: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8671 - loss: 1.1708 - val_accuracy: 0.9306 - val_loss: 1.1232 - learning_rate: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9051 - loss: 1.1680 - val_accuracy: 0.9097 - val_loss: 1.0921 - learning_rate: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8887 - loss: 1.1421 - val_accuracy: 0.8750 - val_loss: 1.1637 - learning_rate: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8504 - loss: 1.2287 - val_accuracy: 0.8958 - val_loss: 1.1522 - learning_rate: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8607 - loss: 1.2125 - val_accuracy: 0.9444 - val_loss: 1.0592 - learning_rate: 1.0000e-04\n",
      "Epoch 220/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9065 - loss: 1.1397 - val_accuracy: 0.9167 - val_loss: 1.1617 - learning_rate: 1.0000e-04\n",
      "Epoch 221/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8735 - loss: 1.2289 - val_accuracy: 0.9236 - val_loss: 1.0632 - learning_rate: 1.0000e-04\n",
      "Epoch 222/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8523 - loss: 1.1744 - val_accuracy: 0.9375 - val_loss: 1.0459 - learning_rate: 1.0000e-04\n",
      "Epoch 223/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.8782 - loss: 1.1957 - val_accuracy: 0.9306 - val_loss: 1.1173 - learning_rate: 1.0000e-04\n",
      "Epoch 224/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8635 - loss: 1.1889 - val_accuracy: 0.9236 - val_loss: 1.0812 - learning_rate: 1.0000e-04\n",
      "Epoch 225/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8933 - loss: 1.1507 - val_accuracy: 0.9167 - val_loss: 1.1155 - learning_rate: 1.0000e-04\n",
      "Epoch 226/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8836 - loss: 1.1454 - val_accuracy: 0.9236 - val_loss: 1.0346 - learning_rate: 1.0000e-04\n",
      "Epoch 227/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8949 - loss: 1.1123 - val_accuracy: 0.9097 - val_loss: 1.0737 - learning_rate: 1.0000e-04\n",
      "Epoch 228/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8733 - loss: 1.1887 - val_accuracy: 0.9236 - val_loss: 1.0756 - learning_rate: 1.0000e-04\n",
      "Epoch 229/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8781 - loss: 1.1928 - val_accuracy: 0.8403 - val_loss: 1.1319 - learning_rate: 1.0000e-04\n",
      "Epoch 230/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8777 - loss: 1.1851 - val_accuracy: 0.9167 - val_loss: 1.0515 - learning_rate: 1.0000e-04\n",
      "Epoch 231/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8847 - loss: 1.1351 - val_accuracy: 0.9236 - val_loss: 1.0376 - learning_rate: 1.0000e-04\n",
      "Epoch 232/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8952 - loss: 1.0932 - val_accuracy: 0.9097 - val_loss: 1.0802 - learning_rate: 1.0000e-04\n",
      "Epoch 233/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9078 - loss: 1.0690 - val_accuracy: 0.9097 - val_loss: 1.0218 - learning_rate: 1.0000e-04\n",
      "Epoch 234/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9040 - loss: 1.0449 - val_accuracy: 0.9444 - val_loss: 1.0139 - learning_rate: 1.0000e-04\n",
      "Epoch 235/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8626 - loss: 1.1244 - val_accuracy: 0.9028 - val_loss: 1.0695 - learning_rate: 1.0000e-04\n",
      "Epoch 236/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9059 - loss: 1.0679 - val_accuracy: 0.9236 - val_loss: 1.0404 - learning_rate: 1.0000e-04\n",
      "Epoch 237/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9083 - loss: 1.0679 - val_accuracy: 0.9167 - val_loss: 1.1052 - learning_rate: 1.0000e-04\n",
      "Epoch 238/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9128 - loss: 1.0436 - val_accuracy: 0.9375 - val_loss: 1.0197 - learning_rate: 1.0000e-04\n",
      "Epoch 239/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9106 - loss: 1.0699 - val_accuracy: 0.9306 - val_loss: 1.0143 - learning_rate: 1.0000e-04\n",
      "Epoch 240/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8883 - loss: 1.1087 - val_accuracy: 0.8889 - val_loss: 1.1260 - learning_rate: 1.0000e-04\n",
      "Epoch 241/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8849 - loss: 1.1265 - val_accuracy: 0.8750 - val_loss: 1.0735 - learning_rate: 1.0000e-04\n",
      "Epoch 242/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8920 - loss: 1.1042 - val_accuracy: 0.9028 - val_loss: 1.0178 - learning_rate: 1.0000e-04\n",
      "Epoch 243/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8657 - loss: 1.1425 - val_accuracy: 0.9306 - val_loss: 1.0191 - learning_rate: 1.0000e-04\n",
      "Epoch 244/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9125 - loss: 1.0402 - val_accuracy: 0.9375 - val_loss: 0.9746 - learning_rate: 1.0000e-04\n",
      "Epoch 245/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8917 - loss: 1.1014 - val_accuracy: 0.9167 - val_loss: 1.0349 - learning_rate: 1.0000e-04\n",
      "Epoch 246/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8835 - loss: 1.1300 - val_accuracy: 0.9306 - val_loss: 1.0077 - learning_rate: 1.0000e-04\n",
      "Epoch 247/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9218 - loss: 1.0549 - val_accuracy: 0.9167 - val_loss: 1.0193 - learning_rate: 1.0000e-04\n",
      "Epoch 248/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9031 - loss: 1.0425 - val_accuracy: 0.9097 - val_loss: 1.0263 - learning_rate: 1.0000e-04\n",
      "Epoch 249/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9157 - loss: 0.9882 - val_accuracy: 0.9236 - val_loss: 0.9506 - learning_rate: 1.0000e-04\n",
      "Epoch 250/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.9193 - loss: 1.0223 - val_accuracy: 0.9444 - val_loss: 0.9525 - learning_rate: 1.0000e-04\n",
      "Epoch 251/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9418 - loss: 0.9856 - val_accuracy: 0.9306 - val_loss: 0.9557 - learning_rate: 1.0000e-04\n",
      "Epoch 252/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9118 - loss: 1.0414 - val_accuracy: 0.9236 - val_loss: 0.9579 - learning_rate: 1.0000e-04\n",
      "Epoch 253/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9167 - loss: 0.9751 - val_accuracy: 0.8889 - val_loss: 1.0664 - learning_rate: 1.0000e-04\n",
      "Epoch 254/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.8943 - loss: 1.0392 - val_accuracy: 0.9514 - val_loss: 0.9166 - learning_rate: 1.0000e-04\n",
      "Epoch 255/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9329 - loss: 0.9716 - val_accuracy: 0.8681 - val_loss: 1.1212 - learning_rate: 1.0000e-04\n",
      "Epoch 256/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.8975 - loss: 1.0233 - val_accuracy: 0.9306 - val_loss: 0.9739 - learning_rate: 1.0000e-04\n",
      "Epoch 257/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.8956 - loss: 1.0529 - val_accuracy: 0.9375 - val_loss: 0.9529 - learning_rate: 1.0000e-04\n",
      "Epoch 258/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9023 - loss: 1.0428 - val_accuracy: 0.9236 - val_loss: 0.9457 - learning_rate: 1.0000e-04\n",
      "Epoch 259/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9078 - loss: 1.0094 - val_accuracy: 0.9306 - val_loss: 0.9730 - learning_rate: 1.0000e-04\n",
      "Epoch 260/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9094 - loss: 1.0567 - val_accuracy: 0.9653 - val_loss: 0.9124 - learning_rate: 1.0000e-04\n",
      "Epoch 261/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9323 - loss: 0.9708 - val_accuracy: 0.9375 - val_loss: 0.9508 - learning_rate: 1.0000e-04\n",
      "Epoch 262/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9422 - loss: 0.9394 - val_accuracy: 0.8958 - val_loss: 1.0636 - learning_rate: 1.0000e-04\n",
      "Epoch 263/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9165 - loss: 0.9637 - val_accuracy: 0.9097 - val_loss: 0.9871 - learning_rate: 1.0000e-04\n",
      "Epoch 264/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9255 - loss: 0.9704 - val_accuracy: 0.9444 - val_loss: 0.9314 - learning_rate: 1.0000e-04\n",
      "Epoch 265/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9205 - loss: 1.0244 - val_accuracy: 0.9375 - val_loss: 0.9524 - learning_rate: 1.0000e-04\n",
      "Epoch 266/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9082 - loss: 1.0193 - val_accuracy: 0.9514 - val_loss: 0.9590 - learning_rate: 1.0000e-04\n",
      "Epoch 267/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9287 - loss: 0.9810 - val_accuracy: 0.9167 - val_loss: 1.0087 - learning_rate: 1.0000e-04\n",
      "Epoch 268/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8960 - loss: 1.0785 - val_accuracy: 0.9028 - val_loss: 0.9721 - learning_rate: 1.0000e-04\n",
      "Epoch 269/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9105 - loss: 0.9945 - val_accuracy: 0.9236 - val_loss: 0.9123 - learning_rate: 1.0000e-04\n",
      "Epoch 270/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9177 - loss: 0.9599 - val_accuracy: 0.9583 - val_loss: 0.8841 - learning_rate: 1.0000e-04\n",
      "Epoch 271/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8859 - loss: 1.0445 - val_accuracy: 0.9306 - val_loss: 0.9126 - learning_rate: 1.0000e-04\n",
      "Epoch 272/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9263 - loss: 0.9668 - val_accuracy: 0.9514 - val_loss: 0.8797 - learning_rate: 1.0000e-04\n",
      "Epoch 273/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9109 - loss: 1.0100 - val_accuracy: 0.8819 - val_loss: 0.9975 - learning_rate: 1.0000e-04\n",
      "Epoch 274/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9161 - loss: 0.9634 - val_accuracy: 0.9583 - val_loss: 0.8674 - learning_rate: 1.0000e-04\n",
      "Epoch 275/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9359 - loss: 0.9361 - val_accuracy: 0.9167 - val_loss: 0.9355 - learning_rate: 1.0000e-04\n",
      "Epoch 276/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8802 - loss: 1.0106 - val_accuracy: 0.9236 - val_loss: 0.9515 - learning_rate: 1.0000e-04\n",
      "Epoch 277/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9172 - loss: 0.9839 - val_accuracy: 0.9375 - val_loss: 0.9108 - learning_rate: 1.0000e-04\n",
      "Epoch 278/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9411 - loss: 0.9180 - val_accuracy: 0.9444 - val_loss: 0.9500 - learning_rate: 1.0000e-04\n",
      "Epoch 279/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.8963 - loss: 0.9685 - val_accuracy: 0.9514 - val_loss: 0.8814 - learning_rate: 1.0000e-04\n",
      "Epoch 280/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9047 - loss: 0.9594 - val_accuracy: 0.9375 - val_loss: 0.8896 - learning_rate: 1.0000e-04\n",
      "Epoch 281/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9028 - loss: 0.9842 - val_accuracy: 0.9097 - val_loss: 0.9430 - learning_rate: 1.0000e-04\n",
      "Epoch 282/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9094 - loss: 0.9387 - val_accuracy: 0.9444 - val_loss: 0.8849 - learning_rate: 1.0000e-04\n",
      "Epoch 283/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9475 - loss: 0.9808 - val_accuracy: 0.9236 - val_loss: 0.9434 - learning_rate: 1.0000e-04\n",
      "Epoch 284/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.8784 - loss: 1.0910 - val_accuracy: 0.9583 - val_loss: 0.9192 - learning_rate: 1.0000e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9168 - loss: 0.9812 - val_accuracy: 0.9375 - val_loss: 0.9106 - learning_rate: 5.0000e-05\n",
      "Epoch 286/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9479 - loss: 0.9232 - val_accuracy: 0.9653 - val_loss: 0.8998 - learning_rate: 5.0000e-05\n",
      "Epoch 287/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9333 - loss: 0.8994 - val_accuracy: 0.9583 - val_loss: 0.9085 - learning_rate: 5.0000e-05\n",
      "Epoch 288/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9195 - loss: 0.9063 - val_accuracy: 0.9375 - val_loss: 0.9103 - learning_rate: 5.0000e-05\n",
      "Epoch 289/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9357 - loss: 0.9351 - val_accuracy: 0.9375 - val_loss: 0.9493 - learning_rate: 5.0000e-05\n",
      "Epoch 290/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9346 - loss: 0.9387 - val_accuracy: 0.9236 - val_loss: 0.9325 - learning_rate: 5.0000e-05\n",
      "Epoch 291/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8992 - loss: 0.9378 - val_accuracy: 0.9514 - val_loss: 0.8564 - learning_rate: 5.0000e-05\n",
      "Epoch 292/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9382 - loss: 0.9210 - val_accuracy: 0.9236 - val_loss: 0.9375 - learning_rate: 5.0000e-05\n",
      "Epoch 293/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9437 - loss: 0.8826 - val_accuracy: 0.9514 - val_loss: 0.8633 - learning_rate: 5.0000e-05\n",
      "Epoch 294/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9544 - loss: 0.9128 - val_accuracy: 0.9514 - val_loss: 0.8789 - learning_rate: 5.0000e-05\n",
      "Epoch 295/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9457 - loss: 0.8946 - val_accuracy: 0.9514 - val_loss: 0.8906 - learning_rate: 5.0000e-05\n",
      "Epoch 296/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9389 - loss: 0.8948 - val_accuracy: 0.9306 - val_loss: 0.9581 - learning_rate: 5.0000e-05\n",
      "Epoch 297/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9404 - loss: 0.8700 - val_accuracy: 0.9444 - val_loss: 0.9364 - learning_rate: 5.0000e-05\n",
      "Epoch 298/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9342 - loss: 0.9087 - val_accuracy: 0.9236 - val_loss: 0.9200 - learning_rate: 5.0000e-05\n",
      "Epoch 299/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9536 - loss: 0.8752 - val_accuracy: 0.9514 - val_loss: 0.8822 - learning_rate: 5.0000e-05\n",
      "Epoch 300/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9528 - loss: 0.8590 - val_accuracy: 0.9583 - val_loss: 0.8860 - learning_rate: 5.0000e-05\n",
      "Epoch 301/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9601 - loss: 0.8293 - val_accuracy: 0.9583 - val_loss: 0.8282 - learning_rate: 5.0000e-05\n",
      "Epoch 302/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9264 - loss: 0.9122 - val_accuracy: 0.9375 - val_loss: 0.8770 - learning_rate: 5.0000e-05\n",
      "Epoch 303/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9517 - loss: 0.9125 - val_accuracy: 0.9375 - val_loss: 0.8772 - learning_rate: 5.0000e-05\n",
      "Epoch 304/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.9418 - loss: 0.8683 - val_accuracy: 0.9514 - val_loss: 0.8393 - learning_rate: 5.0000e-05\n",
      "Epoch 305/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9621 - loss: 0.8217 - val_accuracy: 0.9444 - val_loss: 0.8677 - learning_rate: 5.0000e-05\n",
      "Epoch 306/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9527 - loss: 0.8796 - val_accuracy: 0.9375 - val_loss: 0.8731 - learning_rate: 5.0000e-05\n",
      "Epoch 307/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.9419 - loss: 0.8638 - val_accuracy: 0.9375 - val_loss: 0.8531 - learning_rate: 5.0000e-05\n",
      "Epoch 308/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9456 - loss: 0.8795 - val_accuracy: 0.9306 - val_loss: 0.9369 - learning_rate: 5.0000e-05\n",
      "Epoch 309/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9240 - loss: 0.9148 - val_accuracy: 0.9514 - val_loss: 0.8460 - learning_rate: 5.0000e-05\n",
      "Epoch 310/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9419 - loss: 0.8308 - val_accuracy: 0.9444 - val_loss: 0.8700 - learning_rate: 5.0000e-05\n",
      "Epoch 311/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9370 - loss: 0.8438 - val_accuracy: 0.9514 - val_loss: 0.8894 - learning_rate: 5.0000e-05\n",
      "Epoch 312/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9285 - loss: 0.9273 - val_accuracy: 0.9375 - val_loss: 0.8848 - learning_rate: 2.5000e-05\n",
      "Epoch 313/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9096 - loss: 0.9750 - val_accuracy: 0.9444 - val_loss: 0.8305 - learning_rate: 2.5000e-05\n",
      "Epoch 314/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9557 - loss: 0.8287 - val_accuracy: 0.9375 - val_loss: 0.8466 - learning_rate: 2.5000e-05\n",
      "Epoch 315/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9629 - loss: 0.8787 - val_accuracy: 0.9375 - val_loss: 0.8554 - learning_rate: 2.5000e-05\n",
      "Epoch 316/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9486 - loss: 0.8680 - val_accuracy: 0.9444 - val_loss: 0.8228 - learning_rate: 2.5000e-05\n",
      "Epoch 317/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9690 - loss: 0.7921 - val_accuracy: 0.9514 - val_loss: 0.8125 - learning_rate: 2.5000e-05\n",
      "Epoch 318/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9529 - loss: 0.8529 - val_accuracy: 0.9444 - val_loss: 0.8139 - learning_rate: 2.5000e-05\n",
      "Epoch 319/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9638 - loss: 0.8468 - val_accuracy: 0.9514 - val_loss: 0.8623 - learning_rate: 2.5000e-05\n",
      "Epoch 320/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9508 - loss: 0.8793 - val_accuracy: 0.9514 - val_loss: 0.8281 - learning_rate: 2.5000e-05\n",
      "Epoch 321/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9403 - loss: 0.8493 - val_accuracy: 0.9444 - val_loss: 0.8437 - learning_rate: 2.5000e-05\n",
      "Epoch 322/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9486 - loss: 0.8566 - val_accuracy: 0.9514 - val_loss: 0.8600 - learning_rate: 2.5000e-05\n",
      "Epoch 323/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9438 - loss: 0.8535 - val_accuracy: 0.9444 - val_loss: 0.8900 - learning_rate: 2.5000e-05\n",
      "Epoch 324/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.9594 - loss: 0.8192 - val_accuracy: 0.9444 - val_loss: 0.8285 - learning_rate: 2.5000e-05\n",
      "Epoch 325/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9299 - loss: 0.8942 - val_accuracy: 0.9514 - val_loss: 0.8516 - learning_rate: 2.5000e-05\n",
      "Epoch 326/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9495 - loss: 0.8409 - val_accuracy: 0.9514 - val_loss: 0.8263 - learning_rate: 2.5000e-05\n",
      "Epoch 327/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9508 - loss: 0.8836 - val_accuracy: 0.9306 - val_loss: 0.8810 - learning_rate: 2.5000e-05\n",
      "Epoch 328/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9592 - loss: 0.8169 - val_accuracy: 0.9514 - val_loss: 0.8472 - learning_rate: 1.2500e-05\n",
      "Epoch 329/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9670 - loss: 0.8082 - val_accuracy: 0.9514 - val_loss: 0.8465 - learning_rate: 1.2500e-05\n",
      "Epoch 330/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9675 - loss: 0.7932 - val_accuracy: 0.9444 - val_loss: 0.8627 - learning_rate: 1.2500e-05\n",
      "Epoch 331/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9480 - loss: 0.8318 - val_accuracy: 0.9375 - val_loss: 0.8466 - learning_rate: 1.2500e-05\n",
      "Epoch 332/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9431 - loss: 0.8444 - val_accuracy: 0.9444 - val_loss: 0.8489 - learning_rate: 1.2500e-05\n",
      "Epoch 333/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9608 - loss: 0.8064 - val_accuracy: 0.9444 - val_loss: 0.8593 - learning_rate: 1.2500e-05\n",
      "Epoch 334/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.9597 - loss: 0.8130 - val_accuracy: 0.9444 - val_loss: 0.8806 - learning_rate: 1.2500e-05\n",
      "Epoch 335/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9630 - loss: 0.8377 - val_accuracy: 0.9444 - val_loss: 0.8628 - learning_rate: 1.2500e-05\n",
      "Epoch 336/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9532 - loss: 0.8433 - val_accuracy: 0.9514 - val_loss: 0.8585 - learning_rate: 1.2500e-05\n",
      "Epoch 337/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9495 - loss: 0.8563 - val_accuracy: 0.9444 - val_loss: 0.8653 - learning_rate: 1.2500e-05\n",
      "Epoch 338/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.9713 - loss: 0.8004 - val_accuracy: 0.9514 - val_loss: 0.8674 - learning_rate: 6.2500e-06\n",
      "Epoch 339/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9672 - loss: 0.8101 - val_accuracy: 0.9514 - val_loss: 0.8667 - learning_rate: 6.2500e-06\n",
      "Epoch 340/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9612 - loss: 0.8141 - val_accuracy: 0.9514 - val_loss: 0.8716 - learning_rate: 6.2500e-06\n",
      "Epoch 341/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9473 - loss: 0.8430 - val_accuracy: 0.9514 - val_loss: 0.8518 - learning_rate: 6.2500e-06\n",
      "Epoch 342/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9541 - loss: 0.8102 - val_accuracy: 0.9583 - val_loss: 0.8509 - learning_rate: 6.2500e-06\n",
      "Epoch 343/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9505 - loss: 0.8197 - val_accuracy: 0.9514 - val_loss: 0.8547 - learning_rate: 6.2500e-06\n",
      "Epoch 344/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9479 - loss: 0.8417 - val_accuracy: 0.9514 - val_loss: 0.8609 - learning_rate: 6.2500e-06\n",
      "Epoch 345/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9630 - loss: 0.8333 - val_accuracy: 0.9514 - val_loss: 0.8633 - learning_rate: 6.2500e-06\n",
      "Epoch 346/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9465 - loss: 0.8474 - val_accuracy: 0.9514 - val_loss: 0.8566 - learning_rate: 6.2500e-06\n",
      "Epoch 347/1000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9622 - loss: 0.8617 - val_accuracy: 0.9583 - val_loss: 0.8430 - learning_rate: 6.2500e-06\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# TensorBoard callback for logging\n",
    "log_dir = os.path.join(create_log_dir(os.path.join(\"../logs\"), True))\n",
    "\n",
    "tensor_board_cb = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# train the model with the callbacks\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensor_board_cb, early_stopping, early_stopping_by_loss_val, reduce_lr],\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_filename(directory, base_name, extension):\n",
    "    # list all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    # filter files that start with the base_name and end with the extension\n",
    "    relevant_files = [\n",
    "        f for f in files if f.startswith(base_name) and f.endswith(extension)\n",
    "    ]\n",
    "\n",
    "    if not relevant_files and base_name == \"asl-action-weight\":\n",
    "        # if no relevant files found, start with 001\n",
    "        return f\"{base_name}-001.{extension}\"\n",
    "\n",
    "    if not base_name == \"asl-action-weight\":\n",
    "        return f\"{base_name}.{extension}\"\n",
    "\n",
    "    # extract the numeric part and find the highest number\n",
    "    numbers = [int(f[len(base_name) + 1 : -len(extension) - 1]) for f in relevant_files]\n",
    "    next_number = max(numbers) + 1\n",
    "\n",
    "    # format the next number with leading zeros to maintain the same length\n",
    "    next_filename = f\"{base_name}-{next_number:03d}.{extension}\"\n",
    "    return next_filename\n",
    "\n",
    "\n",
    "def model_save(\n",
    "    model, directory=\"../models/legacy\", base_name=\"asl-action-weight\", extension=\"h5\"\n",
    "):\n",
    "    next_filename = get_next_filename(directory, base_name, extension)\n",
    "    model_path = os.path.join(directory, next_filename)\n",
    "\n",
    "    if extension == \"tflite\":\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "        # See issue here:\n",
    "        # - https://github.com/tensorflow/tensorflow/issues/26869\n",
    "        # - https://github.com/tensorflow/tensorflow/issues/26869#issuecomment-474984631\n",
    "        # - https://github.com/tensorflow/tensorflow/issues/61662\n",
    "        # - https://stackoverflow.com/a/67252118/14182545\n",
    "        converter.target_spec.supported_ops = [\n",
    "            tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "            tf.lite.OpsSet.SELECT_TF_OPS,  # enable TensorFlow ops.\n",
    "        ]\n",
    "\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        print(f\"Model saved as {next_filename}\")\n",
    "        return\n",
    "\n",
    "    save_model(model, model_path)\n",
    "\n",
    "    print(f\"Model saved as {next_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e4-2.9M.keras\n",
      "Model saved as asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e4-2.9M.h5\n"
     ]
    }
   ],
   "source": [
    "model_save(model, directory=\"../models/keras\", base_name=\"asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e4-2.9M\", extension=\"keras\")\n",
    "model_save(model, directory=\"../models/legacy\", base_name=\"asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e4-2.9M\", extension=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\onedrive\\dokumen\\jo\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9513888888888888\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(ACTIONS))\n",
    "plt.xticks(tick_marks, ACTIONS, rotation=45)\n",
    "plt.yticks(tick_marks, ACTIONS)\n",
    "\n",
    "# add labels\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# compute and print accuracy score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
