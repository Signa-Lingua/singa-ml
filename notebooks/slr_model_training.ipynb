{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import (Callback,  # type: ignore\n",
    "                                        EarlyStopping, ReduceLROnPlateau,\n",
    "                                        TensorBoard)\n",
    "from tensorflow.keras.optimizers import Adam  # type: ignore\n",
    "from tensorflow.keras.regularizers import l2  # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up for data training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions to be trained\n",
    "ACTIONS = [\n",
    "    \"_\", \"hello\", \"what's up\", \"how\",\n",
    "    \"thanks\", \"you\", \"morning\", \"afternoon\",\n",
    "    \"night\", \"me\", \"name\", \"fine\",\n",
    "    \"happy\", \"yes\", \"no\", \"repeat\",\n",
    "    \"please\", \"want\", \"good bye\", \"learn\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_path = os.path.join(\"w:/machine-learning/sign-language-batched/combined_sequences.npy\")\n",
    "lab_path = os.path.join(\"w:/machine-learning/sign-language-batched/combined_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the combined dataset\n",
    "combined_sequences, combined_labels = np.load(seq_path), np.load(lab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 4800)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_sequences), len(combined_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjusting the Augmentation Factor**\n",
    "\n",
    "If you want to achieve a specific total number of sequences, you can adjust N<sub>augmented_per_original</sub>\n",
    "\n",
    "- Desired N<sub>total</sub> = 1920\n",
    "- Original N<sub>original</sub> = 480 (without augmentation)\n",
    "\n",
    "Using the formula to find N<sub>augmented_per_original</sub> :\n",
    "- 1920 = 480 + (480 × N<sub>augmented_per_original</sub>)\n",
    "\n",
    "Subtract 480 from both sides :\n",
    "- 1440 = 480 × N<sub>augmented_per_original</sub>\n",
    "\n",
    "Divide both sides by 480 :\n",
    "- N<sub>augmented_per_original</sub> = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "datas = np.array(combined_sequences)\n",
    "\n",
    "# convert labels list to a one-hot encoded NumPy array\n",
    "labels = to_categorical(combined_labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free up memory\n",
    "import gc\n",
    "\n",
    "# we do not need this variable again\n",
    "# so we can just remove it to freed up some memory\n",
    "del combined_sequences\n",
    "del combined_labels\n",
    "\n",
    "# force garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 4800)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the length of the datas and labels should be the same\n",
    "len(datas), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of the datasets depend on the total number of sequences and the sequence length. Here we processes 120 sequence of videos for each of the 4 actions, we have:\n",
    "\n",
    "    Total sequences = 120 sequences/action × 4 actions = 480 sequences\n",
    "\n",
    "Given a test_size of 0.2, 20% of the data (approximately 96 sequences) will be in the test set, and 80% (approximately 384 sequences) will be in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840, 60, 225) (960, 60, 225) (3840, 20) (960, 20)\n"
     ]
    }
   ],
   "source": [
    "# splits the dataset into training and testing sets\n",
    "\n",
    "# specifies that 20% of the data should be used as the test set,\n",
    "# and the remaining 80% should be used as the training set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(datas, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap found between training and test sets.\n"
     ]
    }
   ],
   "source": [
    "# convert arrays to a set of string representations for faster lookup\n",
    "X_train_str = set(map(str, X_train))\n",
    "X_test_str = set(map(str, X_test))\n",
    "\n",
    "# find the intersection\n",
    "overlap = X_train_str.intersection(X_test_str)\n",
    "\n",
    "# assert that there are no overlaps\n",
    "assert len(overlap) == 0, \"Training and Test sets overlap!\"\n",
    "\n",
    "if len(overlap) == 0:\n",
    "    print(\"No overlap found between training and test sets.\")\n",
    "else:\n",
    "    print(\"Overlap found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory\n",
    "import gc\n",
    "\n",
    "# we do not need this variable again\n",
    "# so we can just remove it to freed up some memory\n",
    "del datas\n",
    "del labels\n",
    "\n",
    "# force garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong Output Example : `(384, 60, 225) (96, 60, 225) (384, 4, 2) (96, 4, 2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_rnn_model(input_shape, num_classes):\n",
    "    # Input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape, name=\"input_layer_1\")\n",
    "\n",
    "    # Batch normalization\n",
    "    x = tf.keras.layers.BatchNormalization()(inputs)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(\n",
    "        16, kernel_size=2, activation=\"relu\", kernel_regularizer=l2(0.01)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Conv1D(\n",
    "        32, kernel_size=2, activation=\"relu\", kernel_regularizer=l2(0.01)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Conv1D(\n",
    "        64, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.01)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "    # Reshape layer\n",
    "    x = tf.keras.layers.Reshape((6, 64))(x)\n",
    "\n",
    "    # Bidirectional LSTM layers\n",
    "    x = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64, activation=\"relu\", return_sequences=True)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation=\"relu\"))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    # dense layers\n",
    "    x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # output layer\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # create model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# where 60 is the sequence length\n",
    "# and 225 is the number of features (keypoints) per frame\n",
    "input_shape = (60, 225)\n",
    "num_classes = len(ACTIONS)\n",
    "\n",
    "# create the model\n",
    "model = create_cnn_rnn_model(input_shape, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up callbacks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_dir(base_dir, use_time=False):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # check existing log directories\n",
    "    existing_logs = [\n",
    "        d\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"train-\")\n",
    "    ]\n",
    "\n",
    "    # determine the new log directory name\n",
    "    if existing_logs and not use_time:\n",
    "        latest_log = max(existing_logs)\n",
    "        log_num = int(latest_log.split(\"-\")[1]) + 1\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{str(log_num).zfill(3)}\")\n",
    "\n",
    "    if not existing_logs and not use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-001\")\n",
    "\n",
    "    if use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{current_time}\")\n",
    "\n",
    "    # create the new log directory\n",
    "    os.makedirs(new_log_dir)\n",
    "    print(f\"Created new log directory: {new_log_dir}\")\n",
    "\n",
    "    return new_log_dir\n",
    "\n",
    "\n",
    "# callback for logging\n",
    "log_dir = os.path.join(create_log_dir(os.path.join(\"../storage/logs\"), True))\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the optimizer with an initial learning rate\n",
    "optimizer = Adam(learning_rate=1e-3, clipnorm=1.0)\n",
    "\n",
    "# compile the model with the optimizer\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=50, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=5, min_lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# train the model with the callbacks\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=ACTIONS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(ACTIONS))\n",
    "plt.xticks(tick_marks, ACTIONS, rotation=45)\n",
    "plt.yticks(tick_marks, ACTIONS)\n",
    "\n",
    "# add labels\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# compute and print accuracy score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_filename(directory, base_name, extension):\n",
    "    # list all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # filter files that start with the base_name and end with the extension\n",
    "    versions = [f for f in files if f.startswith(base_name) and f.endswith(extension)]\n",
    "\n",
    "    # if the models directory is empty, then use the\n",
    "    # default start version (001)\n",
    "    if not versions and base_name == \"singa_slr_v_\":\n",
    "        return f\"{base_name}001.{extension}\"\n",
    "\n",
    "    # if the fiven basename is different than the actual basename\n",
    "    # then save the model with given name\n",
    "    if not base_name == \"singa_slr_v_\":\n",
    "        return f\"{base_name}.{extension}\"\n",
    "\n",
    "    # extract version numbers from filenames\n",
    "    versions = [file.split(\"_\")[-1] for file in versions]\n",
    "\n",
    "    # convert version numbers to tuples of integers for comparison\n",
    "    versions_int = [int(v.split(\".\")[0]) for v in versions]\n",
    "\n",
    "    next_version = max(versions_int) + 1\n",
    "\n",
    "    # format the next number with leading zeros to maintain the same length\n",
    "    next_filename = f\"{base_name}{next_version:03d}.{extension}\"\n",
    "\n",
    "    return next_filename\n",
    "\n",
    "\n",
    "def save_as_tflite(_model, model_path):\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # export the model to the temporary directory\n",
    "        export_path = os.path.join(temp_dir, \"_tf_temp\")\n",
    "\n",
    "        _model.export(export_path)\n",
    "\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
    "        # enable resource variables and selective ops to handle the conversion issues\n",
    "        converter.experimental_enable_resource_variables = True\n",
    "        converter.target_spec.supported_ops = [\n",
    "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "            tf.lite.OpsSet.SELECT_TF_OPS,\n",
    "        ]\n",
    "        converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def save_as_keras(_model, model_path):\n",
    "    _model.save(model_path)\n",
    "\n",
    "\n",
    "def save_model(_model, extension=\"keras\", base_name=\"singa_slr_v_\"):\n",
    "    model_dir = \"../storage/models/\" + extension\n",
    "\n",
    "    next_filename = get_next_filename(model_dir, base_name, extension)\n",
    "    model_path = os.path.join(model_dir, next_filename)\n",
    "\n",
    "    match extension:\n",
    "        case \"tflite\":\n",
    "            save_as_tflite(_model, model_path)\n",
    "            print(f\"saved as tflite at {model_path}\")\n",
    "\n",
    "        case \"keras\":\n",
    "            save_as_keras(_model, model_path)\n",
    "            print(f\"saved as keras at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, extension=\"tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory\n",
    "import gc\n",
    "\n",
    "# we do not need this variable again\n",
    "# so we can just remove it to freed up some memory\n",
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test\n",
    "\n",
    "# force garbage collection\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
