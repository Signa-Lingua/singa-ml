{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models  # type: ignore\n",
    "from tensorflow.keras.callbacks import (Callback,  # type: ignore\n",
    "                                        EarlyStopping, ReduceLROnPlateau,\n",
    "                                        TensorBoard)\n",
    "from tensorflow.keras.optimizers import Adam  # type: ignore\n",
    "from tensorflow.keras.regularizers import l2  # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up for data training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocssed dataset path\n",
    "DATASET_PATH = os.path.join(\"../storage/datasets/cleaned\")\n",
    "\n",
    "# actions to be detected\n",
    "ACTIONS = [\n",
    "    \"_\", \"hello\", \"thanks\", \"i-love-you\", \"see-you-later\", \"I\", \"Father\", \"Mother\", \"Yes\",\n",
    "    \"No\", \"Help\", \"Please\", \"Want\", \"What\", \"Again\", \"Eat\", \"Milk\", \"More\", \"Go To\",\n",
    "    \"Bathroom\", \"Fine\", \"Like\", \"Learn\", \"Sign\", \"Done\"\n",
    "]\n",
    "\n",
    "# limit to first x actions for testing\n",
    "ACTIONS = np.array(ACTIONS[:4])\n",
    "\n",
    "# number of videos and actions per video\n",
    "videos_per_label = 120\n",
    "frames_per_video = 60\n",
    "\n",
    "# data labels\n",
    "labels_map = {label: index for index, label in enumerate(ACTIONS)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(landmarks, noise_level, shape=(60, 225)):\n",
    "    noise = np.random.normal(loc=0, scale=noise_level, size=shape)\n",
    "    return landmarks + noise\n",
    "\n",
    "\n",
    "def shift_landmarks(landmarks, shift_factor, shape=(60, 225)):\n",
    "    shift = np.random.uniform(-shift_factor, shift_factor, size=shape[1:])\n",
    "    return landmarks + shift\n",
    "\n",
    "\n",
    "def augment_landmarks(landmarks, noise_level=0.01, shift_factor=0.1):\n",
    "    if random.random() > 0.5:\n",
    "        landmarks = add_noise(landmarks, noise_level)\n",
    "\n",
    "    if random.random() > 0.5:\n",
    "        landmarks = shift_landmarks(landmarks, shift_factor)\n",
    "\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_path = os.path.join(\"./data\", \"sequences.npy\")\n",
    "lab_path = os.path.join(\"./data\", \"labels.npy\")\n",
    "\n",
    "sequences, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA IS BEING LOADED\n"
     ]
    }
   ],
   "source": [
    "def generate_bulk_dataset_and_load(augment=True):\n",
    "    sequences, labels = [], []\n",
    "\n",
    "    for action in ACTIONS:\n",
    "        window = []\n",
    "        window_labels = []\n",
    "\n",
    "        \"\"\"Iterates over each sequence for the current action\"\"\"\n",
    "        for sequence in range(videos_per_label):\n",
    "            \"\"\"\n",
    "            Frame Processing\n",
    "\n",
    "            Iterates over each frame in the current sequence, then constructs the file path to the numpy array for the current frame.\n",
    "            Prints the path to verify correctness, then loads the frame data from the numpy file.\n",
    "            \"\"\"\n",
    "            # construct the path to the numpy file for the current frame\n",
    "            npy_path = os.path.join(DATASET_PATH, action, \"{}.npy\".format(sequence))\n",
    "\n",
    "            # load the frame data from the numpy file\n",
    "            result = np.load(npy_path)\n",
    "\n",
    "            # append the completed sequence to the sequences list\n",
    "            window.append(result)\n",
    "\n",
    "            # append the corresponding label to the labels list\n",
    "            window_labels.append(labels_map[action])\n",
    "\n",
    "            if not augment:\n",
    "                continue\n",
    "\n",
    "            # number of augmented window to create per original sequence\n",
    "            num_augmented_sequences = int(0.1 * 60)  # 10% of total of video\n",
    "\n",
    "            for _ in range(num_augmented_sequences):\n",
    "                augmented_sequence = [\n",
    "                    augment_landmarks(frame, noise_level=0.047, shift_factor=0.47)\n",
    "                    for frame in window\n",
    "                ]\n",
    "\n",
    "                # append the augmented to the window list\n",
    "                window.append(augmented_sequence[0])\n",
    "\n",
    "                window_labels.append(labels_map[action])\n",
    "\n",
    "            print(f\"{action} - {sequence}\")\n",
    "\n",
    "        sequences.append(window)\n",
    "        labels.append(window_labels)\n",
    "\n",
    "    keypoints = np.concatenate([s for s in sequences])\n",
    "    key_label = np.concatenate([l for l in labels])\n",
    "\n",
    "    # save the original sequences and labels\n",
    "    np.save(seq_path, keypoints)\n",
    "    np.save(lab_path, key_label)\n",
    "\n",
    "    return keypoints, key_label\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    if os.path.exists(seq_path) and os.path.exists(lab_path):\n",
    "        print(\"DATA IS BEING LOADED\")\n",
    "\n",
    "        sequences = np.load(seq_path, allow_pickle=True)\n",
    "        labels = np.load(lab_path, allow_pickle=True)\n",
    "\n",
    "        return sequences, labels\n",
    "\n",
    "    print(\"DATA IS BEING GENERATED AND LOADED\")\n",
    "\n",
    "    return generate_bulk_dataset_and_load(augment=True)\n",
    "\n",
    "\n",
    "sequences, labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 3360)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjusting the Augmentation Factor**\n",
    "\n",
    "If you want to achieve a specific total number of sequences, you can adjust N<sub>augmented_per_original</sub>\n",
    "\n",
    "- Desired N<sub>total</sub> = 1920\n",
    "- Original N<sub>original</sub> = 480 (without augmentation)\n",
    "\n",
    "Using the formula to find N<sub>augmented_per_original</sub> :\n",
    "- 1920 = 480 + (480 × N<sub>augmented_per_original</sub>)\n",
    "\n",
    "Subtract 480 from both sides :\n",
    "- 1440 = 480 × N<sub>augmented_per_original</sub>\n",
    "\n",
    "Divide both sides by 480 :\n",
    "- N<sub>augmented_per_original</sub> = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "datas = np.array(sequences)\n",
    "\n",
    "# convert labels list to a one-hot encoded NumPy array\n",
    "labels = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 3360)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the length of the datas and labels should be the same\n",
    "len(datas), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of the datasets depend on the total number of sequences and the sequence length. Here we processes 120 sequence of videos for each of the 4 actions, we have:\n",
    "\n",
    "    Total sequences = 120 sequences/action × 4 actions = 480 sequences\n",
    "\n",
    "Given a test_size of 0.2, 20% of the data (approximately 96 sequences) will be in the test set, and 80% (approximately 384 sequences) will be in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2688, 60, 225) (672, 60, 225) (2688, 4) (672, 4)\n"
     ]
    }
   ],
   "source": [
    "# splits the dataset into training and testing sets\n",
    "\n",
    "# specifies that 20% of the data should be used as the test set,\n",
    "# and the remaining 80% should be used as the training set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(datas, labels, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong Output Example : `(384, 60, 225) (96, 60, 225) (384, 4, 2) (96, 4, 2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # augment the training data\n",
    "# X_train_augmented, y_train_augmented = augment_train_test_data(X_train, y_train)\n",
    "\n",
    "# # convert the test data to the required format\n",
    "# X_test = np.array(X_test)\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "# print(X_train_augmented.shape, X_test.shape, y_train_augmented.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">900</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">58</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">43,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m225\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m225\u001b[0m)        │           \u001b[38;5;34m900\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m58\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m43,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,688</span> (561.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m143,688\u001b[0m (561.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,238</span> (559.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m143,238\u001b[0m (559.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> (1.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m450\u001b[0m (1.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_cnn_rnn_model(input_shape, num_classes):\n",
    "    # the input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # BatchNormalization layer to normalize input data\n",
    "    batch = tf.keras.layers.BatchNormalization()(inputs)\n",
    "\n",
    "    # CNN tf.keras.layers to extract spatial features\n",
    "    cnn = tf.keras.layers.Conv1D(64, 3, activation=\"relu\", kernel_regularizer=l2(0.02))(\n",
    "        batch\n",
    "    )\n",
    "    x = tf.keras.layers.MaxPooling1D(2)(cnn)\n",
    "\n",
    "    # CNN tf.keras.layers to extract spatial features\n",
    "    cnn = tf.keras.layers.Conv1D(\n",
    "        128, 3, activation=\"relu\", kernel_regularizer=l2(0.02)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(cnn)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=l2(0.02))(cnn)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    rnn = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation=\"relu\"))(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=l2(0.02))(rnn)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=l2(0.02))(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(rnn)\n",
    "\n",
    "    # create the model\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# where 60 is the sequence length\n",
    "# and 225 is the number of features (keypoints) per frame\n",
    "input_shape = (60, 225)\n",
    "num_classes = ACTIONS.shape[0]  # N gesture classes\n",
    "\n",
    "# Create the model\n",
    "model = create_cnn_rnn_model(input_shape, num_classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up callbacks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new log directory: ../storage/logs\\train-20240610-190846\n"
     ]
    }
   ],
   "source": [
    "def create_log_dir(base_dir, use_time=False):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # check existing log directories\n",
    "    existing_logs = [\n",
    "        d\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"train-\")\n",
    "    ]\n",
    "\n",
    "    # determine the new log directory name\n",
    "    if existing_logs and not use_time:\n",
    "        latest_log = max(existing_logs)\n",
    "        log_num = int(latest_log.split(\"-\")[1]) + 1\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{str(log_num).zfill(3)}\")\n",
    "\n",
    "    if not existing_logs and not use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-001\")\n",
    "\n",
    "    if use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{current_time}\")\n",
    "\n",
    "    # create the new log directory\n",
    "    os.makedirs(new_log_dir)\n",
    "    print(f\"Created new log directory: {new_log_dir}\")\n",
    "\n",
    "    return new_log_dir\n",
    "\n",
    "# callback for logging\n",
    "log_dir = os.path.join(create_log_dir(os.path.join(\"../storage/logs\"), True))\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the optimizer with an initial learning rate\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "# compile the model with the optimizer\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=30, restore_best_weights=True\n",
    ")\n",
    "\n",
    "es_acc = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=50,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.3394 - loss: 6.5982 - val_accuracy: 0.4747 - val_loss: 6.1387 - learning_rate: 1.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7105 - loss: 5.8122 - val_accuracy: 0.7991 - val_loss: 5.4108 - learning_rate: 1.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8291 - loss: 4.9337 - val_accuracy: 0.8646 - val_loss: 4.6934 - learning_rate: 1.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8871 - loss: 4.3830 - val_accuracy: 0.8869 - val_loss: 4.2302 - learning_rate: 1.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9268 - loss: 4.0319 - val_accuracy: 0.9003 - val_loss: 3.9685 - learning_rate: 1.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9421 - loss: 3.7796 - val_accuracy: 0.8988 - val_loss: 3.7840 - learning_rate: 1.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9523 - loss: 3.5658 - val_accuracy: 0.9003 - val_loss: 3.6258 - learning_rate: 1.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9580 - loss: 3.4088 - val_accuracy: 0.9077 - val_loss: 3.4867 - learning_rate: 1.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9744 - loss: 3.2278 - val_accuracy: 0.9077 - val_loss: 3.4009 - learning_rate: 1.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9810 - loss: 3.0870 - val_accuracy: 0.9107 - val_loss: 3.2705 - learning_rate: 1.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9809 - loss: 2.9558 - val_accuracy: 0.9062 - val_loss: 3.2436 - learning_rate: 1.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 2.8153 - val_accuracy: 0.9211 - val_loss: 3.0297 - learning_rate: 1.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9851 - loss: 2.7088 - val_accuracy: 0.9211 - val_loss: 2.9179 - learning_rate: 1.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 2.5950 - val_accuracy: 0.9211 - val_loss: 2.8192 - learning_rate: 1.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 2.4931 - val_accuracy: 0.9152 - val_loss: 2.8041 - learning_rate: 1.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9920 - loss: 2.3767 - val_accuracy: 0.9092 - val_loss: 2.7075 - learning_rate: 1.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9930 - loss: 2.2917 - val_accuracy: 0.9211 - val_loss: 2.5994 - learning_rate: 1.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9898 - loss: 2.2076 - val_accuracy: 0.9182 - val_loss: 2.5035 - learning_rate: 1.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 2.1164 - val_accuracy: 0.9196 - val_loss: 2.4747 - learning_rate: 1.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9935 - loss: 2.0394 - val_accuracy: 0.9137 - val_loss: 2.3983 - learning_rate: 1.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9877 - loss: 1.9796 - val_accuracy: 0.9182 - val_loss: 2.2853 - learning_rate: 1.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 1.8975 - val_accuracy: 0.9211 - val_loss: 2.2489 - learning_rate: 1.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9943 - loss: 1.8239 - val_accuracy: 0.9256 - val_loss: 2.1997 - learning_rate: 1.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 1.7611 - val_accuracy: 0.9182 - val_loss: 2.0914 - learning_rate: 1.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9936 - loss: 1.6852 - val_accuracy: 0.9226 - val_loss: 2.0302 - learning_rate: 1.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9961 - loss: 1.6202 - val_accuracy: 0.9137 - val_loss: 2.0595 - learning_rate: 1.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9805 - loss: 1.6032 - val_accuracy: 0.9092 - val_loss: 1.9199 - learning_rate: 1.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9957 - loss: 1.5217 - val_accuracy: 0.9315 - val_loss: 1.8499 - learning_rate: 1.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9980 - loss: 1.4631 - val_accuracy: 0.9315 - val_loss: 1.8521 - learning_rate: 1.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9906 - loss: 1.4270 - val_accuracy: 0.9182 - val_loss: 1.8342 - learning_rate: 1.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9955 - loss: 1.3689 - val_accuracy: 0.9196 - val_loss: 1.7761 - learning_rate: 1.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9881 - loss: 1.3525 - val_accuracy: 0.9122 - val_loss: 1.6644 - learning_rate: 1.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9969 - loss: 1.2829 - val_accuracy: 0.9256 - val_loss: 1.6855 - learning_rate: 1.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9990 - loss: 1.2352 - val_accuracy: 0.9226 - val_loss: 1.6726 - learning_rate: 1.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9969 - loss: 1.1933 - val_accuracy: 0.9271 - val_loss: 1.6267 - learning_rate: 1.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9974 - loss: 1.1532 - val_accuracy: 0.8988 - val_loss: 1.5932 - learning_rate: 1.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9893 - loss: 1.1385 - val_accuracy: 0.9241 - val_loss: 1.4762 - learning_rate: 1.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9981 - loss: 1.0727 - val_accuracy: 0.9182 - val_loss: 1.4483 - learning_rate: 1.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9969 - loss: 1.0432 - val_accuracy: 0.9182 - val_loss: 1.3988 - learning_rate: 1.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9917 - loss: 1.0263 - val_accuracy: 0.9271 - val_loss: 1.3609 - learning_rate: 1.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9980 - loss: 0.9786 - val_accuracy: 0.9345 - val_loss: 1.3497 - learning_rate: 1.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9974 - loss: 0.9436 - val_accuracy: 0.9256 - val_loss: 1.3771 - learning_rate: 1.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9957 - loss: 0.9118 - val_accuracy: 0.9226 - val_loss: 1.3944 - learning_rate: 1.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9891 - loss: 0.8965 - val_accuracy: 0.9167 - val_loss: 1.3659 - learning_rate: 1.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9957 - loss: 0.8578 - val_accuracy: 0.9182 - val_loss: 1.3260 - learning_rate: 1.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9927 - loss: 0.8374 - val_accuracy: 0.9301 - val_loss: 1.2121 - learning_rate: 1.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9959 - loss: 0.8051 - val_accuracy: 0.9286 - val_loss: 1.2188 - learning_rate: 1.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9967 - loss: 0.7792 - val_accuracy: 0.9241 - val_loss: 1.2342 - learning_rate: 1.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9986 - loss: 0.7438 - val_accuracy: 0.9241 - val_loss: 1.2082 - learning_rate: 1.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9972 - loss: 0.7220 - val_accuracy: 0.9286 - val_loss: 1.1530 - learning_rate: 1.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.6993 - val_accuracy: 0.9152 - val_loss: 1.1917 - learning_rate: 1.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9945 - loss: 0.6895 - val_accuracy: 0.9241 - val_loss: 1.0916 - learning_rate: 1.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9983 - loss: 0.6511 - val_accuracy: 0.9211 - val_loss: 1.1296 - learning_rate: 1.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9957 - loss: 0.6369 - val_accuracy: 0.9196 - val_loss: 1.1463 - learning_rate: 1.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9955 - loss: 0.6149 - val_accuracy: 0.9211 - val_loss: 1.0692 - learning_rate: 1.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9980 - loss: 0.5871 - val_accuracy: 0.9271 - val_loss: 1.0473 - learning_rate: 1.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.5674 - val_accuracy: 0.9256 - val_loss: 1.0356 - learning_rate: 1.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.5628 - val_accuracy: 0.9271 - val_loss: 0.9774 - learning_rate: 1.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9946 - loss: 0.5408 - val_accuracy: 0.9301 - val_loss: 0.9091 - learning_rate: 1.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9983 - loss: 0.5151 - val_accuracy: 0.9271 - val_loss: 0.9665 - learning_rate: 1.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9939 - loss: 0.5089 - val_accuracy: 0.9152 - val_loss: 0.9858 - learning_rate: 1.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9908 - loss: 0.5029 - val_accuracy: 0.9182 - val_loss: 0.8769 - learning_rate: 1.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9965 - loss: 0.4725 - val_accuracy: 0.9330 - val_loss: 0.8312 - learning_rate: 1.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9991 - loss: 0.4501 - val_accuracy: 0.9241 - val_loss: 0.8572 - learning_rate: 1.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9981 - loss: 0.4398 - val_accuracy: 0.9226 - val_loss: 0.8213 - learning_rate: 1.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9977 - loss: 0.4258 - val_accuracy: 0.9301 - val_loss: 0.8020 - learning_rate: 1.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9942 - loss: 0.4179 - val_accuracy: 0.9286 - val_loss: 0.8097 - learning_rate: 1.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9950 - loss: 0.4110 - val_accuracy: 0.9241 - val_loss: 0.8145 - learning_rate: 1.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.3847 - val_accuracy: 0.9196 - val_loss: 0.8438 - learning_rate: 1.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9966 - loss: 0.3744 - val_accuracy: 0.9256 - val_loss: 0.8138 - learning_rate: 1.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9972 - loss: 0.3598 - val_accuracy: 0.9167 - val_loss: 0.7893 - learning_rate: 1.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9959 - loss: 0.3578 - val_accuracy: 0.9301 - val_loss: 0.7264 - learning_rate: 1.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9986 - loss: 0.3358 - val_accuracy: 0.9301 - val_loss: 0.6901 - learning_rate: 1.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.3329 - val_accuracy: 0.9345 - val_loss: 0.7057 - learning_rate: 1.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9869 - loss: 0.3464 - val_accuracy: 0.9211 - val_loss: 0.7335 - learning_rate: 1.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9955 - loss: 0.3206 - val_accuracy: 0.9182 - val_loss: 0.8173 - learning_rate: 1.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.3040 - val_accuracy: 0.9152 - val_loss: 0.7419 - learning_rate: 1.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9952 - loss: 0.3092 - val_accuracy: 0.9226 - val_loss: 0.6685 - learning_rate: 1.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9975 - loss: 0.2921 - val_accuracy: 0.9152 - val_loss: 0.7062 - learning_rate: 1.0000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9997 - loss: 0.2715 - val_accuracy: 0.9196 - val_loss: 0.7298 - learning_rate: 1.0000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.2628 - val_accuracy: 0.9286 - val_loss: 0.6992 - learning_rate: 1.0000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9940 - loss: 0.2666 - val_accuracy: 0.9301 - val_loss: 0.6901 - learning_rate: 1.0000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9935 - loss: 0.2692 - val_accuracy: 0.9271 - val_loss: 0.6208 - learning_rate: 1.0000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9971 - loss: 0.2481 - val_accuracy: 0.9271 - val_loss: 0.6581 - learning_rate: 1.0000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 0.2449 - val_accuracy: 0.9256 - val_loss: 0.7164 - learning_rate: 1.0000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9967 - loss: 0.2348 - val_accuracy: 0.9286 - val_loss: 0.6577 - learning_rate: 1.0000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9977 - loss: 0.2271 - val_accuracy: 0.9286 - val_loss: 0.6705 - learning_rate: 1.0000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9938 - loss: 0.2321 - val_accuracy: 0.9182 - val_loss: 0.7442 - learning_rate: 1.0000e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9962 - loss: 0.2197 - val_accuracy: 0.9256 - val_loss: 0.6944 - learning_rate: 1.0000e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9951 - loss: 0.2183 - val_accuracy: 0.9301 - val_loss: 0.6657 - learning_rate: 1.0000e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9919 - loss: 0.2178 - val_accuracy: 0.9360 - val_loss: 0.5861 - learning_rate: 1.0000e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.1959 - val_accuracy: 0.9226 - val_loss: 0.6638 - learning_rate: 1.0000e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9974 - loss: 0.1920 - val_accuracy: 0.9315 - val_loss: 0.6447 - learning_rate: 1.0000e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9970 - loss: 0.1890 - val_accuracy: 0.9330 - val_loss: 0.6483 - learning_rate: 1.0000e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9959 - loss: 0.1898 - val_accuracy: 0.9211 - val_loss: 0.6993 - learning_rate: 1.0000e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9954 - loss: 0.1845 - val_accuracy: 0.9330 - val_loss: 0.6032 - learning_rate: 1.0000e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9962 - loss: 0.1783 - val_accuracy: 0.9286 - val_loss: 0.5799 - learning_rate: 1.0000e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9980 - loss: 0.1687 - val_accuracy: 0.9286 - val_loss: 0.6231 - learning_rate: 1.0000e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9961 - loss: 0.1703 - val_accuracy: 0.9286 - val_loss: 0.5752 - learning_rate: 1.0000e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9944 - loss: 0.1747 - val_accuracy: 0.9241 - val_loss: 0.5439 - learning_rate: 1.0000e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9962 - loss: 0.1625 - val_accuracy: 0.9211 - val_loss: 0.5757 - learning_rate: 1.0000e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 0.1577 - val_accuracy: 0.9345 - val_loss: 0.4913 - learning_rate: 1.0000e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9953 - loss: 0.1577 - val_accuracy: 0.9286 - val_loss: 0.4984 - learning_rate: 1.0000e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9969 - loss: 0.1486 - val_accuracy: 0.9315 - val_loss: 0.4870 - learning_rate: 1.0000e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 0.1482 - val_accuracy: 0.9167 - val_loss: 0.6130 - learning_rate: 1.0000e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9982 - loss: 0.1454 - val_accuracy: 0.9330 - val_loss: 0.5369 - learning_rate: 1.0000e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9938 - loss: 0.1431 - val_accuracy: 0.9226 - val_loss: 0.6032 - learning_rate: 1.0000e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.1592 - val_accuracy: 0.9330 - val_loss: 0.4698 - learning_rate: 1.0000e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9961 - loss: 0.1383 - val_accuracy: 0.9301 - val_loss: 0.4732 - learning_rate: 1.0000e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.1461 - val_accuracy: 0.9301 - val_loss: 0.4730 - learning_rate: 1.0000e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9959 - loss: 0.1329 - val_accuracy: 0.9315 - val_loss: 0.5159 - learning_rate: 1.0000e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9975 - loss: 0.1330 - val_accuracy: 0.9330 - val_loss: 0.5049 - learning_rate: 1.0000e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9955 - loss: 0.1333 - val_accuracy: 0.9301 - val_loss: 0.4626 - learning_rate: 1.0000e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9951 - loss: 0.1254 - val_accuracy: 0.9330 - val_loss: 0.4480 - learning_rate: 1.0000e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9979 - loss: 0.1196 - val_accuracy: 0.9345 - val_loss: 0.4954 - learning_rate: 1.0000e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9961 - loss: 0.1242 - val_accuracy: 0.9256 - val_loss: 0.5490 - learning_rate: 1.0000e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9964 - loss: 0.1228 - val_accuracy: 0.9390 - val_loss: 0.4483 - learning_rate: 1.0000e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9972 - loss: 0.1176 - val_accuracy: 0.9360 - val_loss: 0.4491 - learning_rate: 1.0000e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 0.1147 - val_accuracy: 0.9375 - val_loss: 0.4048 - learning_rate: 1.0000e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9956 - loss: 0.1135 - val_accuracy: 0.9345 - val_loss: 0.4159 - learning_rate: 1.0000e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.1081 - val_accuracy: 0.9420 - val_loss: 0.4207 - learning_rate: 1.0000e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9959 - loss: 0.1108 - val_accuracy: 0.9390 - val_loss: 0.4105 - learning_rate: 1.0000e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.1045 - val_accuracy: 0.9315 - val_loss: 0.4919 - learning_rate: 1.0000e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9978 - loss: 0.1018 - val_accuracy: 0.9315 - val_loss: 0.4890 - learning_rate: 1.0000e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9977 - loss: 0.1050 - val_accuracy: 0.9286 - val_loss: 0.4861 - learning_rate: 1.0000e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0984 - val_accuracy: 0.9286 - val_loss: 0.5015 - learning_rate: 1.0000e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9945 - loss: 0.1090 - val_accuracy: 0.9330 - val_loss: 0.4337 - learning_rate: 1.0000e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9919 - loss: 0.1126 - val_accuracy: 0.9345 - val_loss: 0.4490 - learning_rate: 1.0000e-04\n",
      "Epoch 129/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9967 - loss: 0.0983 - val_accuracy: 0.9390 - val_loss: 0.4386 - learning_rate: 1.0000e-04\n",
      "Epoch 130/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9986 - loss: 0.0937 - val_accuracy: 0.9405 - val_loss: 0.4307 - learning_rate: 5.0000e-05\n",
      "Epoch 131/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0909 - val_accuracy: 0.9435 - val_loss: 0.4550 - learning_rate: 5.0000e-05\n",
      "Epoch 132/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9998 - loss: 0.0887 - val_accuracy: 0.9405 - val_loss: 0.4776 - learning_rate: 5.0000e-05\n",
      "Epoch 133/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9990 - loss: 0.0882 - val_accuracy: 0.9375 - val_loss: 0.5099 - learning_rate: 5.0000e-05\n",
      "Epoch 134/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9974 - loss: 0.0902 - val_accuracy: 0.9420 - val_loss: 0.4775 - learning_rate: 5.0000e-05\n",
      "Epoch 135/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9993 - loss: 0.0863 - val_accuracy: 0.9420 - val_loss: 0.4502 - learning_rate: 5.0000e-05\n",
      "Epoch 136/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9997 - loss: 0.0839 - val_accuracy: 0.9390 - val_loss: 0.4726 - learning_rate: 5.0000e-05\n",
      "Epoch 137/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0839 - val_accuracy: 0.9360 - val_loss: 0.5318 - learning_rate: 5.0000e-05\n",
      "Epoch 138/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0847 - val_accuracy: 0.9405 - val_loss: 0.4955 - learning_rate: 5.0000e-05\n",
      "Epoch 139/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9990 - loss: 0.0808 - val_accuracy: 0.9449 - val_loss: 0.4455 - learning_rate: 5.0000e-05\n",
      "Epoch 140/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9999 - loss: 0.0791 - val_accuracy: 0.9539 - val_loss: 0.4395 - learning_rate: 2.5000e-05\n",
      "Epoch 141/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0787 - val_accuracy: 0.9509 - val_loss: 0.4406 - learning_rate: 2.5000e-05\n",
      "Epoch 142/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9991 - loss: 0.0787 - val_accuracy: 0.9464 - val_loss: 0.4478 - learning_rate: 2.5000e-05\n",
      "Epoch 143/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0771 - val_accuracy: 0.9464 - val_loss: 0.4447 - learning_rate: 2.5000e-05\n",
      "Epoch 144/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0760 - val_accuracy: 0.9420 - val_loss: 0.4763 - learning_rate: 2.5000e-05\n",
      "Epoch 145/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0750 - val_accuracy: 0.9435 - val_loss: 0.4703 - learning_rate: 2.5000e-05\n",
      "Epoch 146/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9996 - loss: 0.0745 - val_accuracy: 0.9464 - val_loss: 0.4592 - learning_rate: 2.5000e-05\n",
      "Epoch 147/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0738 - val_accuracy: 0.9509 - val_loss: 0.4699 - learning_rate: 2.5000e-05\n",
      "Epoch 148/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0730 - val_accuracy: 0.9420 - val_loss: 0.4753 - learning_rate: 2.5000e-05\n",
      "Epoch 149/300\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0720 - val_accuracy: 0.9420 - val_loss: 0.4830 - learning_rate: 2.5000e-05\n",
      "Restoring model weights from the end of the best epoch: 140.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# train the model with the callbacks\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=300,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[logging, early_stopping, es_acc, lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0772\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_train, y_train)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9538690476190477\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(ACTIONS))\n",
    "plt.xticks(tick_marks, ACTIONS, rotation=45)\n",
    "plt.yticks(tick_marks, ACTIONS)\n",
    "\n",
    "# add labels\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# compute and print accuracy score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_filename(directory, base_name, extension):\n",
    "    # list all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # filter files that start with the base_name and end with the extension\n",
    "    versions = [f for f in files if f.startswith(base_name) and f.endswith(extension)]\n",
    "\n",
    "    # if the models directory is empty, then use the\n",
    "    # default start version (001)\n",
    "    if not versions and base_name == \"singa_slr_v_\":\n",
    "        return f\"{base_name}001.{extension}\"\n",
    "\n",
    "    # if the fiven basename is different than the actual basename\n",
    "    # then save the model with given name\n",
    "    if not base_name == \"singa_slr_v_\":\n",
    "        return f\"{base_name}.{extension}\"\n",
    "\n",
    "    # extract version numbers from filenames\n",
    "    versions = [file.split(\"_\")[-1] for file in versions]\n",
    "\n",
    "    # convert version numbers to tuples of integers for comparison\n",
    "    versions_int = [int(v.split(\".\")[0]) for v in versions]\n",
    "\n",
    "    next_version = max(versions_int) + 1\n",
    "\n",
    "    # format the next number with leading zeros to maintain the same length\n",
    "    next_filename = f\"{base_name}{next_version:03d}.{extension}\"\n",
    "\n",
    "    return next_filename\n",
    "\n",
    "\n",
    "def save_as_tflite(_model, model_path):\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # export the model to the temporary directory\n",
    "        export_path = os.path.join(temp_dir, \"_tf_temp\")\n",
    "\n",
    "        _model.export(export_path)\n",
    "\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
    "        # Enable resource variables and selective ops to handle the conversion issues\n",
    "        converter.experimental_enable_resource_variables = True\n",
    "        converter.target_spec.supported_ops = [\n",
    "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "            tf.lite.OpsSet.SELECT_TF_OPS,\n",
    "        ]\n",
    "        converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def save_as_keras(_model, model_path):\n",
    "    _model.save(model_path)\n",
    "\n",
    "\n",
    "def save_model(_model, extension=\"keras\", base_name=\"singa_slr_v_\"):\n",
    "    model_dir = \"../storage/models/\" + extension\n",
    "\n",
    "    next_filename = get_next_filename(model_dir, base_name, extension)\n",
    "    model_path = os.path.join(model_dir, next_filename)\n",
    "\n",
    "    match extension:\n",
    "        case \"tflite\":\n",
    "            save_as_tflite(_model, model_path)\n",
    "            print(f\"saved as tflite at {model_path}\")\n",
    "\n",
    "        case \"keras\":\n",
    "            save_as_keras(_model, model_path)\n",
    "            print(f\"saved as keras at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as keras at ../storage/models/keras\\singa_slr_v_001.keras\n"
     ]
    }
   ],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\acer\\AppData\\Local\\Temp\\tmpis0yvzxb\\_tf_temp\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\acer\\AppData\\Local\\Temp\\tmpis0yvzxb\\_tf_temp\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\acer\\AppData\\Local\\Temp\\tmpis0yvzxb\\_tf_temp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 60, 225), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1806568266336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568267392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568262112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568259824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568269680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568269504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568273376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568275664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568606000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568605120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568618672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568850528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568849472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568851408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568853872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568855104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1806568864080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1807674458528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "saved as tflite at ../storage/models/tflite\\singa_slr_v_001.tflite\n"
     ]
    }
   ],
   "source": [
    "save_model(model, extension=\"tflite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
