{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import tensorflow as tf # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path for saving the data (numpy array)\n",
    "DATA_PATH = os.path.join(\"../datasets\")\n",
    "\n",
    "# sign action to be detected\n",
    "ACTIONS = np.array(\n",
    "    [\n",
    "        \"hello\",\n",
    "        \"thanks\",\n",
    "        \"i-love-you\",\n",
    "        \"see-you-later\",\n",
    "        \"I\",\n",
    "        \"Father\",\n",
    "        \"Mother\",\n",
    "        \"Yes\",\n",
    "        \"No\",\n",
    "        \"Help\",\n",
    "        \"Please\",\n",
    "        \"Want\",\n",
    "        \"What\",\n",
    "        \"Again\",\n",
    "        \"Eat\",\n",
    "        \"Milk\",\n",
    "        \"More\",\n",
    "        \"Go To\",\n",
    "        \"Bathroom\",\n",
    "        \"Fine\",\n",
    "        \"Like\",\n",
    "        \"Learn\",\n",
    "        \"Sign\",\n",
    "        \"Done\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# NOTE: use the first 6 since we only have 6 label only for now\n",
    "ACTIONS = ACTIONS[:6]\n",
    "\n",
    "# x videos worth of data (per label)\n",
    "videos_per_label = np.max(np.array(os.listdir(os.path.join(DATA_PATH, ACTIONS[0]))).astype(int)) + 1\n",
    "\n",
    "# 30 action per videos\n",
    "# NOTE: This does not affect how much the frame is\n",
    "action_per_video = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', 'thanks', 'i-love-you', 'see-you-later', 'I', 'Father'],\n",
       "      dtype='<U13')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output example:\n",
    "# {'hello': 0, 'thanks': 1, 'i-love-you': 2}\n",
    "labels_map = {label: index for index, label in enumerate(ACTIONS)}\n",
    "\n",
    "sequences, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'hello': 0,\n",
       "  'thanks': 1,\n",
       "  'i-love-you': 2,\n",
       "  'see-you-later': 3,\n",
       "  'I': 4,\n",
       "  'Father': 5},\n",
       " 60)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_map, videos_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterates over each action in the ACTIONS list.\n",
    "\n",
    "For each action, it will process multiple sequences of frames.\n",
    "\"\"\"\n",
    "for action in ACTIONS:\n",
    "\n",
    "    \"\"\"Iterates over each sequence for the current action\"\"\"\n",
    "    for sequence in range(videos_per_label):\n",
    "        # empty list (window) to hold the frames of the current sequence.\n",
    "        sequence_actions = []\n",
    "\n",
    "        \"\"\"\n",
    "        Frame Processing\n",
    "\n",
    "        Iterates over each frame in the current sequence, then constructs the file path to the numpy array for the current frame.\n",
    "        Prints the path to verify correctness, then loads the frame data from the numpy file.\n",
    "        \"\"\"\n",
    "        for frame_num in range(action_per_video):\n",
    "            # construct the path to the numpy file for the current frame\n",
    "            npy_path = os.path.join(\n",
    "                DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)\n",
    "            )\n",
    "\n",
    "            # load the frame data from the numpy file\n",
    "            result = np.load(npy_path)\n",
    "\n",
    "            # append the frame data to the current sequence (window)\n",
    "            sequence_actions.append(result)\n",
    "\n",
    "        # append the completed sequence to the sequences list\n",
    "        sequences.append(sequence_actions)\n",
    "\n",
    "        # append the corresponding label to the labels list\n",
    "        labels.append(labels_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sequences and labels lists into NumPy arrays that are suitable for use as input (X) and output (y) in machine learning models, particularly for deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)\n",
    "\n",
    "# convert labels list to a one-hot encoded NumPy array\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the dataset into training and testing sets\n",
    "# specifies that 10% of the data should be used as the test set, and the remaining 90% should be used as the training set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of the datasets depend on the total number of sequences and the sequence length. Assuming the code processes 60 sequences for each of the 3 actions, we have:\n",
    "\n",
    "    Total sequences = 60 sequences/action Ã— 6 actions = 360 sequences\n",
    "\n",
    "Given a test_size of 0.2, 20% of the data (approximately 72 sequences) will be in the test set, and 80% (approximately 288 sequences) will be in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 30, 1692), (72, 30, 1692), (288, 6), (72, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, save_model  # type: ignore\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv1D, MaxPooling1D, Dense, Dropout, LSTM, Bidirectional  # type: ignore\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau  # type: ignore\n",
    "from tensorflow.keras.regularizers import l2  # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the input shape (30, 1692) where 30 is the sequence length and 1692 is the number of features per frame\n",
    "input_shape = (30, 1692)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic regarding TimeDistributed\n",
    "\n",
    "- https://stackoverflow.com/a/76796778/14182545\n",
    "- https://medium.com/smileinnovation/how-to-work-with-time-distributed-data-in-a-neural-network-b8b39aa4ce00\n",
    "\n",
    "    Another kind of layer that is the famous \"LSTM\" (or GRU). It is not mandatory but it will finalize the chronological resolution of inputs.\n",
    "\n",
    "    Dense without TimeDistributed computes perBatch.\n",
    "    TimeDistributed with Dense computes per Timestep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture CNN-LSTM_1L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\keras\\src\\backend.py:277: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# asl-action-cnn-lstm_1l-2.9M\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# data normalization\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "# first Conv1D layer with L2 regularization\n",
    "model.add(\n",
    "    Conv1D(filters=64, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.01))\n",
    ")  # changed kernel size and filters\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# second Conv1D layer with L2 regularization\n",
    "model.add(\n",
    "    Conv1D(filters=128, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.01))\n",
    ")  # changed kernel size and filters\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# third Conv1D layer with L2 regularization\n",
    "model.add(\n",
    "    Conv1D(filters=256, kernel_size=3, activation=\"relu\", kernel_regularizer=l2(0.01))\n",
    ")  # changed kernel size and filters\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# dense layer for feature extraction with L2 regularization\n",
    "model.add(Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# bidirectional LSTM layer with L2 regularization\n",
    "model.add(\n",
    "    Bidirectional(\n",
    "        LSTM(512, return_sequences=False, activation=\"relu\", kernel_regularizer=l2(0.01))\n",
    "    )\n",
    ")\n",
    "\n",
    "# dense layers for classification with dropout for regularization\n",
    "model.add(Dense(128, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))  # slightly higher dropout rate, so it's not overfitting\n",
    "model.add(Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))  # slightly higher dropout rate, so it's not overfitting\n",
    "\n",
    "model.add(Dense(ACTIONS.shape[0], activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (Batch  (None, 30, 1692)          6768      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 28, 64)            324928    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 14, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 12, 128)           24704     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 6, 128)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 4, 256)            98560     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 2, 256)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2, 64)             16448     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 64)             0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 1024)              2363392   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2974646 (11.35 MB)\n",
      "Trainable params: 2971262 (11.33 MB)\n",
      "Non-trainable params: 3384 (13.22 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_dir(base_dir, use_time=False):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # check existing log directories\n",
    "    existing_logs = [\n",
    "        d\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"train-\")\n",
    "    ]\n",
    "\n",
    "    # determine the new log directory name\n",
    "    if existing_logs and not use_time:\n",
    "        latest_log = max(existing_logs)\n",
    "        log_num = int(latest_log.split(\"-\")[1]) + 1\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{str(log_num).zfill(3)}\")\n",
    "\n",
    "    if not existing_logs and not use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-001\")\n",
    "\n",
    "    if use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{current_time}\")\n",
    "\n",
    "    # create the new log directory\n",
    "    os.makedirs(new_log_dir)\n",
    "    print(f\"Created new log directory: {new_log_dir}\")\n",
    "\n",
    "    return new_log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback  # type: ignore\n",
    "\n",
    "\n",
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor=\"val_loss\", value=0.001, verbose=0, patience=20):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            raise ValueError(f\"Early stopping requires {self.monitor} available!\")\n",
    "\n",
    "        if current <= self.value:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                if self.verbose > 0:\n",
    "                    print(\n",
    "                        f\"Epoch {epoch}: early stopping threshold reached with {self.monitor} = {current}\"\n",
    "                    )\n",
    "                self.model.stop_training = True\n",
    "        else:\n",
    "            self.wait = 0  # reset wait if the condition is not met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the optimizer with an initial learning rate\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "# compile the model with the optimizer\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\"\"\"\n",
    "Define the EarlyStopping callback with adjusted patience\n",
    "\n",
    "monitor  : monitor the `val_loss` for training.\n",
    "patience : sets the number of epochs to wait for an improvement,\n",
    "           in the monitored metric before stopping the training.\n",
    "           `patience=10` means that if the validation loss does not improve for 10 consecutive epochs,\n",
    "           the training will be stopped.\n",
    "\"\"\"\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "early_stopping_by_loss_val = EarlyStoppingByLossVal(monitor='val_loss', value=0.001, verbose=1, patience=20)\n",
    "\n",
    "\"\"\"\n",
    "Define the ReduceLROnPlateau callback with adjusted factor and patience\n",
    "\n",
    "monitor  : monitor the `val_loss` for training.\n",
    "factor   : which the learning rate will be reduced. A factor=0.5 means the\n",
    "           learning rate will be halved when the metric has stopped improving.\n",
    "patience : sets the number of epochs with no improvement after which the learning rate will be reduced.\n",
    "           `patience=10` means if the validation loss does not improve for 10 consecutive epochs,\n",
    "           the learning rate will be reduced.\n",
    "min_lr   : lower bound on the learning rate, learning rate will not be reduced below `0.00001`,\n",
    "           ensuring it doesn't become too small.\n",
    "\"\"\"\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new log directory: ../drive/logs/asl_action_6\\train-20240602-162728\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "9/9 [==============================] - 4s 128ms/step - loss: 10.7488 - accuracy: 0.2639 - val_loss: 9.3540 - val_accuracy: 0.2222 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 8.2814 - accuracy: 0.2882 - val_loss: 7.4950 - val_accuracy: 0.2222 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 6.5810 - accuracy: 0.3403 - val_loss: 6.2648 - val_accuracy: 0.2222 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 5.4691 - accuracy: 0.3403 - val_loss: 5.5961 - val_accuracy: 0.2222 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 4.6247 - accuracy: 0.3507 - val_loss: 4.6664 - val_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 4.0321 - accuracy: 0.3785 - val_loss: 4.4560 - val_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 3.5834 - accuracy: 0.3472 - val_loss: 3.8417 - val_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 3.2327 - accuracy: 0.3750 - val_loss: 3.6190 - val_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 2.8963 - accuracy: 0.4514 - val_loss: 3.2947 - val_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 2.6878 - accuracy: 0.3889 - val_loss: 3.2005 - val_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 2.4350 - accuracy: 0.4688 - val_loss: 3.1515 - val_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 2.3068 - accuracy: 0.4410 - val_loss: 3.0889 - val_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 2.1682 - accuracy: 0.4826 - val_loss: 2.7970 - val_accuracy: 0.1528 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 2.0036 - accuracy: 0.5278 - val_loss: 2.6992 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.6867 - accuracy: 0.6285 - val_loss: 2.6646 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.9002 - accuracy: 0.5868 - val_loss: 2.7723 - val_accuracy: 0.1667 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.8075 - accuracy: 0.6042 - val_loss: 2.6815 - val_accuracy: 0.2639 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.5769 - accuracy: 0.6944 - val_loss: 2.8602 - val_accuracy: 0.2361 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.4257 - accuracy: 0.6875 - val_loss: 2.5271 - val_accuracy: 0.2639 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1.7454 - accuracy: 0.6042 - val_loss: 2.0076 - val_accuracy: 0.4861 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.8786 - accuracy: 0.4965 - val_loss: 2.3312 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.7626 - accuracy: 0.4757 - val_loss: 2.0632 - val_accuracy: 0.3750 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.6212 - accuracy: 0.5625 - val_loss: 1.9026 - val_accuracy: 0.3056 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.5668 - accuracy: 0.5347 - val_loss: 1.7950 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.4832 - accuracy: 0.5764 - val_loss: 1.6841 - val_accuracy: 0.2778 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 1.4747 - accuracy: 0.5972 - val_loss: 1.6462 - val_accuracy: 0.3194 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.3940 - accuracy: 0.6042 - val_loss: 1.4242 - val_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.3027 - accuracy: 0.6250 - val_loss: 1.4783 - val_accuracy: 0.4306 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.2442 - accuracy: 0.6562 - val_loss: 1.4187 - val_accuracy: 0.4167 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.2147 - accuracy: 0.6528 - val_loss: 1.3305 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.1249 - accuracy: 0.6736 - val_loss: 1.2215 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.1105 - accuracy: 0.6632 - val_loss: 1.2855 - val_accuracy: 0.4861 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0469 - accuracy: 0.7083 - val_loss: 1.3965 - val_accuracy: 0.4444 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0755 - accuracy: 0.6632 - val_loss: 1.2608 - val_accuracy: 0.5694 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.3120 - accuracy: 0.5938 - val_loss: 1.4592 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.2006 - accuracy: 0.6319 - val_loss: 1.2024 - val_accuracy: 0.5694 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 1.0362 - accuracy: 0.6632 - val_loss: 1.0847 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 1.0819 - accuracy: 0.6701 - val_loss: 1.1094 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 1.0716 - accuracy: 0.6528 - val_loss: 1.1332 - val_accuracy: 0.5694 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 1.0252 - accuracy: 0.6944 - val_loss: 1.0506 - val_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9860 - accuracy: 0.7049 - val_loss: 1.0034 - val_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9557 - accuracy: 0.6910 - val_loss: 0.9679 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.9183 - accuracy: 0.6736 - val_loss: 0.9400 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9244 - accuracy: 0.6979 - val_loss: 0.9272 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8893 - accuracy: 0.6875 - val_loss: 0.9176 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9137 - accuracy: 0.6736 - val_loss: 0.9061 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8743 - accuracy: 0.7222 - val_loss: 0.8956 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.8410 - accuracy: 0.6979 - val_loss: 0.8801 - val_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.8381 - accuracy: 0.6806 - val_loss: 0.8702 - val_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8507 - accuracy: 0.7014 - val_loss: 0.8588 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.8186 - accuracy: 0.6806 - val_loss: 0.8496 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8298 - accuracy: 0.6632 - val_loss: 0.8383 - val_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.7963 - accuracy: 0.6944 - val_loss: 0.8279 - val_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.8142 - accuracy: 0.6597 - val_loss: 0.8214 - val_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.8476 - accuracy: 0.6806 - val_loss: 0.8148 - val_accuracy: 0.5972 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.8382 - accuracy: 0.6458 - val_loss: 0.9523 - val_accuracy: 0.5278 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.9369 - accuracy: 0.6111 - val_loss: 0.9483 - val_accuracy: 0.5694 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 1.2201 - accuracy: 0.5833 - val_loss: 1.0325 - val_accuracy: 0.5556 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.9721 - accuracy: 0.6632 - val_loss: 0.9495 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.9122 - accuracy: 0.7465 - val_loss: 0.9239 - val_accuracy: 0.5833 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.8775 - accuracy: 0.6944 - val_loss: 0.8981 - val_accuracy: 0.6528 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8480 - accuracy: 0.7049 - val_loss: 0.8760 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.8177 - accuracy: 0.7257 - val_loss: 0.8435 - val_accuracy: 0.6944 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7948 - accuracy: 0.6979 - val_loss: 0.8152 - val_accuracy: 0.6944 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.7959 - accuracy: 0.6875 - val_loss: 0.8154 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.8055 - accuracy: 0.7049 - val_loss: 0.8078 - val_accuracy: 0.6806 - lr: 5.0000e-04\n",
      "Epoch 67/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.7954 - accuracy: 0.7014 - val_loss: 0.8048 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 68/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.7594 - accuracy: 0.7465 - val_loss: 0.7978 - val_accuracy: 0.7083 - lr: 5.0000e-04\n",
      "Epoch 69/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.7677 - accuracy: 0.7188 - val_loss: 0.7822 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 70/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.7304 - accuracy: 0.7257 - val_loss: 0.7742 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 71/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.7788 - accuracy: 0.7083 - val_loss: 0.7533 - val_accuracy: 0.6944 - lr: 5.0000e-04\n",
      "Epoch 72/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.7323 - accuracy: 0.7083 - val_loss: 0.7351 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 73/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.7102 - accuracy: 0.7743 - val_loss: 0.7287 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 74/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7128 - accuracy: 0.7639 - val_loss: 0.7014 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 75/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6775 - accuracy: 0.7674 - val_loss: 0.6626 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 76/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.7267 - accuracy: 0.7326 - val_loss: 0.6446 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 77/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6754 - accuracy: 0.7812 - val_loss: 0.6772 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 78/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6564 - accuracy: 0.8021 - val_loss: 0.6336 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 79/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6450 - accuracy: 0.8160 - val_loss: 0.5944 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 80/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6050 - accuracy: 0.8090 - val_loss: 0.5800 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 81/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6921 - accuracy: 0.7917 - val_loss: 0.5713 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 82/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6250 - accuracy: 0.7986 - val_loss: 0.6176 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 83/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6286 - accuracy: 0.8333 - val_loss: 0.5958 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 84/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6383 - accuracy: 0.7847 - val_loss: 0.5836 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 85/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6403 - accuracy: 0.7986 - val_loss: 0.6072 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 86/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6541 - accuracy: 0.7917 - val_loss: 0.5778 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 87/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.6931 - accuracy: 0.8090 - val_loss: 0.6061 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 88/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6081 - accuracy: 0.8229 - val_loss: 0.5762 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 89/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.5744 - accuracy: 0.8472 - val_loss: 0.5584 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 90/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5844 - accuracy: 0.8438 - val_loss: 0.5639 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 91/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6327 - accuracy: 0.8056 - val_loss: 0.5668 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 92/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.6012 - accuracy: 0.8229 - val_loss: 0.5762 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 93/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5751 - accuracy: 0.8299 - val_loss: 0.5512 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 94/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.6081 - accuracy: 0.7882 - val_loss: 0.5610 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 95/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.6206 - accuracy: 0.8160 - val_loss: 0.5462 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 96/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5897 - accuracy: 0.8160 - val_loss: 0.5532 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 97/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5742 - accuracy: 0.8472 - val_loss: 0.5653 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 98/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6259 - accuracy: 0.8160 - val_loss: 0.5603 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
      "Epoch 99/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.5756 - accuracy: 0.8229 - val_loss: 0.5528 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 100/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5419 - accuracy: 0.8403 - val_loss: 0.5435 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 101/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5427 - accuracy: 0.8056 - val_loss: 0.5430 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 102/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5120 - accuracy: 0.8368 - val_loss: 0.5395 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 103/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5139 - accuracy: 0.8299 - val_loss: 0.5330 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 104/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5474 - accuracy: 0.8021 - val_loss: 0.5327 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 105/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5492 - accuracy: 0.8160 - val_loss: 0.5265 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 106/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5298 - accuracy: 0.8125 - val_loss: 0.5325 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 107/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5035 - accuracy: 0.8333 - val_loss: 0.5318 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 108/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5153 - accuracy: 0.8229 - val_loss: 0.5263 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 109/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4990 - accuracy: 0.8438 - val_loss: 0.5205 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 110/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5143 - accuracy: 0.8611 - val_loss: 0.5180 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 111/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5389 - accuracy: 0.8125 - val_loss: 0.5275 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 112/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.5005 - accuracy: 0.8194 - val_loss: 0.5121 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 113/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5917 - accuracy: 0.8438 - val_loss: 0.5466 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 114/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.5115 - accuracy: 0.8472 - val_loss: 0.5191 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 115/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.5320 - accuracy: 0.8160 - val_loss: 0.5320 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 116/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.5263 - accuracy: 0.8403 - val_loss: 0.5335 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 117/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5902 - accuracy: 0.8333 - val_loss: 0.5731 - val_accuracy: 0.7639 - lr: 5.0000e-04\n",
      "Epoch 118/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.7806 - accuracy: 0.7812 - val_loss: 0.6230 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 119/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.6349 - accuracy: 0.8229 - val_loss: 0.6642 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
      "Epoch 120/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.6710 - accuracy: 0.8299 - val_loss: 0.6101 - val_accuracy: 0.8194 - lr: 5.0000e-04\n",
      "Epoch 121/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5700 - accuracy: 0.8299 - val_loss: 0.6001 - val_accuracy: 0.7778 - lr: 5.0000e-04\n",
      "Epoch 122/1000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5593 - accuracy: 0.8438 - val_loss: 0.5581 - val_accuracy: 0.8056 - lr: 5.0000e-04\n",
      "Epoch 123/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5663 - accuracy: 0.8472 - val_loss: 0.5470 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
      "Epoch 124/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5397 - accuracy: 0.8368 - val_loss: 0.5480 - val_accuracy: 0.8472 - lr: 2.5000e-04\n",
      "Epoch 125/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5275 - accuracy: 0.8264 - val_loss: 0.5466 - val_accuracy: 0.8194 - lr: 2.5000e-04\n",
      "Epoch 126/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.5168 - accuracy: 0.8472 - val_loss: 0.5364 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
      "Epoch 127/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5646 - accuracy: 0.7882 - val_loss: 0.5339 - val_accuracy: 0.7778 - lr: 2.5000e-04\n",
      "Epoch 128/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5308 - accuracy: 0.8194 - val_loss: 0.5347 - val_accuracy: 0.7639 - lr: 2.5000e-04\n",
      "Epoch 129/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5146 - accuracy: 0.8646 - val_loss: 0.5311 - val_accuracy: 0.7639 - lr: 2.5000e-04\n",
      "Epoch 130/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4980 - accuracy: 0.8403 - val_loss: 0.5274 - val_accuracy: 0.7639 - lr: 2.5000e-04\n",
      "Epoch 131/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5165 - accuracy: 0.8021 - val_loss: 0.5277 - val_accuracy: 0.7639 - lr: 2.5000e-04\n",
      "Epoch 132/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5047 - accuracy: 0.8576 - val_loss: 0.5249 - val_accuracy: 0.7639 - lr: 2.5000e-04\n",
      "Epoch 133/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4999 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7639 - lr: 1.2500e-04\n",
      "Epoch 134/1000\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.5224 - accuracy: 0.8472 - val_loss: 0.5203 - val_accuracy: 0.7500 - lr: 1.2500e-04\n",
      "Epoch 135/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4997 - accuracy: 0.8264 - val_loss: 0.5204 - val_accuracy: 0.7639 - lr: 1.2500e-04\n",
      "Epoch 136/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4932 - accuracy: 0.8438 - val_loss: 0.5199 - val_accuracy: 0.7639 - lr: 1.2500e-04\n",
      "Epoch 137/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5017 - accuracy: 0.8229 - val_loss: 0.5177 - val_accuracy: 0.7639 - lr: 1.2500e-04\n",
      "Epoch 138/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4854 - accuracy: 0.8368 - val_loss: 0.5157 - val_accuracy: 0.7500 - lr: 1.2500e-04\n",
      "Epoch 139/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5005 - accuracy: 0.8611 - val_loss: 0.5143 - val_accuracy: 0.7639 - lr: 1.2500e-04\n",
      "Epoch 140/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4870 - accuracy: 0.8160 - val_loss: 0.5129 - val_accuracy: 0.7778 - lr: 1.2500e-04\n",
      "Epoch 141/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.5411 - accuracy: 0.8264 - val_loss: 0.5120 - val_accuracy: 0.7639 - lr: 1.2500e-04\n",
      "Epoch 142/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.4980 - accuracy: 0.8507 - val_loss: 0.5146 - val_accuracy: 0.7639 - lr: 1.2500e-04\n",
      "Epoch 143/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4888 - accuracy: 0.8333 - val_loss: 0.5121 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 144/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4964 - accuracy: 0.8333 - val_loss: 0.5108 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 145/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5279 - accuracy: 0.8090 - val_loss: 0.5112 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 146/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4809 - accuracy: 0.8542 - val_loss: 0.5109 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 147/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4954 - accuracy: 0.8299 - val_loss: 0.5105 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 148/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4941 - accuracy: 0.8472 - val_loss: 0.5104 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 149/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4868 - accuracy: 0.8160 - val_loss: 0.5106 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 150/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4834 - accuracy: 0.8160 - val_loss: 0.5104 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 151/1000\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.5362 - accuracy: 0.8333 - val_loss: 0.5108 - val_accuracy: 0.7500 - lr: 6.2500e-05\n",
      "Epoch 152/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.4943 - accuracy: 0.8368 - val_loss: 0.5101 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 153/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4721 - accuracy: 0.8438 - val_loss: 0.5089 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 154/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4826 - accuracy: 0.8438 - val_loss: 0.5082 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 155/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4772 - accuracy: 0.8472 - val_loss: 0.5076 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 156/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4814 - accuracy: 0.8403 - val_loss: 0.5070 - val_accuracy: 0.7500 - lr: 6.2500e-05\n",
      "Epoch 157/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4767 - accuracy: 0.8229 - val_loss: 0.5065 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 158/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4681 - accuracy: 0.8681 - val_loss: 0.5064 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 159/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4679 - accuracy: 0.8576 - val_loss: 0.5061 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 160/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5178 - accuracy: 0.8368 - val_loss: 0.5064 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 161/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4885 - accuracy: 0.8576 - val_loss: 0.5073 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 162/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4910 - accuracy: 0.8229 - val_loss: 0.5050 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 163/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4660 - accuracy: 0.8576 - val_loss: 0.5038 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 164/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4879 - accuracy: 0.8750 - val_loss: 0.5033 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 165/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4686 - accuracy: 0.8646 - val_loss: 0.5027 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 166/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4804 - accuracy: 0.8264 - val_loss: 0.5024 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 167/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4775 - accuracy: 0.8438 - val_loss: 0.5031 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 168/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4854 - accuracy: 0.8438 - val_loss: 0.5041 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 169/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4816 - accuracy: 0.8299 - val_loss: 0.5059 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 170/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4791 - accuracy: 0.8507 - val_loss: 0.5059 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 171/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4815 - accuracy: 0.8507 - val_loss: 0.5039 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 172/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4915 - accuracy: 0.8264 - val_loss: 0.5029 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 173/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4919 - accuracy: 0.8611 - val_loss: 0.5008 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 174/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4676 - accuracy: 0.8611 - val_loss: 0.5002 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 175/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4848 - accuracy: 0.8194 - val_loss: 0.4997 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 176/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.5051 - accuracy: 0.8333 - val_loss: 0.5004 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 177/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4760 - accuracy: 0.8333 - val_loss: 0.5020 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 178/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4731 - accuracy: 0.8264 - val_loss: 0.5017 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 179/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4825 - accuracy: 0.8403 - val_loss: 0.4996 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 180/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4772 - accuracy: 0.8333 - val_loss: 0.4977 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 181/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4968 - accuracy: 0.8403 - val_loss: 0.4971 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 182/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5324 - accuracy: 0.8403 - val_loss: 0.4975 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 183/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4683 - accuracy: 0.8264 - val_loss: 0.4979 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 184/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4848 - accuracy: 0.8229 - val_loss: 0.4984 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 185/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4950 - accuracy: 0.8403 - val_loss: 0.5013 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 186/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4757 - accuracy: 0.8542 - val_loss: 0.4995 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 187/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4744 - accuracy: 0.8403 - val_loss: 0.4972 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 188/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4858 - accuracy: 0.8507 - val_loss: 0.4961 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 189/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4772 - accuracy: 0.8438 - val_loss: 0.4963 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 190/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4755 - accuracy: 0.8264 - val_loss: 0.4960 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 191/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4844 - accuracy: 0.8229 - val_loss: 0.4949 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 192/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4760 - accuracy: 0.8229 - val_loss: 0.4943 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 193/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4555 - accuracy: 0.8576 - val_loss: 0.4940 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 194/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4873 - accuracy: 0.8507 - val_loss: 0.4938 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 195/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4682 - accuracy: 0.8542 - val_loss: 0.4939 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 196/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4681 - accuracy: 0.8576 - val_loss: 0.4940 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 197/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4681 - accuracy: 0.8333 - val_loss: 0.4934 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 198/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.4606 - accuracy: 0.8472 - val_loss: 0.4928 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 199/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4825 - accuracy: 0.8403 - val_loss: 0.4930 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 200/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4619 - accuracy: 0.8576 - val_loss: 0.4927 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 201/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4830 - accuracy: 0.8229 - val_loss: 0.4926 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 202/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4825 - accuracy: 0.8194 - val_loss: 0.4922 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 203/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4660 - accuracy: 0.8368 - val_loss: 0.4915 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 204/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4840 - accuracy: 0.8194 - val_loss: 0.4910 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 205/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4602 - accuracy: 0.8507 - val_loss: 0.4906 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 206/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4608 - accuracy: 0.8333 - val_loss: 0.4899 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 207/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4811 - accuracy: 0.8438 - val_loss: 0.4894 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 208/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4665 - accuracy: 0.8229 - val_loss: 0.4889 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 209/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4637 - accuracy: 0.8611 - val_loss: 0.4890 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 210/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4724 - accuracy: 0.8576 - val_loss: 0.4888 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 211/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4547 - accuracy: 0.8819 - val_loss: 0.4889 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 212/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4687 - accuracy: 0.8750 - val_loss: 0.4884 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 213/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4771 - accuracy: 0.8611 - val_loss: 0.4887 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 214/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4593 - accuracy: 0.8542 - val_loss: 0.4870 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 215/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4544 - accuracy: 0.8438 - val_loss: 0.4863 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 216/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.4647 - accuracy: 0.8333 - val_loss: 0.4860 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 217/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4679 - accuracy: 0.8403 - val_loss: 0.4862 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 218/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4525 - accuracy: 0.8576 - val_loss: 0.4862 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 219/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4797 - accuracy: 0.8507 - val_loss: 0.4862 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 220/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4641 - accuracy: 0.8438 - val_loss: 0.4863 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 221/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.5022 - accuracy: 0.8160 - val_loss: 0.4865 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 222/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4510 - accuracy: 0.8715 - val_loss: 0.4859 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 223/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4612 - accuracy: 0.8403 - val_loss: 0.4852 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 224/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.4541 - accuracy: 0.8438 - val_loss: 0.4848 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 225/1000\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.4427 - accuracy: 0.8403 - val_loss: 0.4843 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 226/1000\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.4630 - accuracy: 0.8368 - val_loss: 0.4838 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 227/1000\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.4506 - accuracy: 0.8750 - val_loss: 0.4838 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 228/1000\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.4475 - accuracy: 0.8646 - val_loss: 0.4835 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 229/1000\n",
      "9/9 [==============================] - 1s 106ms/step - loss: 0.4650 - accuracy: 0.8403 - val_loss: 0.4835 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 230/1000\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.4642 - accuracy: 0.8681 - val_loss: 0.4834 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 231/1000\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.4654 - accuracy: 0.8056 - val_loss: 0.4835 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 232/1000\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.4556 - accuracy: 0.8368 - val_loss: 0.4828 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 233/1000\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 0.4464 - accuracy: 0.8576 - val_loss: 0.4822 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 234/1000\n",
      "9/9 [==============================] - 1s 108ms/step - loss: 0.4601 - accuracy: 0.8403 - val_loss: 0.4816 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 235/1000\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.4649 - accuracy: 0.8229 - val_loss: 0.4814 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 236/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4424 - accuracy: 0.8715 - val_loss: 0.4815 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 237/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4564 - accuracy: 0.8333 - val_loss: 0.4812 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 238/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4929 - accuracy: 0.8368 - val_loss: 0.4810 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 239/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4799 - accuracy: 0.8368 - val_loss: 0.4825 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 240/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4479 - accuracy: 0.8646 - val_loss: 0.4828 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 241/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4721 - accuracy: 0.8438 - val_loss: 0.4812 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 242/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4601 - accuracy: 0.8368 - val_loss: 0.4800 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 243/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4479 - accuracy: 0.8194 - val_loss: 0.4794 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 244/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4482 - accuracy: 0.8507 - val_loss: 0.4787 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 245/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4569 - accuracy: 0.8056 - val_loss: 0.4785 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 246/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4868 - accuracy: 0.8333 - val_loss: 0.4785 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 247/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4688 - accuracy: 0.8125 - val_loss: 0.4793 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 248/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4674 - accuracy: 0.8438 - val_loss: 0.4807 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 249/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4754 - accuracy: 0.8264 - val_loss: 0.4793 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 250/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4506 - accuracy: 0.8438 - val_loss: 0.4779 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 251/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4461 - accuracy: 0.8299 - val_loss: 0.4772 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 252/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4542 - accuracy: 0.8403 - val_loss: 0.4770 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 253/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4399 - accuracy: 0.8403 - val_loss: 0.4767 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 254/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4435 - accuracy: 0.8368 - val_loss: 0.4764 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 255/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4561 - accuracy: 0.8229 - val_loss: 0.4762 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 256/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4434 - accuracy: 0.8472 - val_loss: 0.4760 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 257/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4717 - accuracy: 0.8229 - val_loss: 0.4758 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 258/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.5146 - accuracy: 0.8264 - val_loss: 0.4762 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 259/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4533 - accuracy: 0.8438 - val_loss: 0.4772 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 260/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4547 - accuracy: 0.8819 - val_loss: 0.4773 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 261/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4462 - accuracy: 0.8993 - val_loss: 0.4752 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 262/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4532 - accuracy: 0.8194 - val_loss: 0.4743 - val_accuracy: 0.7500 - lr: 6.2500e-05\n",
      "Epoch 263/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4412 - accuracy: 0.8542 - val_loss: 0.4741 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 264/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4417 - accuracy: 0.8611 - val_loss: 0.4739 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 265/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4444 - accuracy: 0.8542 - val_loss: 0.4738 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 266/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4459 - accuracy: 0.8264 - val_loss: 0.4737 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 267/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4611 - accuracy: 0.8299 - val_loss: 0.4736 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 268/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4587 - accuracy: 0.8681 - val_loss: 0.4738 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 269/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4621 - accuracy: 0.8403 - val_loss: 0.4744 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 270/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4852 - accuracy: 0.8194 - val_loss: 0.4739 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 271/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4404 - accuracy: 0.8472 - val_loss: 0.4732 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 272/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4405 - accuracy: 0.8576 - val_loss: 0.4727 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 273/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4409 - accuracy: 0.8472 - val_loss: 0.4721 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 274/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4683 - accuracy: 0.8403 - val_loss: 0.4721 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 275/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4442 - accuracy: 0.8368 - val_loss: 0.4721 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 276/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4564 - accuracy: 0.8333 - val_loss: 0.4721 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 277/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4760 - accuracy: 0.8160 - val_loss: 0.4723 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 278/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4716 - accuracy: 0.8472 - val_loss: 0.4723 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 279/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4477 - accuracy: 0.8542 - val_loss: 0.4723 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 280/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4541 - accuracy: 0.8264 - val_loss: 0.4724 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 281/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4436 - accuracy: 0.8403 - val_loss: 0.4718 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 282/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4346 - accuracy: 0.8299 - val_loss: 0.4710 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 283/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4534 - accuracy: 0.8507 - val_loss: 0.4704 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 284/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4368 - accuracy: 0.8368 - val_loss: 0.4700 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 285/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4437 - accuracy: 0.8229 - val_loss: 0.4695 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 286/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4300 - accuracy: 0.8542 - val_loss: 0.4691 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 287/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4390 - accuracy: 0.8507 - val_loss: 0.4687 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 288/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4387 - accuracy: 0.8194 - val_loss: 0.4686 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 289/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4345 - accuracy: 0.8472 - val_loss: 0.4682 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 290/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4283 - accuracy: 0.8576 - val_loss: 0.4678 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 291/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4703 - accuracy: 0.8542 - val_loss: 0.4677 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 292/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4338 - accuracy: 0.8507 - val_loss: 0.4674 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 293/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4725 - accuracy: 0.8299 - val_loss: 0.4678 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 294/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4406 - accuracy: 0.8646 - val_loss: 0.4681 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 295/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4667 - accuracy: 0.8125 - val_loss: 0.4679 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 296/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4506 - accuracy: 0.8854 - val_loss: 0.4679 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 297/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4397 - accuracy: 0.8611 - val_loss: 0.4688 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 298/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4434 - accuracy: 0.8542 - val_loss: 0.4675 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 299/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4435 - accuracy: 0.8472 - val_loss: 0.4671 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 300/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4349 - accuracy: 0.8507 - val_loss: 0.4672 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 301/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4368 - accuracy: 0.8438 - val_loss: 0.4673 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 302/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4278 - accuracy: 0.8681 - val_loss: 0.4670 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 303/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4245 - accuracy: 0.8889 - val_loss: 0.4668 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 304/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4322 - accuracy: 0.8854 - val_loss: 0.4665 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 305/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4255 - accuracy: 0.8750 - val_loss: 0.4657 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 306/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4342 - accuracy: 0.8507 - val_loss: 0.4656 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 307/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4287 - accuracy: 0.8611 - val_loss: 0.4649 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 308/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4621 - accuracy: 0.8646 - val_loss: 0.4656 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 309/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4301 - accuracy: 0.8368 - val_loss: 0.4652 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 310/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4371 - accuracy: 0.8611 - val_loss: 0.4648 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 311/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4262 - accuracy: 0.8715 - val_loss: 0.4644 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 312/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4361 - accuracy: 0.8368 - val_loss: 0.4639 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 313/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4467 - accuracy: 0.8576 - val_loss: 0.4637 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 314/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4380 - accuracy: 0.8403 - val_loss: 0.4629 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 315/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4426 - accuracy: 0.8785 - val_loss: 0.4618 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 316/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4521 - accuracy: 0.8333 - val_loss: 0.4702 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 317/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4489 - accuracy: 0.8542 - val_loss: 0.4652 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 318/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4530 - accuracy: 0.8576 - val_loss: 0.4622 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 319/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4543 - accuracy: 0.8438 - val_loss: 0.4619 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 320/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4546 - accuracy: 0.8646 - val_loss: 0.4619 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 321/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4415 - accuracy: 0.8576 - val_loss: 0.4613 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 322/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4350 - accuracy: 0.8438 - val_loss: 0.4608 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 323/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4443 - accuracy: 0.8368 - val_loss: 0.4612 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 324/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4229 - accuracy: 0.8750 - val_loss: 0.4601 - val_accuracy: 0.7778 - lr: 6.2500e-05\n",
      "Epoch 325/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4687 - accuracy: 0.8576 - val_loss: 0.4586 - val_accuracy: 0.7917 - lr: 6.2500e-05\n",
      "Epoch 326/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4198 - accuracy: 0.8854 - val_loss: 0.4545 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 327/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4825 - accuracy: 0.8681 - val_loss: 0.4521 - val_accuracy: 0.8750 - lr: 6.2500e-05\n",
      "Epoch 328/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4416 - accuracy: 0.8611 - val_loss: 0.4586 - val_accuracy: 0.8333 - lr: 6.2500e-05\n",
      "Epoch 329/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4398 - accuracy: 0.8750 - val_loss: 0.4616 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 330/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4317 - accuracy: 0.8472 - val_loss: 0.4614 - val_accuracy: 0.7639 - lr: 6.2500e-05\n",
      "Epoch 331/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4308 - accuracy: 0.8681 - val_loss: 0.4605 - val_accuracy: 0.8056 - lr: 6.2500e-05\n",
      "Epoch 332/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4297 - accuracy: 0.8368 - val_loss: 0.4589 - val_accuracy: 0.8194 - lr: 6.2500e-05\n",
      "Epoch 333/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4280 - accuracy: 0.8785 - val_loss: 0.4590 - val_accuracy: 0.8194 - lr: 6.2500e-05\n",
      "Epoch 334/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4367 - accuracy: 0.8542 - val_loss: 0.4587 - val_accuracy: 0.8056 - lr: 6.2500e-05\n",
      "Epoch 335/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.4218 - accuracy: 0.8681 - val_loss: 0.4567 - val_accuracy: 0.8333 - lr: 6.2500e-05\n",
      "Epoch 336/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4210 - accuracy: 0.8750 - val_loss: 0.4521 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 337/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4331 - accuracy: 0.8646 - val_loss: 0.4481 - val_accuracy: 0.8750 - lr: 6.2500e-05\n",
      "Epoch 338/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4503 - accuracy: 0.8576 - val_loss: 0.4553 - val_accuracy: 0.8333 - lr: 6.2500e-05\n",
      "Epoch 339/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4255 - accuracy: 0.8785 - val_loss: 0.4551 - val_accuracy: 0.8333 - lr: 6.2500e-05\n",
      "Epoch 340/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4189 - accuracy: 0.8646 - val_loss: 0.4512 - val_accuracy: 0.8333 - lr: 6.2500e-05\n",
      "Epoch 341/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4279 - accuracy: 0.8715 - val_loss: 0.4473 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 342/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4334 - accuracy: 0.9028 - val_loss: 0.4496 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 343/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4289 - accuracy: 0.8576 - val_loss: 0.4451 - val_accuracy: 0.8889 - lr: 6.2500e-05\n",
      "Epoch 344/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4118 - accuracy: 0.8854 - val_loss: 0.4437 - val_accuracy: 0.8750 - lr: 6.2500e-05\n",
      "Epoch 345/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4396 - accuracy: 0.8715 - val_loss: 0.4424 - val_accuracy: 0.8750 - lr: 6.2500e-05\n",
      "Epoch 346/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4197 - accuracy: 0.8715 - val_loss: 0.4414 - val_accuracy: 0.8750 - lr: 6.2500e-05\n",
      "Epoch 347/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4173 - accuracy: 0.8750 - val_loss: 0.4432 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 348/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4160 - accuracy: 0.8889 - val_loss: 0.4466 - val_accuracy: 0.8472 - lr: 6.2500e-05\n",
      "Epoch 349/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4028 - accuracy: 0.8819 - val_loss: 0.4399 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 350/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4114 - accuracy: 0.8889 - val_loss: 0.4349 - val_accuracy: 0.8889 - lr: 6.2500e-05\n",
      "Epoch 351/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4159 - accuracy: 0.8993 - val_loss: 0.4392 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 352/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4188 - accuracy: 0.8854 - val_loss: 0.4426 - val_accuracy: 0.8472 - lr: 6.2500e-05\n",
      "Epoch 353/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4371 - accuracy: 0.8542 - val_loss: 0.4454 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 354/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4017 - accuracy: 0.8958 - val_loss: 0.4475 - val_accuracy: 0.8472 - lr: 6.2500e-05\n",
      "Epoch 355/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4077 - accuracy: 0.8785 - val_loss: 0.4411 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 356/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4185 - accuracy: 0.8819 - val_loss: 0.4324 - val_accuracy: 0.8889 - lr: 6.2500e-05\n",
      "Epoch 357/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4394 - accuracy: 0.8576 - val_loss: 0.4332 - val_accuracy: 0.8750 - lr: 6.2500e-05\n",
      "Epoch 358/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4307 - accuracy: 0.8854 - val_loss: 0.4403 - val_accuracy: 0.8750 - lr: 6.2500e-05\n",
      "Epoch 359/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3925 - accuracy: 0.9097 - val_loss: 0.4406 - val_accuracy: 0.8472 - lr: 6.2500e-05\n",
      "Epoch 360/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4238 - accuracy: 0.8819 - val_loss: 0.4303 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 361/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3961 - accuracy: 0.9201 - val_loss: 0.4282 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 362/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4242 - accuracy: 0.8854 - val_loss: 0.4409 - val_accuracy: 0.8472 - lr: 6.2500e-05\n",
      "Epoch 363/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4231 - accuracy: 0.9132 - val_loss: 0.4403 - val_accuracy: 0.8472 - lr: 6.2500e-05\n",
      "Epoch 364/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4212 - accuracy: 0.8854 - val_loss: 0.4305 - val_accuracy: 0.8750 - lr: 6.2500e-05\n",
      "Epoch 365/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4223 - accuracy: 0.8819 - val_loss: 0.4350 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 366/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4095 - accuracy: 0.8924 - val_loss: 0.4415 - val_accuracy: 0.8472 - lr: 6.2500e-05\n",
      "Epoch 367/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4079 - accuracy: 0.8785 - val_loss: 0.4331 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 368/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4283 - accuracy: 0.8889 - val_loss: 0.4221 - val_accuracy: 0.9028 - lr: 6.2500e-05\n",
      "Epoch 369/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3852 - accuracy: 0.9271 - val_loss: 0.4194 - val_accuracy: 0.8889 - lr: 6.2500e-05\n",
      "Epoch 370/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4007 - accuracy: 0.8958 - val_loss: 0.4127 - val_accuracy: 0.8889 - lr: 6.2500e-05\n",
      "Epoch 371/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4525 - accuracy: 0.8924 - val_loss: 0.4336 - val_accuracy: 0.8611 - lr: 6.2500e-05\n",
      "Epoch 372/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4125 - accuracy: 0.8958 - val_loss: 0.4427 - val_accuracy: 0.8472 - lr: 6.2500e-05\n",
      "Epoch 373/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.4166 - accuracy: 0.8785 - val_loss: 0.4360 - val_accuracy: 0.8889 - lr: 6.2500e-05\n",
      "Epoch 374/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4014 - accuracy: 0.9028 - val_loss: 0.4225 - val_accuracy: 0.8889 - lr: 6.2500e-05\n",
      "Epoch 375/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4163 - accuracy: 0.8993 - val_loss: 0.4209 - val_accuracy: 0.9028 - lr: 6.2500e-05\n",
      "Epoch 376/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4292 - accuracy: 0.8993 - val_loss: 0.4201 - val_accuracy: 0.9028 - lr: 6.2500e-05\n",
      "Epoch 377/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4001 - accuracy: 0.9062 - val_loss: 0.4186 - val_accuracy: 0.9028 - lr: 6.2500e-05\n",
      "Epoch 378/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4105 - accuracy: 0.8715 - val_loss: 0.4187 - val_accuracy: 0.9028 - lr: 6.2500e-05\n",
      "Epoch 379/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3964 - accuracy: 0.9062 - val_loss: 0.4195 - val_accuracy: 0.9028 - lr: 6.2500e-05\n",
      "Epoch 380/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4018 - accuracy: 0.9167 - val_loss: 0.4178 - val_accuracy: 0.9028 - lr: 6.2500e-05\n",
      "Epoch 381/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4279 - accuracy: 0.8889 - val_loss: 0.4182 - val_accuracy: 0.8889 - lr: 3.1250e-05\n",
      "Epoch 382/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3863 - accuracy: 0.8993 - val_loss: 0.4218 - val_accuracy: 0.8750 - lr: 3.1250e-05\n",
      "Epoch 383/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3860 - accuracy: 0.9167 - val_loss: 0.4184 - val_accuracy: 0.8889 - lr: 3.1250e-05\n",
      "Epoch 384/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4108 - accuracy: 0.8785 - val_loss: 0.4121 - val_accuracy: 0.9167 - lr: 3.1250e-05\n",
      "Epoch 385/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4044 - accuracy: 0.8958 - val_loss: 0.4101 - val_accuracy: 0.9028 - lr: 3.1250e-05\n",
      "Epoch 386/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4043 - accuracy: 0.8889 - val_loss: 0.4173 - val_accuracy: 0.9028 - lr: 3.1250e-05\n",
      "Epoch 387/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3732 - accuracy: 0.9167 - val_loss: 0.4169 - val_accuracy: 0.8750 - lr: 3.1250e-05\n",
      "Epoch 388/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3739 - accuracy: 0.9306 - val_loss: 0.4090 - val_accuracy: 0.8750 - lr: 3.1250e-05\n",
      "Epoch 389/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3960 - accuracy: 0.9028 - val_loss: 0.4062 - val_accuracy: 0.8889 - lr: 3.1250e-05\n",
      "Epoch 390/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3732 - accuracy: 0.9236 - val_loss: 0.4049 - val_accuracy: 0.8750 - lr: 3.1250e-05\n",
      "Epoch 391/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3927 - accuracy: 0.9167 - val_loss: 0.4031 - val_accuracy: 0.8889 - lr: 3.1250e-05\n",
      "Epoch 392/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4011 - accuracy: 0.9097 - val_loss: 0.4115 - val_accuracy: 0.8889 - lr: 3.1250e-05\n",
      "Epoch 393/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3788 - accuracy: 0.9132 - val_loss: 0.4180 - val_accuracy: 0.9028 - lr: 3.1250e-05\n",
      "Epoch 394/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3826 - accuracy: 0.9167 - val_loss: 0.4118 - val_accuracy: 0.9028 - lr: 3.1250e-05\n",
      "Epoch 395/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3908 - accuracy: 0.9132 - val_loss: 0.4086 - val_accuracy: 0.9028 - lr: 3.1250e-05\n",
      "Epoch 396/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4039 - accuracy: 0.9097 - val_loss: 0.4144 - val_accuracy: 0.9028 - lr: 3.1250e-05\n",
      "Epoch 397/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3843 - accuracy: 0.9306 - val_loss: 0.4134 - val_accuracy: 0.8889 - lr: 3.1250e-05\n",
      "Epoch 398/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3814 - accuracy: 0.9201 - val_loss: 0.4065 - val_accuracy: 0.9167 - lr: 3.1250e-05\n",
      "Epoch 399/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4053 - accuracy: 0.8854 - val_loss: 0.4089 - val_accuracy: 0.8889 - lr: 3.1250e-05\n",
      "Epoch 400/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4165 - accuracy: 0.9097 - val_loss: 0.4133 - val_accuracy: 0.8889 - lr: 3.1250e-05\n",
      "Epoch 401/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3936 - accuracy: 0.9167 - val_loss: 0.4110 - val_accuracy: 0.9028 - lr: 3.1250e-05\n",
      "Epoch 402/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3904 - accuracy: 0.9167 - val_loss: 0.4028 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 403/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3770 - accuracy: 0.9340 - val_loss: 0.3979 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 404/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3809 - accuracy: 0.9271 - val_loss: 0.3970 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 405/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4249 - accuracy: 0.9062 - val_loss: 0.4055 - val_accuracy: 0.8889 - lr: 1.5625e-05\n",
      "Epoch 406/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3895 - accuracy: 0.9271 - val_loss: 0.4092 - val_accuracy: 0.8750 - lr: 1.5625e-05\n",
      "Epoch 407/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3731 - accuracy: 0.9479 - val_loss: 0.4046 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 408/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3986 - accuracy: 0.9132 - val_loss: 0.3983 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 409/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3933 - accuracy: 0.8924 - val_loss: 0.3928 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 410/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3817 - accuracy: 0.9236 - val_loss: 0.3932 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 411/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3629 - accuracy: 0.9271 - val_loss: 0.3940 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 412/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3854 - accuracy: 0.8993 - val_loss: 0.3953 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 413/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3750 - accuracy: 0.9236 - val_loss: 0.3957 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 414/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4032 - accuracy: 0.9271 - val_loss: 0.3976 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 415/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4171 - accuracy: 0.9062 - val_loss: 0.3970 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 416/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4129 - accuracy: 0.9132 - val_loss: 0.3979 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 417/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3846 - accuracy: 0.9097 - val_loss: 0.3956 - val_accuracy: 0.9444 - lr: 1.5625e-05\n",
      "Epoch 418/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3901 - accuracy: 0.8958 - val_loss: 0.3923 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 419/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4080 - accuracy: 0.9097 - val_loss: 0.3934 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 420/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3780 - accuracy: 0.9340 - val_loss: 0.3932 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 421/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3759 - accuracy: 0.9028 - val_loss: 0.3916 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 422/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4070 - accuracy: 0.9097 - val_loss: 0.3903 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 423/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3523 - accuracy: 0.9375 - val_loss: 0.3910 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 424/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3738 - accuracy: 0.9097 - val_loss: 0.3915 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 425/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3884 - accuracy: 0.9271 - val_loss: 0.3913 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 426/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3914 - accuracy: 0.9097 - val_loss: 0.3892 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 427/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3833 - accuracy: 0.9271 - val_loss: 0.3898 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 428/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3881 - accuracy: 0.9132 - val_loss: 0.3912 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 429/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3650 - accuracy: 0.9375 - val_loss: 0.3958 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 430/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3918 - accuracy: 0.9236 - val_loss: 0.3972 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 431/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3609 - accuracy: 0.9375 - val_loss: 0.3922 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 432/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3744 - accuracy: 0.9306 - val_loss: 0.3878 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 433/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.4027 - accuracy: 0.9062 - val_loss: 0.3896 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 434/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3933 - accuracy: 0.9132 - val_loss: 0.3935 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 435/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4109 - accuracy: 0.8993 - val_loss: 0.4024 - val_accuracy: 0.8750 - lr: 1.5625e-05\n",
      "Epoch 436/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3776 - accuracy: 0.9271 - val_loss: 0.4025 - val_accuracy: 0.8889 - lr: 1.5625e-05\n",
      "Epoch 437/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3754 - accuracy: 0.9167 - val_loss: 0.3941 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 438/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3799 - accuracy: 0.9097 - val_loss: 0.3864 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 439/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4142 - accuracy: 0.9097 - val_loss: 0.3856 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 440/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3639 - accuracy: 0.9306 - val_loss: 0.3853 - val_accuracy: 0.9028 - lr: 1.5625e-05\n",
      "Epoch 441/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3649 - accuracy: 0.9375 - val_loss: 0.3833 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 442/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3800 - accuracy: 0.9236 - val_loss: 0.3803 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 443/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3683 - accuracy: 0.9236 - val_loss: 0.3831 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 444/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3685 - accuracy: 0.9340 - val_loss: 0.3833 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 445/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3939 - accuracy: 0.9132 - val_loss: 0.3834 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 446/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3648 - accuracy: 0.9410 - val_loss: 0.3819 - val_accuracy: 0.9167 - lr: 1.5625e-05\n",
      "Epoch 447/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3658 - accuracy: 0.9340 - val_loss: 0.3819 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 448/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3564 - accuracy: 0.9479 - val_loss: 0.3819 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 449/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3895 - accuracy: 0.9236 - val_loss: 0.3813 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 450/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3723 - accuracy: 0.9271 - val_loss: 0.3807 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 451/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3922 - accuracy: 0.9201 - val_loss: 0.3802 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 452/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3614 - accuracy: 0.9340 - val_loss: 0.3838 - val_accuracy: 0.9306 - lr: 1.5625e-05\n",
      "Epoch 453/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3533 - accuracy: 0.9340 - val_loss: 0.3833 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 454/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3602 - accuracy: 0.9375 - val_loss: 0.3784 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 455/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3634 - accuracy: 0.9201 - val_loss: 0.3758 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 456/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3809 - accuracy: 0.9271 - val_loss: 0.3751 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 457/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.4057 - accuracy: 0.9236 - val_loss: 0.3818 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 458/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3799 - accuracy: 0.9201 - val_loss: 0.3897 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 459/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3650 - accuracy: 0.9306 - val_loss: 0.3905 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 460/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3709 - accuracy: 0.9201 - val_loss: 0.3830 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 461/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3847 - accuracy: 0.9236 - val_loss: 0.3823 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 462/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3616 - accuracy: 0.9236 - val_loss: 0.3808 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 463/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3752 - accuracy: 0.9132 - val_loss: 0.3774 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 464/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3861 - accuracy: 0.9236 - val_loss: 0.3791 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 465/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4083 - accuracy: 0.9167 - val_loss: 0.3835 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 466/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4223 - accuracy: 0.9410 - val_loss: 0.3806 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 467/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3561 - accuracy: 0.9306 - val_loss: 0.3768 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 468/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4104 - accuracy: 0.8993 - val_loss: 0.3739 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 469/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3868 - accuracy: 0.9062 - val_loss: 0.3785 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 470/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3752 - accuracy: 0.9201 - val_loss: 0.3793 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 471/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3851 - accuracy: 0.9340 - val_loss: 0.3781 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 472/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3723 - accuracy: 0.9271 - val_loss: 0.3786 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 473/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3655 - accuracy: 0.9306 - val_loss: 0.3752 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 474/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.4443 - accuracy: 0.9028 - val_loss: 0.3779 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 475/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3769 - accuracy: 0.9271 - val_loss: 0.3793 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 476/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3802 - accuracy: 0.9132 - val_loss: 0.3824 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 477/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3775 - accuracy: 0.9306 - val_loss: 0.3816 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 478/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3421 - accuracy: 0.9444 - val_loss: 0.3743 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 479/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3654 - accuracy: 0.9340 - val_loss: 0.3718 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 480/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3553 - accuracy: 0.9375 - val_loss: 0.3680 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 481/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3472 - accuracy: 0.9410 - val_loss: 0.3659 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 482/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3775 - accuracy: 0.9132 - val_loss: 0.3664 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 483/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3706 - accuracy: 0.9236 - val_loss: 0.3684 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 484/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.4196 - accuracy: 0.9340 - val_loss: 0.3726 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 485/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3617 - accuracy: 0.9444 - val_loss: 0.3750 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 486/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3672 - accuracy: 0.9201 - val_loss: 0.3719 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 487/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3610 - accuracy: 0.9306 - val_loss: 0.3700 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 488/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3933 - accuracy: 0.9132 - val_loss: 0.3710 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 489/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3779 - accuracy: 0.9306 - val_loss: 0.3710 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 490/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3832 - accuracy: 0.9271 - val_loss: 0.3752 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 491/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3915 - accuracy: 0.9167 - val_loss: 0.3780 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 492/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3806 - accuracy: 0.9271 - val_loss: 0.3764 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 493/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3665 - accuracy: 0.9340 - val_loss: 0.3770 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 494/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3675 - accuracy: 0.9236 - val_loss: 0.3768 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Epoch 495/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3491 - accuracy: 0.9340 - val_loss: 0.3705 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 496/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3806 - accuracy: 0.9132 - val_loss: 0.3651 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 497/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3870 - accuracy: 0.9097 - val_loss: 0.3641 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 498/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3991 - accuracy: 0.9375 - val_loss: 0.3662 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 499/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3677 - accuracy: 0.9375 - val_loss: 0.3664 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 500/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3605 - accuracy: 0.9340 - val_loss: 0.3641 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 501/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3652 - accuracy: 0.9271 - val_loss: 0.3627 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 502/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3428 - accuracy: 0.9444 - val_loss: 0.3601 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 503/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3799 - accuracy: 0.9271 - val_loss: 0.3596 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 504/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3489 - accuracy: 0.9410 - val_loss: 0.3596 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 505/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3603 - accuracy: 0.9340 - val_loss: 0.3590 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 506/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3551 - accuracy: 0.9375 - val_loss: 0.3585 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 507/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3898 - accuracy: 0.9340 - val_loss: 0.3617 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 508/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3555 - accuracy: 0.9375 - val_loss: 0.3646 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 509/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3838 - accuracy: 0.9306 - val_loss: 0.3751 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 510/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3660 - accuracy: 0.9340 - val_loss: 0.3756 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 511/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3689 - accuracy: 0.9201 - val_loss: 0.3709 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 512/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3762 - accuracy: 0.9271 - val_loss: 0.3660 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 513/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3503 - accuracy: 0.9306 - val_loss: 0.3638 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 514/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3785 - accuracy: 0.9271 - val_loss: 0.3592 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 515/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3894 - accuracy: 0.9028 - val_loss: 0.3590 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 516/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3635 - accuracy: 0.9236 - val_loss: 0.3602 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 517/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3483 - accuracy: 0.9410 - val_loss: 0.3605 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 518/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3544 - accuracy: 0.9410 - val_loss: 0.3585 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 519/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3860 - accuracy: 0.9271 - val_loss: 0.3581 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 520/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3633 - accuracy: 0.9167 - val_loss: 0.3582 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 521/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3657 - accuracy: 0.9410 - val_loss: 0.3550 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 522/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3909 - accuracy: 0.9306 - val_loss: 0.3553 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 523/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3810 - accuracy: 0.9375 - val_loss: 0.3570 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 524/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3711 - accuracy: 0.9271 - val_loss: 0.3581 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 525/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3436 - accuracy: 0.9618 - val_loss: 0.3580 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 526/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3870 - accuracy: 0.9097 - val_loss: 0.3580 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 527/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3563 - accuracy: 0.9410 - val_loss: 0.3574 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 528/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3452 - accuracy: 0.9375 - val_loss: 0.3547 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 529/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3486 - accuracy: 0.9444 - val_loss: 0.3522 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 530/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3907 - accuracy: 0.9167 - val_loss: 0.3523 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 531/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3608 - accuracy: 0.9340 - val_loss: 0.3528 - val_accuracy: 0.9306 - lr: 1.0000e-05\n",
      "Epoch 532/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3908 - accuracy: 0.9444 - val_loss: 0.3613 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 533/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3617 - accuracy: 0.9375 - val_loss: 0.3615 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 534/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3772 - accuracy: 0.9167 - val_loss: 0.3590 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 535/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3687 - accuracy: 0.9375 - val_loss: 0.3556 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 536/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3775 - accuracy: 0.9410 - val_loss: 0.3529 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 537/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3355 - accuracy: 0.9514 - val_loss: 0.3516 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 538/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3512 - accuracy: 0.9410 - val_loss: 0.3505 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 539/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.4140 - accuracy: 0.9201 - val_loss: 0.3505 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 540/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3635 - accuracy: 0.9375 - val_loss: 0.3492 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 541/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3306 - accuracy: 0.9479 - val_loss: 0.3475 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 542/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3297 - accuracy: 0.9549 - val_loss: 0.3454 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 543/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3422 - accuracy: 0.9444 - val_loss: 0.3441 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 544/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3576 - accuracy: 0.9340 - val_loss: 0.3447 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 545/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3536 - accuracy: 0.9340 - val_loss: 0.3470 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 546/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3459 - accuracy: 0.9375 - val_loss: 0.3474 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 547/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3476 - accuracy: 0.9549 - val_loss: 0.3537 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 548/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3699 - accuracy: 0.9410 - val_loss: 0.3530 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 549/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3334 - accuracy: 0.9306 - val_loss: 0.3510 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 550/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3429 - accuracy: 0.9444 - val_loss: 0.3521 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 551/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3621 - accuracy: 0.9236 - val_loss: 0.3498 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 552/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3469 - accuracy: 0.9306 - val_loss: 0.3470 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 553/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3460 - accuracy: 0.9549 - val_loss: 0.3441 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 554/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.4134 - accuracy: 0.9062 - val_loss: 0.3486 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 555/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3425 - accuracy: 0.9549 - val_loss: 0.3545 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 556/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3898 - accuracy: 0.9236 - val_loss: 0.3531 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 557/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3517 - accuracy: 0.9375 - val_loss: 0.3452 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 558/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3343 - accuracy: 0.9722 - val_loss: 0.3405 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 559/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3270 - accuracy: 0.9583 - val_loss: 0.3381 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 560/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3553 - accuracy: 0.9236 - val_loss: 0.3381 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 561/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3325 - accuracy: 0.9583 - val_loss: 0.3385 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 562/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.4084 - accuracy: 0.9271 - val_loss: 0.3397 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 563/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3747 - accuracy: 0.9340 - val_loss: 0.3423 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 564/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3373 - accuracy: 0.9479 - val_loss: 0.3415 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 565/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3742 - accuracy: 0.9201 - val_loss: 0.3412 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 566/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3466 - accuracy: 0.9479 - val_loss: 0.3426 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 567/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3555 - accuracy: 0.9306 - val_loss: 0.3391 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 568/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3516 - accuracy: 0.9410 - val_loss: 0.3371 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 569/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3950 - accuracy: 0.9201 - val_loss: 0.3425 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 570/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3630 - accuracy: 0.9306 - val_loss: 0.3498 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 571/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3481 - accuracy: 0.9410 - val_loss: 0.3441 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 572/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3378 - accuracy: 0.9410 - val_loss: 0.3381 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 573/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3694 - accuracy: 0.9410 - val_loss: 0.3351 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 574/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3603 - accuracy: 0.9549 - val_loss: 0.3339 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 575/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3435 - accuracy: 0.9306 - val_loss: 0.3333 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 576/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3688 - accuracy: 0.9410 - val_loss: 0.3334 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 577/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3676 - accuracy: 0.9306 - val_loss: 0.3348 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 578/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3724 - accuracy: 0.9375 - val_loss: 0.3334 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 579/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3289 - accuracy: 0.9549 - val_loss: 0.3323 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 580/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3518 - accuracy: 0.9618 - val_loss: 0.3354 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 581/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3524 - accuracy: 0.9306 - val_loss: 0.3394 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 582/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3424 - accuracy: 0.9410 - val_loss: 0.3409 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 583/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3336 - accuracy: 0.9618 - val_loss: 0.3385 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 584/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3586 - accuracy: 0.9410 - val_loss: 0.3358 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 585/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3325 - accuracy: 0.9514 - val_loss: 0.3335 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 586/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3502 - accuracy: 0.9479 - val_loss: 0.3354 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 587/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3524 - accuracy: 0.9340 - val_loss: 0.3343 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 588/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3749 - accuracy: 0.9410 - val_loss: 0.3312 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 589/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3552 - accuracy: 0.9410 - val_loss: 0.3274 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 590/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3424 - accuracy: 0.9444 - val_loss: 0.3242 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 591/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3600 - accuracy: 0.9514 - val_loss: 0.3250 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 592/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3447 - accuracy: 0.9444 - val_loss: 0.3271 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 593/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3493 - accuracy: 0.9618 - val_loss: 0.3301 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 594/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3403 - accuracy: 0.9583 - val_loss: 0.3287 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 595/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3596 - accuracy: 0.9271 - val_loss: 0.3265 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 596/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3785 - accuracy: 0.9306 - val_loss: 0.3254 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 597/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3695 - accuracy: 0.9271 - val_loss: 0.3256 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 598/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3423 - accuracy: 0.9549 - val_loss: 0.3251 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 599/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3213 - accuracy: 0.9757 - val_loss: 0.3206 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 600/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3599 - accuracy: 0.9514 - val_loss: 0.3172 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 601/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3701 - accuracy: 0.9375 - val_loss: 0.3168 - val_accuracy: 0.9444 - lr: 1.0000e-05\n",
      "Epoch 602/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3401 - accuracy: 0.9479 - val_loss: 0.3169 - val_accuracy: 0.9583 - lr: 1.0000e-05\n",
      "Epoch 603/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3425 - accuracy: 0.9514 - val_loss: 0.3162 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 604/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3321 - accuracy: 0.9444 - val_loss: 0.3165 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 605/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3448 - accuracy: 0.9410 - val_loss: 0.3175 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 606/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3471 - accuracy: 0.9479 - val_loss: 0.3200 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 607/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3413 - accuracy: 0.9410 - val_loss: 0.3206 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 608/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3252 - accuracy: 0.9583 - val_loss: 0.3158 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 609/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3393 - accuracy: 0.9479 - val_loss: 0.3141 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 610/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3312 - accuracy: 0.9583 - val_loss: 0.3143 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 611/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3713 - accuracy: 0.9340 - val_loss: 0.3147 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 612/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3980 - accuracy: 0.9410 - val_loss: 0.3204 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 613/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3420 - accuracy: 0.9410 - val_loss: 0.3216 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 614/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3563 - accuracy: 0.9444 - val_loss: 0.3187 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 615/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3327 - accuracy: 0.9514 - val_loss: 0.3184 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 616/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3566 - accuracy: 0.9479 - val_loss: 0.3174 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 617/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3683 - accuracy: 0.9410 - val_loss: 0.3208 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 618/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3595 - accuracy: 0.9132 - val_loss: 0.3191 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 619/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3230 - accuracy: 0.9653 - val_loss: 0.3198 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 620/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3694 - accuracy: 0.9306 - val_loss: 0.3181 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 621/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3128 - accuracy: 0.9653 - val_loss: 0.3159 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 622/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3758 - accuracy: 0.9167 - val_loss: 0.3139 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 623/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3523 - accuracy: 0.9306 - val_loss: 0.3147 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 624/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3248 - accuracy: 0.9653 - val_loss: 0.3135 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 625/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3358 - accuracy: 0.9549 - val_loss: 0.3127 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 626/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3595 - accuracy: 0.9583 - val_loss: 0.3129 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 627/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3562 - accuracy: 0.9340 - val_loss: 0.3136 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 628/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3476 - accuracy: 0.9410 - val_loss: 0.3146 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 629/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3286 - accuracy: 0.9618 - val_loss: 0.3116 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 630/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3611 - accuracy: 0.9340 - val_loss: 0.3087 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 631/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3373 - accuracy: 0.9618 - val_loss: 0.3081 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 632/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3291 - accuracy: 0.9549 - val_loss: 0.3060 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 633/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3349 - accuracy: 0.9514 - val_loss: 0.3052 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 634/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3269 - accuracy: 0.9479 - val_loss: 0.3042 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 635/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3482 - accuracy: 0.9375 - val_loss: 0.3075 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 636/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3346 - accuracy: 0.9479 - val_loss: 0.3079 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 637/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3298 - accuracy: 0.9549 - val_loss: 0.3077 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 638/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3325 - accuracy: 0.9653 - val_loss: 0.3033 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 639/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3345 - accuracy: 0.9549 - val_loss: 0.3019 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 640/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3424 - accuracy: 0.9479 - val_loss: 0.3023 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 641/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3113 - accuracy: 0.9653 - val_loss: 0.3011 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 642/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3314 - accuracy: 0.9479 - val_loss: 0.3013 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 643/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3641 - accuracy: 0.9444 - val_loss: 0.2997 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 644/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3422 - accuracy: 0.9479 - val_loss: 0.2993 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 645/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3348 - accuracy: 0.9444 - val_loss: 0.3012 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 646/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2931 - accuracy: 0.9861 - val_loss: 0.3016 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 647/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3620 - accuracy: 0.9514 - val_loss: 0.3007 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 648/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3465 - accuracy: 0.9549 - val_loss: 0.3036 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 649/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3461 - accuracy: 0.9479 - val_loss: 0.3091 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 650/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3483 - accuracy: 0.9549 - val_loss: 0.3053 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 651/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3504 - accuracy: 0.9549 - val_loss: 0.3009 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 652/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3752 - accuracy: 0.9236 - val_loss: 0.2983 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 653/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3370 - accuracy: 0.9444 - val_loss: 0.2966 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 654/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3229 - accuracy: 0.9549 - val_loss: 0.2952 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 655/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3497 - accuracy: 0.9479 - val_loss: 0.2949 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 656/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3455 - accuracy: 0.9549 - val_loss: 0.2948 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 657/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3243 - accuracy: 0.9618 - val_loss: 0.2958 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 658/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3131 - accuracy: 0.9618 - val_loss: 0.2957 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 659/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3391 - accuracy: 0.9514 - val_loss: 0.2951 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 660/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3168 - accuracy: 0.9479 - val_loss: 0.2951 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 661/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3278 - accuracy: 0.9618 - val_loss: 0.2960 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 662/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3294 - accuracy: 0.9653 - val_loss: 0.2945 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 663/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3146 - accuracy: 0.9618 - val_loss: 0.2928 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 664/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3429 - accuracy: 0.9444 - val_loss: 0.2927 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 665/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3619 - accuracy: 0.9444 - val_loss: 0.2937 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 666/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3175 - accuracy: 0.9688 - val_loss: 0.2929 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 667/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3436 - accuracy: 0.9410 - val_loss: 0.2904 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 668/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3274 - accuracy: 0.9618 - val_loss: 0.2887 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 669/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3165 - accuracy: 0.9583 - val_loss: 0.2868 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 670/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3412 - accuracy: 0.9514 - val_loss: 0.2860 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 671/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2988 - accuracy: 0.9618 - val_loss: 0.2857 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 672/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3568 - accuracy: 0.9375 - val_loss: 0.2882 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 673/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3343 - accuracy: 0.9514 - val_loss: 0.2870 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 674/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3506 - accuracy: 0.9583 - val_loss: 0.2871 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 675/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3488 - accuracy: 0.9583 - val_loss: 0.2883 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 676/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3370 - accuracy: 0.9549 - val_loss: 0.2873 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 677/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3589 - accuracy: 0.9549 - val_loss: 0.2849 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 678/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3288 - accuracy: 0.9688 - val_loss: 0.2848 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 679/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3159 - accuracy: 0.9618 - val_loss: 0.2861 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 680/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3228 - accuracy: 0.9514 - val_loss: 0.2853 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 681/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3504 - accuracy: 0.9375 - val_loss: 0.2844 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 682/1000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3239 - accuracy: 0.9653 - val_loss: 0.2838 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 683/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3007 - accuracy: 0.9757 - val_loss: 0.2840 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 684/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3238 - accuracy: 0.9444 - val_loss: 0.2846 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 685/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3383 - accuracy: 0.9618 - val_loss: 0.2842 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 686/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3180 - accuracy: 0.9618 - val_loss: 0.2823 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 687/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3094 - accuracy: 0.9722 - val_loss: 0.2815 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 688/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3046 - accuracy: 0.9688 - val_loss: 0.2804 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 689/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3216 - accuracy: 0.9514 - val_loss: 0.2802 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 690/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3215 - accuracy: 0.9653 - val_loss: 0.2806 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 691/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3165 - accuracy: 0.9618 - val_loss: 0.2807 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 692/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3188 - accuracy: 0.9479 - val_loss: 0.2805 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 693/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3300 - accuracy: 0.9618 - val_loss: 0.2798 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 694/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3350 - accuracy: 0.9618 - val_loss: 0.2800 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 695/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3154 - accuracy: 0.9549 - val_loss: 0.2829 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 696/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3168 - accuracy: 0.9618 - val_loss: 0.2792 - val_accuracy: 0.9722 - lr: 1.0000e-05\n",
      "Epoch 697/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3226 - accuracy: 0.9653 - val_loss: 0.2776 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 698/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3308 - accuracy: 0.9618 - val_loss: 0.2769 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 699/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3309 - accuracy: 0.9444 - val_loss: 0.2760 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 700/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3250 - accuracy: 0.9653 - val_loss: 0.2765 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 701/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3069 - accuracy: 0.9653 - val_loss: 0.2750 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 702/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3199 - accuracy: 0.9653 - val_loss: 0.2748 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 703/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3218 - accuracy: 0.9653 - val_loss: 0.2781 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 704/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3158 - accuracy: 0.9618 - val_loss: 0.2766 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 705/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3097 - accuracy: 0.9722 - val_loss: 0.2748 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 706/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3158 - accuracy: 0.9653 - val_loss: 0.2717 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 707/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3097 - accuracy: 0.9688 - val_loss: 0.2712 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 708/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3222 - accuracy: 0.9583 - val_loss: 0.2696 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 709/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3094 - accuracy: 0.9688 - val_loss: 0.2680 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 710/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3478 - accuracy: 0.9549 - val_loss: 0.2675 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 711/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3126 - accuracy: 0.9549 - val_loss: 0.2672 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 712/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2924 - accuracy: 0.9792 - val_loss: 0.2671 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 713/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3067 - accuracy: 0.9653 - val_loss: 0.2659 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 714/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2881 - accuracy: 0.9826 - val_loss: 0.2658 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 715/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3314 - accuracy: 0.9549 - val_loss: 0.2660 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 716/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3518 - accuracy: 0.9514 - val_loss: 0.2651 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 717/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3180 - accuracy: 0.9688 - val_loss: 0.2654 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 718/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3331 - accuracy: 0.9514 - val_loss: 0.2662 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 719/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3077 - accuracy: 0.9653 - val_loss: 0.2656 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 720/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3130 - accuracy: 0.9688 - val_loss: 0.2643 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 721/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2920 - accuracy: 0.9618 - val_loss: 0.2644 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 722/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2914 - accuracy: 0.9826 - val_loss: 0.2639 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 723/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3269 - accuracy: 0.9514 - val_loss: 0.2637 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 724/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2884 - accuracy: 0.9757 - val_loss: 0.2638 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 725/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3061 - accuracy: 0.9757 - val_loss: 0.2623 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 726/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3156 - accuracy: 0.9688 - val_loss: 0.2609 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 727/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3033 - accuracy: 0.9653 - val_loss: 0.2601 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 728/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3301 - accuracy: 0.9583 - val_loss: 0.2596 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 729/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2998 - accuracy: 0.9688 - val_loss: 0.2596 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 730/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3064 - accuracy: 0.9792 - val_loss: 0.2597 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 731/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3010 - accuracy: 0.9688 - val_loss: 0.2594 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 732/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3197 - accuracy: 0.9618 - val_loss: 0.2585 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 733/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2876 - accuracy: 0.9757 - val_loss: 0.2582 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 734/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2989 - accuracy: 0.9653 - val_loss: 0.2572 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 735/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2891 - accuracy: 0.9688 - val_loss: 0.2567 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 736/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2963 - accuracy: 0.9757 - val_loss: 0.2556 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 737/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2785 - accuracy: 0.9792 - val_loss: 0.2551 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 738/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3052 - accuracy: 0.9653 - val_loss: 0.2548 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 739/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3179 - accuracy: 0.9653 - val_loss: 0.2534 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 740/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3101 - accuracy: 0.9549 - val_loss: 0.2519 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 741/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3038 - accuracy: 0.9653 - val_loss: 0.2512 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 742/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2889 - accuracy: 0.9688 - val_loss: 0.2517 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 743/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2927 - accuracy: 0.9653 - val_loss: 0.2524 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 744/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3269 - accuracy: 0.9653 - val_loss: 0.2514 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 745/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3161 - accuracy: 0.9653 - val_loss: 0.2503 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 746/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3339 - accuracy: 0.9618 - val_loss: 0.2523 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 747/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3317 - accuracy: 0.9618 - val_loss: 0.2530 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 748/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3059 - accuracy: 0.9618 - val_loss: 0.2536 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 749/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3379 - accuracy: 0.9688 - val_loss: 0.2564 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 750/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3068 - accuracy: 0.9653 - val_loss: 0.2534 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 751/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3124 - accuracy: 0.9653 - val_loss: 0.2514 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 752/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2969 - accuracy: 0.9792 - val_loss: 0.2511 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 753/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3325 - accuracy: 0.9583 - val_loss: 0.2514 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 754/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3285 - accuracy: 0.9514 - val_loss: 0.2512 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 755/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.3109 - accuracy: 0.9653 - val_loss: 0.2508 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 756/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2991 - accuracy: 0.9688 - val_loss: 0.2509 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 757/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2993 - accuracy: 0.9792 - val_loss: 0.2507 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 758/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3058 - accuracy: 0.9757 - val_loss: 0.2511 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 759/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3019 - accuracy: 0.9688 - val_loss: 0.2499 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 760/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3043 - accuracy: 0.9653 - val_loss: 0.2493 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 761/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3104 - accuracy: 0.9653 - val_loss: 0.2490 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 762/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3032 - accuracy: 0.9688 - val_loss: 0.2497 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 763/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2959 - accuracy: 0.9688 - val_loss: 0.2501 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 764/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2955 - accuracy: 0.9757 - val_loss: 0.2481 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 765/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3230 - accuracy: 0.9549 - val_loss: 0.2482 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 766/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2988 - accuracy: 0.9688 - val_loss: 0.2483 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 767/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2940 - accuracy: 0.9792 - val_loss: 0.2483 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 768/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2978 - accuracy: 0.9722 - val_loss: 0.2487 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 769/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2964 - accuracy: 0.9792 - val_loss: 0.2485 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 770/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2872 - accuracy: 0.9653 - val_loss: 0.2484 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 771/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3121 - accuracy: 0.9722 - val_loss: 0.2485 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 772/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2897 - accuracy: 0.9688 - val_loss: 0.2477 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 773/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2871 - accuracy: 0.9861 - val_loss: 0.2463 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 774/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3051 - accuracy: 0.9722 - val_loss: 0.2461 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 775/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3083 - accuracy: 0.9618 - val_loss: 0.2452 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 776/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3006 - accuracy: 0.9688 - val_loss: 0.2461 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 777/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2931 - accuracy: 0.9618 - val_loss: 0.2458 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 778/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2898 - accuracy: 0.9722 - val_loss: 0.2452 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 779/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2982 - accuracy: 0.9757 - val_loss: 0.2440 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 780/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3201 - accuracy: 0.9688 - val_loss: 0.2422 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 781/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2903 - accuracy: 0.9722 - val_loss: 0.2411 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 782/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3103 - accuracy: 0.9549 - val_loss: 0.2423 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 783/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3158 - accuracy: 0.9722 - val_loss: 0.2413 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 784/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2922 - accuracy: 0.9722 - val_loss: 0.2388 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 785/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2767 - accuracy: 0.9722 - val_loss: 0.2381 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 786/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3089 - accuracy: 0.9618 - val_loss: 0.2392 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 787/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3117 - accuracy: 0.9688 - val_loss: 0.2404 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 788/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2738 - accuracy: 0.9722 - val_loss: 0.2416 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 789/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3132 - accuracy: 0.9688 - val_loss: 0.2424 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 790/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2887 - accuracy: 0.9792 - val_loss: 0.2391 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 791/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2928 - accuracy: 0.9722 - val_loss: 0.2417 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 792/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2827 - accuracy: 0.9861 - val_loss: 0.2436 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 793/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2874 - accuracy: 0.9722 - val_loss: 0.2369 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 794/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2871 - accuracy: 0.9653 - val_loss: 0.2371 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 795/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3063 - accuracy: 0.9618 - val_loss: 0.2361 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 796/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2798 - accuracy: 0.9792 - val_loss: 0.2347 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 797/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2947 - accuracy: 0.9653 - val_loss: 0.2335 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 798/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2970 - accuracy: 0.9722 - val_loss: 0.2332 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 799/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2827 - accuracy: 0.9792 - val_loss: 0.2326 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 800/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2762 - accuracy: 0.9757 - val_loss: 0.2322 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 801/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2926 - accuracy: 0.9688 - val_loss: 0.2314 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 802/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2973 - accuracy: 0.9688 - val_loss: 0.2319 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 803/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2650 - accuracy: 0.9826 - val_loss: 0.2313 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 804/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3011 - accuracy: 0.9722 - val_loss: 0.2317 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 805/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2838 - accuracy: 0.9653 - val_loss: 0.2321 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 806/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3054 - accuracy: 0.9722 - val_loss: 0.2321 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 807/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2714 - accuracy: 0.9861 - val_loss: 0.2327 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 808/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2933 - accuracy: 0.9653 - val_loss: 0.2323 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 809/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2836 - accuracy: 0.9757 - val_loss: 0.2317 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 810/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2890 - accuracy: 0.9757 - val_loss: 0.2319 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 811/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2768 - accuracy: 0.9792 - val_loss: 0.2333 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 812/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2869 - accuracy: 0.9896 - val_loss: 0.2330 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 813/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3074 - accuracy: 0.9688 - val_loss: 0.2316 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 814/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2944 - accuracy: 0.9861 - val_loss: 0.2306 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 815/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3197 - accuracy: 0.9688 - val_loss: 0.2301 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 816/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2740 - accuracy: 0.9757 - val_loss: 0.2311 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 817/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2807 - accuracy: 0.9826 - val_loss: 0.2315 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 818/1000\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2808 - accuracy: 0.9792 - val_loss: 0.2304 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 819/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2804 - accuracy: 0.9861 - val_loss: 0.2297 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 820/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2595 - accuracy: 0.9896 - val_loss: 0.2294 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 821/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3007 - accuracy: 0.9653 - val_loss: 0.2290 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 822/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2715 - accuracy: 0.9896 - val_loss: 0.2308 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 823/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3149 - accuracy: 0.9688 - val_loss: 0.2312 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 824/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2985 - accuracy: 0.9688 - val_loss: 0.2295 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 825/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2976 - accuracy: 0.9792 - val_loss: 0.2300 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 826/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3064 - accuracy: 0.9618 - val_loss: 0.2298 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 827/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2748 - accuracy: 0.9861 - val_loss: 0.2316 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 828/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2804 - accuracy: 0.9826 - val_loss: 0.2322 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 829/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2623 - accuracy: 0.9861 - val_loss: 0.2310 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 830/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3005 - accuracy: 0.9618 - val_loss: 0.2284 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 831/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2761 - accuracy: 0.9757 - val_loss: 0.2275 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 832/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2448 - accuracy: 0.9931 - val_loss: 0.2261 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 833/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2820 - accuracy: 0.9826 - val_loss: 0.2251 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 834/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2696 - accuracy: 0.9722 - val_loss: 0.2264 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 835/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2742 - accuracy: 0.9861 - val_loss: 0.2254 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 836/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2864 - accuracy: 0.9757 - val_loss: 0.2245 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 837/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2777 - accuracy: 0.9757 - val_loss: 0.2248 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 838/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3196 - accuracy: 0.9757 - val_loss: 0.2252 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 839/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2992 - accuracy: 0.9653 - val_loss: 0.2263 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 840/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2734 - accuracy: 0.9861 - val_loss: 0.2289 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 841/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2829 - accuracy: 0.9826 - val_loss: 0.2327 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 842/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2941 - accuracy: 0.9757 - val_loss: 0.2305 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 843/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2807 - accuracy: 0.9688 - val_loss: 0.2288 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 844/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2747 - accuracy: 0.9792 - val_loss: 0.2293 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 845/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2918 - accuracy: 0.9757 - val_loss: 0.2277 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 846/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2815 - accuracy: 0.9792 - val_loss: 0.2268 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 847/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2675 - accuracy: 0.9861 - val_loss: 0.2273 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 848/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2855 - accuracy: 0.9722 - val_loss: 0.2282 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 849/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2584 - accuracy: 0.9861 - val_loss: 0.2304 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 850/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2954 - accuracy: 0.9757 - val_loss: 0.2271 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 851/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3241 - accuracy: 0.9618 - val_loss: 0.2261 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 852/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3072 - accuracy: 0.9688 - val_loss: 0.2250 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 853/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2791 - accuracy: 0.9757 - val_loss: 0.2256 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 854/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3067 - accuracy: 0.9688 - val_loss: 0.2238 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 855/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2705 - accuracy: 0.9826 - val_loss: 0.2241 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 856/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2640 - accuracy: 0.9896 - val_loss: 0.2238 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 857/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2724 - accuracy: 0.9861 - val_loss: 0.2245 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 858/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3138 - accuracy: 0.9826 - val_loss: 0.2248 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 859/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2702 - accuracy: 0.9826 - val_loss: 0.2233 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 860/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3264 - accuracy: 0.9757 - val_loss: 0.2216 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 861/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2556 - accuracy: 0.9965 - val_loss: 0.2213 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 862/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2728 - accuracy: 0.9722 - val_loss: 0.2225 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 863/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2592 - accuracy: 0.9826 - val_loss: 0.2220 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 864/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2788 - accuracy: 0.9792 - val_loss: 0.2224 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 865/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3186 - accuracy: 0.9514 - val_loss: 0.2230 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 866/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2779 - accuracy: 0.9861 - val_loss: 0.2241 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 867/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2851 - accuracy: 0.9722 - val_loss: 0.2264 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 868/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2745 - accuracy: 0.9861 - val_loss: 0.2255 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 869/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2796 - accuracy: 0.9826 - val_loss: 0.2242 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 870/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2622 - accuracy: 0.9826 - val_loss: 0.2238 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 871/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2725 - accuracy: 0.9757 - val_loss: 0.2229 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 872/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2695 - accuracy: 0.9826 - val_loss: 0.2215 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 873/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2666 - accuracy: 0.9792 - val_loss: 0.2209 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 874/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2636 - accuracy: 0.9861 - val_loss: 0.2205 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 875/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3009 - accuracy: 0.9653 - val_loss: 0.2215 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 876/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2630 - accuracy: 0.9931 - val_loss: 0.2204 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 877/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2854 - accuracy: 0.9757 - val_loss: 0.2203 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 878/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2775 - accuracy: 0.9757 - val_loss: 0.2198 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 879/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2604 - accuracy: 0.9931 - val_loss: 0.2211 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 880/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2783 - accuracy: 0.9792 - val_loss: 0.2198 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 881/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2617 - accuracy: 0.9896 - val_loss: 0.2189 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 882/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2777 - accuracy: 0.9792 - val_loss: 0.2194 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 883/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2857 - accuracy: 0.9722 - val_loss: 0.2207 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 884/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2865 - accuracy: 0.9722 - val_loss: 0.2216 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 885/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2639 - accuracy: 0.9896 - val_loss: 0.2203 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 886/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2642 - accuracy: 0.9896 - val_loss: 0.2192 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 887/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2625 - accuracy: 0.9757 - val_loss: 0.2179 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 888/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2530 - accuracy: 0.9896 - val_loss: 0.2176 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 889/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2698 - accuracy: 0.9792 - val_loss: 0.2165 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 890/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3057 - accuracy: 0.9792 - val_loss: 0.2161 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 891/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2766 - accuracy: 0.9896 - val_loss: 0.2164 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 892/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2827 - accuracy: 0.9688 - val_loss: 0.2163 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 893/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3201 - accuracy: 0.9792 - val_loss: 0.2159 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 894/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2866 - accuracy: 0.9757 - val_loss: 0.2156 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 895/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2711 - accuracy: 0.9722 - val_loss: 0.2170 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 896/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2730 - accuracy: 0.9792 - val_loss: 0.2171 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 897/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2699 - accuracy: 0.9826 - val_loss: 0.2171 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 898/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2647 - accuracy: 0.9826 - val_loss: 0.2180 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 899/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2731 - accuracy: 0.9792 - val_loss: 0.2176 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 900/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3087 - accuracy: 0.9653 - val_loss: 0.2160 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 901/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2768 - accuracy: 0.9826 - val_loss: 0.2160 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 902/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2582 - accuracy: 0.9896 - val_loss: 0.2155 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 903/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2835 - accuracy: 0.9826 - val_loss: 0.2151 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 904/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2872 - accuracy: 0.9861 - val_loss: 0.2150 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 905/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2379 - accuracy: 0.9896 - val_loss: 0.2148 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 906/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2654 - accuracy: 0.9861 - val_loss: 0.2147 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 907/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2748 - accuracy: 0.9792 - val_loss: 0.2157 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 908/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2610 - accuracy: 0.9861 - val_loss: 0.2178 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 909/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2671 - accuracy: 0.9653 - val_loss: 0.2177 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 910/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2607 - accuracy: 0.9792 - val_loss: 0.2167 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 911/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2664 - accuracy: 0.9826 - val_loss: 0.2149 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 912/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2670 - accuracy: 0.9792 - val_loss: 0.2145 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 913/1000\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.2663 - accuracy: 0.9896 - val_loss: 0.2146 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 914/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2717 - accuracy: 0.9861 - val_loss: 0.2145 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 915/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2551 - accuracy: 0.9826 - val_loss: 0.2147 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 916/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2589 - accuracy: 0.9896 - val_loss: 0.2170 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 917/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3036 - accuracy: 0.9792 - val_loss: 0.2158 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 918/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2472 - accuracy: 0.9931 - val_loss: 0.2157 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 919/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2378 - accuracy: 0.9965 - val_loss: 0.2158 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 920/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2713 - accuracy: 0.9722 - val_loss: 0.2156 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 921/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2626 - accuracy: 0.9861 - val_loss: 0.2176 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 922/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2511 - accuracy: 0.9861 - val_loss: 0.2169 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 923/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3102 - accuracy: 0.9826 - val_loss: 0.2154 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 924/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2703 - accuracy: 0.9861 - val_loss: 0.2141 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 925/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2467 - accuracy: 0.9861 - val_loss: 0.2139 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 926/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2717 - accuracy: 0.9861 - val_loss: 0.2141 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 927/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2857 - accuracy: 0.9757 - val_loss: 0.2150 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 928/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2502 - accuracy: 0.9931 - val_loss: 0.2137 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 929/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2565 - accuracy: 0.9826 - val_loss: 0.2129 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 930/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2571 - accuracy: 0.9826 - val_loss: 0.2133 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 931/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2594 - accuracy: 0.9826 - val_loss: 0.2130 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 932/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2434 - accuracy: 0.9965 - val_loss: 0.2133 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 933/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2669 - accuracy: 0.9826 - val_loss: 0.2142 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 934/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2651 - accuracy: 0.9931 - val_loss: 0.2168 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 935/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2383 - accuracy: 0.9931 - val_loss: 0.2159 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 936/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2518 - accuracy: 0.9826 - val_loss: 0.2162 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 937/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2917 - accuracy: 0.9653 - val_loss: 0.2154 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 938/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2808 - accuracy: 0.9688 - val_loss: 0.2144 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 939/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2657 - accuracy: 0.9896 - val_loss: 0.2143 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 940/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2624 - accuracy: 0.9861 - val_loss: 0.2137 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 941/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2544 - accuracy: 0.9861 - val_loss: 0.2174 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 942/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2495 - accuracy: 0.9965 - val_loss: 0.2200 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 943/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2801 - accuracy: 0.9896 - val_loss: 0.2153 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 944/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2704 - accuracy: 0.9757 - val_loss: 0.2133 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 945/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2309 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 946/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2769 - accuracy: 0.9792 - val_loss: 0.2127 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 947/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2787 - accuracy: 0.9861 - val_loss: 0.2155 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 948/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2393 - accuracy: 0.9965 - val_loss: 0.2164 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 949/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2442 - accuracy: 0.9826 - val_loss: 0.2143 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 950/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2416 - accuracy: 0.9931 - val_loss: 0.2129 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 951/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2611 - accuracy: 0.9826 - val_loss: 0.2121 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 952/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2788 - accuracy: 0.9792 - val_loss: 0.2125 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 953/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2543 - accuracy: 0.9931 - val_loss: 0.2130 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 954/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2562 - accuracy: 0.9861 - val_loss: 0.2128 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 955/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2638 - accuracy: 0.9861 - val_loss: 0.2130 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 956/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2533 - accuracy: 0.9896 - val_loss: 0.2129 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 957/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2490 - accuracy: 0.9931 - val_loss: 0.2124 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 958/1000\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2673 - accuracy: 0.9861 - val_loss: 0.2118 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 959/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2745 - accuracy: 0.9826 - val_loss: 0.2122 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 960/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2592 - accuracy: 0.9792 - val_loss: 0.2127 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 961/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2677 - accuracy: 0.9896 - val_loss: 0.2132 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 962/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2595 - accuracy: 0.9826 - val_loss: 0.2124 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 963/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2811 - accuracy: 0.9861 - val_loss: 0.2122 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 964/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2710 - accuracy: 0.9826 - val_loss: 0.2122 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 965/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2810 - accuracy: 0.9757 - val_loss: 0.2121 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 966/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2576 - accuracy: 0.9861 - val_loss: 0.2119 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 967/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2399 - accuracy: 0.9965 - val_loss: 0.2140 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 968/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3115 - accuracy: 0.9792 - val_loss: 0.2143 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 969/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2475 - accuracy: 0.9861 - val_loss: 0.2123 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 970/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2522 - accuracy: 0.9861 - val_loss: 0.2120 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 971/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2689 - accuracy: 0.9792 - val_loss: 0.2138 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 972/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2721 - accuracy: 0.9722 - val_loss: 0.2148 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 973/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2706 - accuracy: 0.9792 - val_loss: 0.2115 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 974/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2548 - accuracy: 0.9896 - val_loss: 0.2114 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 975/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2486 - accuracy: 0.9965 - val_loss: 0.2119 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 976/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2510 - accuracy: 0.9931 - val_loss: 0.2117 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 977/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2543 - accuracy: 0.9826 - val_loss: 0.2120 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 978/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2529 - accuracy: 0.9931 - val_loss: 0.2110 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 979/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2468 - accuracy: 0.9861 - val_loss: 0.2111 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 980/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2656 - accuracy: 0.9826 - val_loss: 0.2105 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 981/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2866 - accuracy: 0.9792 - val_loss: 0.2145 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 982/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2529 - accuracy: 0.9826 - val_loss: 0.2132 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 983/1000\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2616 - accuracy: 0.9757 - val_loss: 0.2107 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 984/1000\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.2575 - accuracy: 0.9861 - val_loss: 0.2104 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 985/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2675 - accuracy: 0.9896 - val_loss: 0.2105 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 986/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2623 - accuracy: 0.9861 - val_loss: 0.2110 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 987/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2622 - accuracy: 0.9757 - val_loss: 0.2118 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 988/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3119 - accuracy: 0.9826 - val_loss: 0.2123 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 989/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2569 - accuracy: 0.9861 - val_loss: 0.2121 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 990/1000\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2612 - accuracy: 0.9896 - val_loss: 0.2113 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 991/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2558 - accuracy: 0.9896 - val_loss: 0.2108 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 992/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2505 - accuracy: 0.9861 - val_loss: 0.2108 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 993/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2400 - accuracy: 0.9965 - val_loss: 0.2103 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 994/1000\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.2421 - accuracy: 0.9861 - val_loss: 0.2105 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 995/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2679 - accuracy: 0.9826 - val_loss: 0.2117 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 996/1000\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.2588 - accuracy: 0.9792 - val_loss: 0.2121 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 997/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2754 - accuracy: 0.9653 - val_loss: 0.2099 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 998/1000\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2684 - accuracy: 0.9896 - val_loss: 0.2104 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 999/1000\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.2458 - accuracy: 0.9931 - val_loss: 0.2108 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 1000/1000\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2507 - accuracy: 0.9896 - val_loss: 0.2111 - val_accuracy: 1.0000 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# TensorBoard callback for logging\n",
    "log_dir = os.path.join(create_log_dir(os.path.join(\"../drive/logs/asl_action_6\"), True))\n",
    "\n",
    "tensor_board_cb = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# train the model with the callbacks\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[tensor_board_cb, early_stopping, early_stopping_by_loss_val, reduce_lr],\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving The Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_filename(directory, base_name, extension):\n",
    "    # list all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    # filter files that start with the base_name and end with the extension\n",
    "    relevant_files = [\n",
    "        f for f in files if f.startswith(base_name) and f.endswith(extension)\n",
    "    ]\n",
    "\n",
    "    if not relevant_files and base_name == \"asl-action-weight\":\n",
    "        # if no relevant files found, start with 001\n",
    "        return f\"{base_name}-001.{extension}\"\n",
    "\n",
    "    if not base_name == \"asl-action-weight\":\n",
    "        return f\"{base_name}.{extension}\"\n",
    "\n",
    "    # extract the numeric part and find the highest number\n",
    "    numbers = [int(f[len(base_name) + 1 : -len(extension) - 1]) for f in relevant_files]\n",
    "    next_number = max(numbers) + 1\n",
    "\n",
    "    # format the next number with leading zeros to maintain the same length\n",
    "    next_filename = f\"{base_name}-{next_number:03d}.{extension}\"\n",
    "    return next_filename\n",
    "\n",
    "\n",
    "def model_save(\n",
    "    model, directory=\"../models/legacy\", base_name=\"asl-action-weight\", extension=\"h5\"\n",
    "):\n",
    "    next_filename = get_next_filename(directory, base_name, extension)\n",
    "    model_path = os.path.join(directory, next_filename)\n",
    "\n",
    "    if extension == \"tflite\":\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "        # See issue here:\n",
    "        # - https://github.com/tensorflow/tensorflow/issues/26869\n",
    "        # - https://github.com/tensorflow/tensorflow/issues/26869#issuecomment-474984631\n",
    "        # - https://github.com/tensorflow/tensorflow/issues/61662\n",
    "        # - https://stackoverflow.com/a/67252118/14182545\n",
    "        converter.target_spec.supported_ops = [\n",
    "            tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "            tf.lite.OpsSet.SELECT_TF_OPS,  # enable TensorFlow ops.\n",
    "        ]\n",
    "\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        print(f\"Model saved as {next_filename}\")\n",
    "        return\n",
    "\n",
    "    save_model(model, model_path)\n",
    "\n",
    "    print(f\"Model saved as {next_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e6-2.9M.keras\n",
      "Model saved as asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e6-2.9M.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Local\\Temp\\ipykernel_6432\\2091103176.py:54: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model, model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\acer\\AppData\\Local\\Temp\\tmpjqk9b5tv\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\acer\\AppData\\Local\\Temp\\tmpjqk9b5tv\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e6-2.9M.tflite\n"
     ]
    }
   ],
   "source": [
    "model_save(model, directory=\"../drive/models/keras\", base_name=\"asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e6-2.9M\", extension=\"keras\")\n",
    "model_save(model, directory=\"../drive/models/legacy\", base_name=\"asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e6-2.9M\", extension=\"h5\")\n",
    "model_save(model, directory=\"../drive/models/tflite\", base_name=\"asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e6-2.9M\", extension=\"tflite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(ACTIONS))\n",
    "plt.xticks(tick_marks, ACTIONS, rotation=45)\n",
    "plt.yticks(tick_marks, ACTIONS)\n",
    "\n",
    "# add labels\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# compute and print accuracy score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
