{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import models  # type: ignore\n",
    "from tensorflow.keras.callbacks import (Callback,  # type: ignore\n",
    "                                        EarlyStopping, ReduceLROnPlateau,\n",
    "                                        TensorBoard)\n",
    "from tensorflow.keras.optimizers import Adam  # type: ignore\n",
    "from tensorflow.keras.regularizers import l2  # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up for data training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocssed dataset path\n",
    "DATASET_PATH = os.path.join(\"../storage/datasets/cleaned\")\n",
    "\n",
    "# actions to be detected\n",
    "ACTIONS = [\n",
    "    \"_\", \"hello\", \"thanks\", \"i-love-you\", \"I\", \"Yes\", \"No\", \"Help\", \"Please\",\n",
    "    \"Want\", \"Eat\", \"More\", \"Bathroom\", \"Learn\", \"Sign\",\n",
    "]\n",
    "\n",
    "# limit to first x actions for testing\n",
    "ACTIONS = np.array(ACTIONS[:8])\n",
    "\n",
    "# number of videos and actions per video\n",
    "\n",
    "# current dataset have 120 video, so technically:\n",
    "# 120 for processed image (not flipped horizontally)\n",
    "# 120 for processed image (flipped horizontally)\n",
    "videos_per_label = 240\n",
    "\n",
    "# 60 frame per video\n",
    "frames_per_video = 60\n",
    "\n",
    "# data labels\n",
    "labels_map = {label: index for index, label in enumerate(ACTIONS)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(landmarks, noise_level, shape=(60, 225)):\n",
    "    noise = np.random.normal(loc=0, scale=noise_level, size=shape)\n",
    "    return landmarks + noise\n",
    "\n",
    "\n",
    "def shift_landmarks(landmarks, shift_factor, shape=(60, 225)):\n",
    "    shift = np.random.uniform(-shift_factor, shift_factor, size=shape[1:])\n",
    "    return landmarks + shift\n",
    "\n",
    "\n",
    "def augment_landmarks(landmarks, noise_level=0.01, shift_factor=0.1):\n",
    "    if random.random() > 0.6:\n",
    "        landmarks = add_noise(landmarks, noise_level)\n",
    "\n",
    "    if random.random() > 0.6:\n",
    "        landmarks = shift_landmarks(landmarks, shift_factor)\n",
    "\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and Augment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_path = os.path.join(\"./data\", \"sequences.npy\")\n",
    "lab_path = os.path.join(\"./data\", \"labels.npy\")\n",
    "\n",
    "sequences, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA IS BEING GENERATED AND LOADED\n",
      "_ - 0\n",
      "_ - 1\n",
      "_ - 2\n",
      "_ - 3\n",
      "_ - 4\n",
      "_ - 5\n",
      "_ - 6\n",
      "_ - 7\n",
      "_ - 8\n",
      "_ - 9\n",
      "_ - 10\n",
      "_ - 11\n",
      "_ - 12\n",
      "_ - 13\n",
      "_ - 14\n",
      "_ - 15\n",
      "_ - 16\n",
      "_ - 17\n",
      "_ - 18\n",
      "_ - 19\n",
      "_ - 20\n",
      "_ - 21\n",
      "_ - 22\n",
      "_ - 23\n",
      "_ - 24\n",
      "_ - 25\n",
      "_ - 26\n",
      "_ - 27\n",
      "_ - 28\n",
      "_ - 29\n",
      "_ - 30\n",
      "_ - 31\n",
      "_ - 32\n",
      "_ - 33\n",
      "_ - 34\n",
      "_ - 35\n",
      "_ - 36\n",
      "_ - 37\n",
      "_ - 38\n",
      "_ - 39\n",
      "_ - 40\n",
      "_ - 41\n",
      "_ - 42\n",
      "_ - 43\n",
      "_ - 44\n",
      "_ - 45\n",
      "_ - 46\n",
      "_ - 47\n",
      "_ - 48\n",
      "_ - 49\n",
      "_ - 50\n",
      "_ - 51\n",
      "_ - 52\n",
      "_ - 53\n",
      "_ - 54\n",
      "_ - 55\n",
      "_ - 56\n",
      "_ - 57\n",
      "_ - 58\n",
      "_ - 59\n",
      "_ - 60\n",
      "_ - 61\n",
      "_ - 62\n",
      "_ - 63\n",
      "_ - 64\n",
      "_ - 65\n",
      "_ - 66\n",
      "_ - 67\n",
      "_ - 68\n",
      "_ - 69\n",
      "_ - 70\n",
      "_ - 71\n",
      "_ - 72\n",
      "_ - 73\n",
      "_ - 74\n",
      "_ - 75\n",
      "_ - 76\n",
      "_ - 77\n",
      "_ - 78\n",
      "_ - 79\n",
      "_ - 80\n",
      "_ - 81\n",
      "_ - 82\n",
      "_ - 83\n",
      "_ - 84\n",
      "_ - 85\n",
      "_ - 86\n",
      "_ - 87\n",
      "_ - 88\n",
      "_ - 89\n",
      "_ - 90\n",
      "_ - 91\n",
      "_ - 92\n",
      "_ - 93\n",
      "_ - 94\n",
      "_ - 95\n",
      "_ - 96\n",
      "_ - 97\n",
      "_ - 98\n",
      "_ - 99\n",
      "_ - 100\n",
      "_ - 101\n",
      "_ - 102\n",
      "_ - 103\n",
      "_ - 104\n",
      "_ - 105\n",
      "_ - 106\n",
      "_ - 107\n",
      "_ - 108\n",
      "_ - 109\n",
      "_ - 110\n",
      "_ - 111\n",
      "_ - 112\n",
      "_ - 113\n",
      "_ - 114\n",
      "_ - 115\n",
      "_ - 116\n",
      "_ - 117\n",
      "_ - 118\n",
      "_ - 119\n",
      "_ - 120\n",
      "_ - 121\n",
      "_ - 122\n",
      "_ - 123\n",
      "_ - 124\n",
      "_ - 125\n",
      "_ - 126\n",
      "_ - 127\n",
      "_ - 128\n",
      "_ - 129\n",
      "_ - 130\n",
      "_ - 131\n",
      "_ - 132\n",
      "_ - 133\n",
      "_ - 134\n",
      "_ - 135\n",
      "_ - 136\n",
      "_ - 137\n",
      "_ - 138\n",
      "_ - 139\n",
      "_ - 140\n",
      "_ - 141\n",
      "_ - 142\n",
      "_ - 143\n",
      "_ - 144\n",
      "_ - 145\n",
      "_ - 146\n",
      "_ - 147\n",
      "_ - 148\n",
      "_ - 149\n",
      "_ - 150\n",
      "_ - 151\n",
      "_ - 152\n",
      "_ - 153\n",
      "_ - 154\n",
      "_ - 155\n",
      "_ - 156\n",
      "_ - 157\n",
      "_ - 158\n",
      "_ - 159\n",
      "_ - 160\n",
      "_ - 161\n",
      "_ - 162\n",
      "_ - 163\n",
      "_ - 164\n",
      "_ - 165\n",
      "_ - 166\n",
      "_ - 167\n",
      "_ - 168\n",
      "_ - 169\n",
      "_ - 170\n",
      "_ - 171\n",
      "_ - 172\n",
      "_ - 173\n",
      "_ - 174\n",
      "_ - 175\n",
      "_ - 176\n",
      "_ - 177\n",
      "_ - 178\n",
      "_ - 179\n",
      "_ - 180\n",
      "_ - 181\n",
      "_ - 182\n",
      "_ - 183\n",
      "_ - 184\n",
      "_ - 185\n",
      "_ - 186\n",
      "_ - 187\n",
      "_ - 188\n",
      "_ - 189\n",
      "_ - 190\n",
      "_ - 191\n",
      "_ - 192\n",
      "_ - 193\n",
      "_ - 194\n",
      "_ - 195\n",
      "_ - 196\n",
      "_ - 197\n",
      "_ - 198\n",
      "_ - 199\n",
      "_ - 200\n",
      "_ - 201\n",
      "_ - 202\n",
      "_ - 203\n",
      "_ - 204\n",
      "_ - 205\n",
      "_ - 206\n",
      "_ - 207\n",
      "_ - 208\n",
      "_ - 209\n",
      "_ - 210\n",
      "_ - 211\n",
      "_ - 212\n",
      "_ - 213\n",
      "_ - 214\n",
      "_ - 215\n",
      "_ - 216\n",
      "_ - 217\n",
      "_ - 218\n",
      "_ - 219\n",
      "_ - 220\n",
      "_ - 221\n",
      "_ - 222\n",
      "_ - 223\n",
      "_ - 224\n",
      "_ - 225\n",
      "_ - 226\n",
      "_ - 227\n",
      "_ - 228\n",
      "_ - 229\n",
      "_ - 230\n",
      "_ - 231\n",
      "_ - 232\n",
      "_ - 233\n",
      "_ - 234\n",
      "_ - 235\n",
      "_ - 236\n",
      "_ - 237\n",
      "_ - 238\n",
      "_ - 239\n",
      "hello - 0\n",
      "hello - 1\n",
      "hello - 2\n",
      "hello - 3\n",
      "hello - 4\n",
      "hello - 5\n",
      "hello - 6\n",
      "hello - 7\n",
      "hello - 8\n",
      "hello - 9\n",
      "hello - 10\n",
      "hello - 11\n",
      "hello - 12\n",
      "hello - 13\n",
      "hello - 14\n",
      "hello - 15\n",
      "hello - 16\n",
      "hello - 17\n",
      "hello - 18\n",
      "hello - 19\n",
      "hello - 20\n",
      "hello - 21\n",
      "hello - 22\n",
      "hello - 23\n",
      "hello - 24\n",
      "hello - 25\n",
      "hello - 26\n",
      "hello - 27\n",
      "hello - 28\n",
      "hello - 29\n",
      "hello - 30\n",
      "hello - 31\n",
      "hello - 32\n",
      "hello - 33\n",
      "hello - 34\n",
      "hello - 35\n",
      "hello - 36\n",
      "hello - 37\n",
      "hello - 38\n",
      "hello - 39\n",
      "hello - 40\n",
      "hello - 41\n",
      "hello - 42\n",
      "hello - 43\n",
      "hello - 44\n",
      "hello - 45\n",
      "hello - 46\n",
      "hello - 47\n",
      "hello - 48\n",
      "hello - 49\n",
      "hello - 50\n",
      "hello - 51\n",
      "hello - 52\n",
      "hello - 53\n",
      "hello - 54\n",
      "hello - 55\n",
      "hello - 56\n",
      "hello - 57\n",
      "hello - 58\n",
      "hello - 59\n",
      "hello - 60\n",
      "hello - 61\n",
      "hello - 62\n",
      "hello - 63\n",
      "hello - 64\n",
      "hello - 65\n",
      "hello - 66\n",
      "hello - 67\n",
      "hello - 68\n",
      "hello - 69\n",
      "hello - 70\n",
      "hello - 71\n",
      "hello - 72\n",
      "hello - 73\n",
      "hello - 74\n",
      "hello - 75\n",
      "hello - 76\n",
      "hello - 77\n",
      "hello - 78\n",
      "hello - 79\n",
      "hello - 80\n",
      "hello - 81\n",
      "hello - 82\n",
      "hello - 83\n",
      "hello - 84\n",
      "hello - 85\n",
      "hello - 86\n",
      "hello - 87\n",
      "hello - 88\n",
      "hello - 89\n",
      "hello - 90\n",
      "hello - 91\n",
      "hello - 92\n",
      "hello - 93\n",
      "hello - 94\n",
      "hello - 95\n",
      "hello - 96\n",
      "hello - 97\n",
      "hello - 98\n",
      "hello - 99\n",
      "hello - 100\n",
      "hello - 101\n",
      "hello - 102\n",
      "hello - 103\n",
      "hello - 104\n",
      "hello - 105\n",
      "hello - 106\n",
      "hello - 107\n",
      "hello - 108\n",
      "hello - 109\n",
      "hello - 110\n",
      "hello - 111\n",
      "hello - 112\n",
      "hello - 113\n",
      "hello - 114\n",
      "hello - 115\n",
      "hello - 116\n",
      "hello - 117\n",
      "hello - 118\n",
      "hello - 119\n",
      "hello - 120\n",
      "hello - 121\n",
      "hello - 122\n",
      "hello - 123\n",
      "hello - 124\n",
      "hello - 125\n",
      "hello - 126\n",
      "hello - 127\n",
      "hello - 128\n",
      "hello - 129\n",
      "hello - 130\n",
      "hello - 131\n",
      "hello - 132\n",
      "hello - 133\n",
      "hello - 134\n",
      "hello - 135\n",
      "hello - 136\n",
      "hello - 137\n",
      "hello - 138\n",
      "hello - 139\n",
      "hello - 140\n",
      "hello - 141\n",
      "hello - 142\n",
      "hello - 143\n",
      "hello - 144\n",
      "hello - 145\n",
      "hello - 146\n",
      "hello - 147\n",
      "hello - 148\n",
      "hello - 149\n",
      "hello - 150\n",
      "hello - 151\n",
      "hello - 152\n",
      "hello - 153\n",
      "hello - 154\n",
      "hello - 155\n",
      "hello - 156\n",
      "hello - 157\n",
      "hello - 158\n",
      "hello - 159\n",
      "hello - 160\n",
      "hello - 161\n",
      "hello - 162\n",
      "hello - 163\n",
      "hello - 164\n",
      "hello - 165\n",
      "hello - 166\n",
      "hello - 167\n",
      "hello - 168\n",
      "hello - 169\n",
      "hello - 170\n",
      "hello - 171\n",
      "hello - 172\n",
      "hello - 173\n",
      "hello - 174\n",
      "hello - 175\n",
      "hello - 176\n",
      "hello - 177\n",
      "hello - 178\n",
      "hello - 179\n",
      "hello - 180\n",
      "hello - 181\n",
      "hello - 182\n",
      "hello - 183\n",
      "hello - 184\n",
      "hello - 185\n",
      "hello - 186\n",
      "hello - 187\n",
      "hello - 188\n",
      "hello - 189\n",
      "hello - 190\n",
      "hello - 191\n",
      "hello - 192\n",
      "hello - 193\n",
      "hello - 194\n",
      "hello - 195\n",
      "hello - 196\n",
      "hello - 197\n",
      "hello - 198\n",
      "hello - 199\n",
      "hello - 200\n",
      "hello - 201\n",
      "hello - 202\n",
      "hello - 203\n",
      "hello - 204\n",
      "hello - 205\n",
      "hello - 206\n",
      "hello - 207\n",
      "hello - 208\n",
      "hello - 209\n",
      "hello - 210\n",
      "hello - 211\n",
      "hello - 212\n",
      "hello - 213\n",
      "hello - 214\n",
      "hello - 215\n",
      "hello - 216\n",
      "hello - 217\n",
      "hello - 218\n",
      "hello - 219\n",
      "hello - 220\n",
      "hello - 221\n",
      "hello - 222\n",
      "hello - 223\n",
      "hello - 224\n",
      "hello - 225\n",
      "hello - 226\n",
      "hello - 227\n",
      "hello - 228\n",
      "hello - 229\n",
      "hello - 230\n",
      "hello - 231\n",
      "hello - 232\n",
      "hello - 233\n",
      "hello - 234\n",
      "hello - 235\n",
      "hello - 236\n",
      "hello - 237\n",
      "hello - 238\n",
      "hello - 239\n",
      "thanks - 0\n",
      "thanks - 1\n",
      "thanks - 2\n",
      "thanks - 3\n",
      "thanks - 4\n",
      "thanks - 5\n",
      "thanks - 6\n",
      "thanks - 7\n",
      "thanks - 8\n",
      "thanks - 9\n",
      "thanks - 10\n",
      "thanks - 11\n",
      "thanks - 12\n",
      "thanks - 13\n",
      "thanks - 14\n",
      "thanks - 15\n",
      "thanks - 16\n",
      "thanks - 17\n",
      "thanks - 18\n",
      "thanks - 19\n",
      "thanks - 20\n",
      "thanks - 21\n",
      "thanks - 22\n",
      "thanks - 23\n",
      "thanks - 24\n",
      "thanks - 25\n",
      "thanks - 26\n",
      "thanks - 27\n",
      "thanks - 28\n",
      "thanks - 29\n",
      "thanks - 30\n",
      "thanks - 31\n",
      "thanks - 32\n",
      "thanks - 33\n",
      "thanks - 34\n",
      "thanks - 35\n",
      "thanks - 36\n",
      "thanks - 37\n",
      "thanks - 38\n",
      "thanks - 39\n",
      "thanks - 40\n",
      "thanks - 41\n",
      "thanks - 42\n",
      "thanks - 43\n",
      "thanks - 44\n",
      "thanks - 45\n",
      "thanks - 46\n",
      "thanks - 47\n",
      "thanks - 48\n",
      "thanks - 49\n",
      "thanks - 50\n",
      "thanks - 51\n",
      "thanks - 52\n",
      "thanks - 53\n",
      "thanks - 54\n",
      "thanks - 55\n",
      "thanks - 56\n",
      "thanks - 57\n",
      "thanks - 58\n",
      "thanks - 59\n",
      "thanks - 60\n",
      "thanks - 61\n",
      "thanks - 62\n",
      "thanks - 63\n",
      "thanks - 64\n",
      "thanks - 65\n",
      "thanks - 66\n",
      "thanks - 67\n",
      "thanks - 68\n",
      "thanks - 69\n",
      "thanks - 70\n",
      "thanks - 71\n",
      "thanks - 72\n",
      "thanks - 73\n",
      "thanks - 74\n",
      "thanks - 75\n",
      "thanks - 76\n",
      "thanks - 77\n",
      "thanks - 78\n",
      "thanks - 79\n",
      "thanks - 80\n",
      "thanks - 81\n",
      "thanks - 82\n",
      "thanks - 83\n",
      "thanks - 84\n",
      "thanks - 85\n",
      "thanks - 86\n",
      "thanks - 87\n",
      "thanks - 88\n",
      "thanks - 89\n",
      "thanks - 90\n",
      "thanks - 91\n",
      "thanks - 92\n",
      "thanks - 93\n",
      "thanks - 94\n",
      "thanks - 95\n",
      "thanks - 96\n",
      "thanks - 97\n",
      "thanks - 98\n",
      "thanks - 99\n",
      "thanks - 100\n",
      "thanks - 101\n",
      "thanks - 102\n",
      "thanks - 103\n",
      "thanks - 104\n",
      "thanks - 105\n",
      "thanks - 106\n",
      "thanks - 107\n",
      "thanks - 108\n",
      "thanks - 109\n",
      "thanks - 110\n",
      "thanks - 111\n",
      "thanks - 112\n",
      "thanks - 113\n",
      "thanks - 114\n",
      "thanks - 115\n",
      "thanks - 116\n",
      "thanks - 117\n",
      "thanks - 118\n",
      "thanks - 119\n",
      "thanks - 120\n",
      "thanks - 121\n",
      "thanks - 122\n",
      "thanks - 123\n",
      "thanks - 124\n",
      "thanks - 125\n",
      "thanks - 126\n",
      "thanks - 127\n",
      "thanks - 128\n",
      "thanks - 129\n",
      "thanks - 130\n",
      "thanks - 131\n",
      "thanks - 132\n",
      "thanks - 133\n",
      "thanks - 134\n",
      "thanks - 135\n",
      "thanks - 136\n",
      "thanks - 137\n",
      "thanks - 138\n",
      "thanks - 139\n",
      "thanks - 140\n",
      "thanks - 141\n",
      "thanks - 142\n",
      "thanks - 143\n",
      "thanks - 144\n",
      "thanks - 145\n",
      "thanks - 146\n",
      "thanks - 147\n",
      "thanks - 148\n",
      "thanks - 149\n",
      "thanks - 150\n",
      "thanks - 151\n",
      "thanks - 152\n",
      "thanks - 153\n",
      "thanks - 154\n",
      "thanks - 155\n",
      "thanks - 156\n",
      "thanks - 157\n",
      "thanks - 158\n",
      "thanks - 159\n",
      "thanks - 160\n",
      "thanks - 161\n",
      "thanks - 162\n",
      "thanks - 163\n",
      "thanks - 164\n",
      "thanks - 165\n",
      "thanks - 166\n",
      "thanks - 167\n",
      "thanks - 168\n",
      "thanks - 169\n",
      "thanks - 170\n",
      "thanks - 171\n",
      "thanks - 172\n",
      "thanks - 173\n",
      "thanks - 174\n",
      "thanks - 175\n",
      "thanks - 176\n",
      "thanks - 177\n",
      "thanks - 178\n",
      "thanks - 179\n",
      "thanks - 180\n",
      "thanks - 181\n",
      "thanks - 182\n",
      "thanks - 183\n",
      "thanks - 184\n",
      "thanks - 185\n",
      "thanks - 186\n",
      "thanks - 187\n",
      "thanks - 188\n",
      "thanks - 189\n",
      "thanks - 190\n",
      "thanks - 191\n",
      "thanks - 192\n",
      "thanks - 193\n",
      "thanks - 194\n",
      "thanks - 195\n",
      "thanks - 196\n",
      "thanks - 197\n",
      "thanks - 198\n",
      "thanks - 199\n",
      "thanks - 200\n",
      "thanks - 201\n",
      "thanks - 202\n",
      "thanks - 203\n",
      "thanks - 204\n",
      "thanks - 205\n",
      "thanks - 206\n",
      "thanks - 207\n",
      "thanks - 208\n",
      "thanks - 209\n",
      "thanks - 210\n",
      "thanks - 211\n",
      "thanks - 212\n",
      "thanks - 213\n",
      "thanks - 214\n",
      "thanks - 215\n",
      "thanks - 216\n",
      "thanks - 217\n",
      "thanks - 218\n",
      "thanks - 219\n",
      "thanks - 220\n",
      "thanks - 221\n",
      "thanks - 222\n",
      "thanks - 223\n",
      "thanks - 224\n",
      "thanks - 225\n",
      "thanks - 226\n",
      "thanks - 227\n",
      "thanks - 228\n",
      "thanks - 229\n",
      "thanks - 230\n",
      "thanks - 231\n",
      "thanks - 232\n",
      "thanks - 233\n",
      "thanks - 234\n",
      "thanks - 235\n",
      "thanks - 236\n",
      "thanks - 237\n",
      "thanks - 238\n",
      "thanks - 239\n",
      "i-love-you - 0\n",
      "i-love-you - 1\n",
      "i-love-you - 2\n",
      "i-love-you - 3\n",
      "i-love-you - 4\n",
      "i-love-you - 5\n",
      "i-love-you - 6\n",
      "i-love-you - 7\n",
      "i-love-you - 8\n",
      "i-love-you - 9\n",
      "i-love-you - 10\n",
      "i-love-you - 11\n",
      "i-love-you - 12\n",
      "i-love-you - 13\n",
      "i-love-you - 14\n",
      "i-love-you - 15\n",
      "i-love-you - 16\n",
      "i-love-you - 17\n",
      "i-love-you - 18\n",
      "i-love-you - 19\n",
      "i-love-you - 20\n",
      "i-love-you - 21\n",
      "i-love-you - 22\n",
      "i-love-you - 23\n",
      "i-love-you - 24\n",
      "i-love-you - 25\n",
      "i-love-you - 26\n",
      "i-love-you - 27\n",
      "i-love-you - 28\n",
      "i-love-you - 29\n",
      "i-love-you - 30\n",
      "i-love-you - 31\n",
      "i-love-you - 32\n",
      "i-love-you - 33\n",
      "i-love-you - 34\n",
      "i-love-you - 35\n",
      "i-love-you - 36\n",
      "i-love-you - 37\n",
      "i-love-you - 38\n",
      "i-love-you - 39\n",
      "i-love-you - 40\n",
      "i-love-you - 41\n",
      "i-love-you - 42\n",
      "i-love-you - 43\n",
      "i-love-you - 44\n",
      "i-love-you - 45\n",
      "i-love-you - 46\n",
      "i-love-you - 47\n",
      "i-love-you - 48\n",
      "i-love-you - 49\n",
      "i-love-you - 50\n",
      "i-love-you - 51\n",
      "i-love-you - 52\n",
      "i-love-you - 53\n",
      "i-love-you - 54\n",
      "i-love-you - 55\n",
      "i-love-you - 56\n",
      "i-love-you - 57\n",
      "i-love-you - 58\n",
      "i-love-you - 59\n",
      "i-love-you - 60\n",
      "i-love-you - 61\n",
      "i-love-you - 62\n",
      "i-love-you - 63\n",
      "i-love-you - 64\n",
      "i-love-you - 65\n",
      "i-love-you - 66\n",
      "i-love-you - 67\n",
      "i-love-you - 68\n",
      "i-love-you - 69\n",
      "i-love-you - 70\n",
      "i-love-you - 71\n",
      "i-love-you - 72\n",
      "i-love-you - 73\n",
      "i-love-you - 74\n",
      "i-love-you - 75\n",
      "i-love-you - 76\n",
      "i-love-you - 77\n",
      "i-love-you - 78\n",
      "i-love-you - 79\n",
      "i-love-you - 80\n",
      "i-love-you - 81\n",
      "i-love-you - 82\n",
      "i-love-you - 83\n",
      "i-love-you - 84\n",
      "i-love-you - 85\n",
      "i-love-you - 86\n",
      "i-love-you - 87\n",
      "i-love-you - 88\n",
      "i-love-you - 89\n",
      "i-love-you - 90\n",
      "i-love-you - 91\n",
      "i-love-you - 92\n",
      "i-love-you - 93\n",
      "i-love-you - 94\n",
      "i-love-you - 95\n",
      "i-love-you - 96\n",
      "i-love-you - 97\n",
      "i-love-you - 98\n",
      "i-love-you - 99\n",
      "i-love-you - 100\n",
      "i-love-you - 101\n",
      "i-love-you - 102\n",
      "i-love-you - 103\n",
      "i-love-you - 104\n",
      "i-love-you - 105\n",
      "i-love-you - 106\n",
      "i-love-you - 107\n",
      "i-love-you - 108\n",
      "i-love-you - 109\n",
      "i-love-you - 110\n",
      "i-love-you - 111\n",
      "i-love-you - 112\n",
      "i-love-you - 113\n",
      "i-love-you - 114\n",
      "i-love-you - 115\n",
      "i-love-you - 116\n",
      "i-love-you - 117\n",
      "i-love-you - 118\n",
      "i-love-you - 119\n",
      "i-love-you - 120\n",
      "i-love-you - 121\n",
      "i-love-you - 122\n",
      "i-love-you - 123\n",
      "i-love-you - 124\n",
      "i-love-you - 125\n",
      "i-love-you - 126\n",
      "i-love-you - 127\n",
      "i-love-you - 128\n",
      "i-love-you - 129\n",
      "i-love-you - 130\n",
      "i-love-you - 131\n",
      "i-love-you - 132\n",
      "i-love-you - 133\n",
      "i-love-you - 134\n",
      "i-love-you - 135\n",
      "i-love-you - 136\n",
      "i-love-you - 137\n",
      "i-love-you - 138\n",
      "i-love-you - 139\n",
      "i-love-you - 140\n",
      "i-love-you - 141\n",
      "i-love-you - 142\n",
      "i-love-you - 143\n",
      "i-love-you - 144\n",
      "i-love-you - 145\n",
      "i-love-you - 146\n",
      "i-love-you - 147\n",
      "i-love-you - 148\n",
      "i-love-you - 149\n",
      "i-love-you - 150\n",
      "i-love-you - 151\n",
      "i-love-you - 152\n",
      "i-love-you - 153\n",
      "i-love-you - 154\n",
      "i-love-you - 155\n",
      "i-love-you - 156\n",
      "i-love-you - 157\n",
      "i-love-you - 158\n",
      "i-love-you - 159\n",
      "i-love-you - 160\n",
      "i-love-you - 161\n",
      "i-love-you - 162\n",
      "i-love-you - 163\n",
      "i-love-you - 164\n",
      "i-love-you - 165\n",
      "i-love-you - 166\n",
      "i-love-you - 167\n",
      "i-love-you - 168\n",
      "i-love-you - 169\n",
      "i-love-you - 170\n",
      "i-love-you - 171\n",
      "i-love-you - 172\n",
      "i-love-you - 173\n",
      "i-love-you - 174\n",
      "i-love-you - 175\n",
      "i-love-you - 176\n",
      "i-love-you - 177\n",
      "i-love-you - 178\n",
      "i-love-you - 179\n",
      "i-love-you - 180\n",
      "i-love-you - 181\n",
      "i-love-you - 182\n",
      "i-love-you - 183\n",
      "i-love-you - 184\n",
      "i-love-you - 185\n",
      "i-love-you - 186\n",
      "i-love-you - 187\n",
      "i-love-you - 188\n",
      "i-love-you - 189\n",
      "i-love-you - 190\n",
      "i-love-you - 191\n",
      "i-love-you - 192\n",
      "i-love-you - 193\n",
      "i-love-you - 194\n",
      "i-love-you - 195\n",
      "i-love-you - 196\n",
      "i-love-you - 197\n",
      "i-love-you - 198\n",
      "i-love-you - 199\n",
      "i-love-you - 200\n",
      "i-love-you - 201\n",
      "i-love-you - 202\n",
      "i-love-you - 203\n",
      "i-love-you - 204\n",
      "i-love-you - 205\n",
      "i-love-you - 206\n",
      "i-love-you - 207\n",
      "i-love-you - 208\n",
      "i-love-you - 209\n",
      "i-love-you - 210\n",
      "i-love-you - 211\n",
      "i-love-you - 212\n",
      "i-love-you - 213\n",
      "i-love-you - 214\n",
      "i-love-you - 215\n",
      "i-love-you - 216\n",
      "i-love-you - 217\n",
      "i-love-you - 218\n",
      "i-love-you - 219\n",
      "i-love-you - 220\n",
      "i-love-you - 221\n",
      "i-love-you - 222\n",
      "i-love-you - 223\n",
      "i-love-you - 224\n",
      "i-love-you - 225\n",
      "i-love-you - 226\n",
      "i-love-you - 227\n",
      "i-love-you - 228\n",
      "i-love-you - 229\n",
      "i-love-you - 230\n",
      "i-love-you - 231\n",
      "i-love-you - 232\n",
      "i-love-you - 233\n",
      "i-love-you - 234\n",
      "i-love-you - 235\n",
      "i-love-you - 236\n",
      "i-love-you - 237\n",
      "i-love-you - 238\n",
      "i-love-you - 239\n",
      "I - 0\n",
      "I - 1\n",
      "I - 2\n",
      "I - 3\n",
      "I - 4\n",
      "I - 5\n",
      "I - 6\n",
      "I - 7\n",
      "I - 8\n",
      "I - 9\n",
      "I - 10\n",
      "I - 11\n",
      "I - 12\n",
      "I - 13\n",
      "I - 14\n",
      "I - 15\n",
      "I - 16\n",
      "I - 17\n",
      "I - 18\n",
      "I - 19\n",
      "I - 20\n",
      "I - 21\n",
      "I - 22\n",
      "I - 23\n",
      "I - 24\n",
      "I - 25\n",
      "I - 26\n",
      "I - 27\n",
      "I - 28\n",
      "I - 29\n",
      "I - 30\n",
      "I - 31\n",
      "I - 32\n",
      "I - 33\n",
      "I - 34\n",
      "I - 35\n",
      "I - 36\n",
      "I - 37\n",
      "I - 38\n",
      "I - 39\n",
      "I - 40\n",
      "I - 41\n",
      "I - 42\n",
      "I - 43\n",
      "I - 44\n",
      "I - 45\n",
      "I - 46\n",
      "I - 47\n",
      "I - 48\n",
      "I - 49\n",
      "I - 50\n",
      "I - 51\n",
      "I - 52\n",
      "I - 53\n",
      "I - 54\n",
      "I - 55\n",
      "I - 56\n",
      "I - 57\n",
      "I - 58\n",
      "I - 59\n",
      "I - 60\n",
      "I - 61\n",
      "I - 62\n",
      "I - 63\n",
      "I - 64\n",
      "I - 65\n",
      "I - 66\n",
      "I - 67\n",
      "I - 68\n",
      "I - 69\n",
      "I - 70\n",
      "I - 71\n",
      "I - 72\n",
      "I - 73\n",
      "I - 74\n",
      "I - 75\n",
      "I - 76\n",
      "I - 77\n",
      "I - 78\n",
      "I - 79\n",
      "I - 80\n",
      "I - 81\n",
      "I - 82\n",
      "I - 83\n",
      "I - 84\n",
      "I - 85\n",
      "I - 86\n",
      "I - 87\n",
      "I - 88\n",
      "I - 89\n",
      "I - 90\n",
      "I - 91\n",
      "I - 92\n",
      "I - 93\n",
      "I - 94\n",
      "I - 95\n",
      "I - 96\n",
      "I - 97\n",
      "I - 98\n",
      "I - 99\n",
      "I - 100\n",
      "I - 101\n",
      "I - 102\n",
      "I - 103\n",
      "I - 104\n",
      "I - 105\n",
      "I - 106\n",
      "I - 107\n",
      "I - 108\n",
      "I - 109\n",
      "I - 110\n",
      "I - 111\n",
      "I - 112\n",
      "I - 113\n",
      "I - 114\n",
      "I - 115\n",
      "I - 116\n",
      "I - 117\n",
      "I - 118\n",
      "I - 119\n",
      "I - 120\n",
      "I - 121\n",
      "I - 122\n",
      "I - 123\n",
      "I - 124\n",
      "I - 125\n",
      "I - 126\n",
      "I - 127\n",
      "I - 128\n",
      "I - 129\n",
      "I - 130\n",
      "I - 131\n",
      "I - 132\n",
      "I - 133\n",
      "I - 134\n",
      "I - 135\n",
      "I - 136\n",
      "I - 137\n",
      "I - 138\n",
      "I - 139\n",
      "I - 140\n",
      "I - 141\n",
      "I - 142\n",
      "I - 143\n",
      "I - 144\n",
      "I - 145\n",
      "I - 146\n",
      "I - 147\n",
      "I - 148\n",
      "I - 149\n",
      "I - 150\n",
      "I - 151\n",
      "I - 152\n",
      "I - 153\n",
      "I - 154\n",
      "I - 155\n",
      "I - 156\n",
      "I - 157\n",
      "I - 158\n",
      "I - 159\n",
      "I - 160\n",
      "I - 161\n",
      "I - 162\n",
      "I - 163\n",
      "I - 164\n",
      "I - 165\n",
      "I - 166\n",
      "I - 167\n",
      "I - 168\n",
      "I - 169\n",
      "I - 170\n",
      "I - 171\n",
      "I - 172\n",
      "I - 173\n",
      "I - 174\n",
      "I - 175\n",
      "I - 176\n",
      "I - 177\n",
      "I - 178\n",
      "I - 179\n",
      "I - 180\n",
      "I - 181\n",
      "I - 182\n",
      "I - 183\n",
      "I - 184\n",
      "I - 185\n",
      "I - 186\n",
      "I - 187\n",
      "I - 188\n",
      "I - 189\n",
      "I - 190\n",
      "I - 191\n",
      "I - 192\n",
      "I - 193\n",
      "I - 194\n",
      "I - 195\n",
      "I - 196\n",
      "I - 197\n",
      "I - 198\n",
      "I - 199\n",
      "I - 200\n",
      "I - 201\n",
      "I - 202\n",
      "I - 203\n",
      "I - 204\n",
      "I - 205\n",
      "I - 206\n",
      "I - 207\n",
      "I - 208\n",
      "I - 209\n",
      "I - 210\n",
      "I - 211\n",
      "I - 212\n",
      "I - 213\n",
      "I - 214\n",
      "I - 215\n",
      "I - 216\n",
      "I - 217\n",
      "I - 218\n",
      "I - 219\n",
      "I - 220\n",
      "I - 221\n",
      "I - 222\n",
      "I - 223\n",
      "I - 224\n",
      "I - 225\n",
      "I - 226\n",
      "I - 227\n",
      "I - 228\n",
      "I - 229\n",
      "I - 230\n",
      "I - 231\n",
      "I - 232\n",
      "I - 233\n",
      "I - 234\n",
      "I - 235\n",
      "I - 236\n",
      "I - 237\n",
      "I - 238\n",
      "I - 239\n",
      "Yes - 0\n",
      "Yes - 1\n",
      "Yes - 2\n",
      "Yes - 3\n",
      "Yes - 4\n",
      "Yes - 5\n",
      "Yes - 6\n",
      "Yes - 7\n",
      "Yes - 8\n",
      "Yes - 9\n",
      "Yes - 10\n",
      "Yes - 11\n",
      "Yes - 12\n",
      "Yes - 13\n",
      "Yes - 14\n",
      "Yes - 15\n",
      "Yes - 16\n",
      "Yes - 17\n",
      "Yes - 18\n",
      "Yes - 19\n",
      "Yes - 20\n",
      "Yes - 21\n",
      "Yes - 22\n",
      "Yes - 23\n",
      "Yes - 24\n",
      "Yes - 25\n",
      "Yes - 26\n",
      "Yes - 27\n",
      "Yes - 28\n",
      "Yes - 29\n",
      "Yes - 30\n",
      "Yes - 31\n",
      "Yes - 32\n",
      "Yes - 33\n",
      "Yes - 34\n",
      "Yes - 35\n",
      "Yes - 36\n",
      "Yes - 37\n",
      "Yes - 38\n",
      "Yes - 39\n",
      "Yes - 40\n",
      "Yes - 41\n",
      "Yes - 42\n",
      "Yes - 43\n",
      "Yes - 44\n",
      "Yes - 45\n",
      "Yes - 46\n",
      "Yes - 47\n",
      "Yes - 48\n",
      "Yes - 49\n",
      "Yes - 50\n",
      "Yes - 51\n",
      "Yes - 52\n",
      "Yes - 53\n",
      "Yes - 54\n",
      "Yes - 55\n",
      "Yes - 56\n",
      "Yes - 57\n",
      "Yes - 58\n",
      "Yes - 59\n",
      "Yes - 60\n",
      "Yes - 61\n",
      "Yes - 62\n",
      "Yes - 63\n",
      "Yes - 64\n",
      "Yes - 65\n",
      "Yes - 66\n",
      "Yes - 67\n",
      "Yes - 68\n",
      "Yes - 69\n",
      "Yes - 70\n",
      "Yes - 71\n",
      "Yes - 72\n",
      "Yes - 73\n",
      "Yes - 74\n",
      "Yes - 75\n",
      "Yes - 76\n",
      "Yes - 77\n",
      "Yes - 78\n",
      "Yes - 79\n",
      "Yes - 80\n",
      "Yes - 81\n",
      "Yes - 82\n",
      "Yes - 83\n",
      "Yes - 84\n",
      "Yes - 85\n",
      "Yes - 86\n",
      "Yes - 87\n",
      "Yes - 88\n",
      "Yes - 89\n",
      "Yes - 90\n",
      "Yes - 91\n",
      "Yes - 92\n",
      "Yes - 93\n",
      "Yes - 94\n",
      "Yes - 95\n",
      "Yes - 96\n",
      "Yes - 97\n",
      "Yes - 98\n",
      "Yes - 99\n",
      "Yes - 100\n",
      "Yes - 101\n",
      "Yes - 102\n",
      "Yes - 103\n",
      "Yes - 104\n",
      "Yes - 105\n",
      "Yes - 106\n",
      "Yes - 107\n",
      "Yes - 108\n",
      "Yes - 109\n",
      "Yes - 110\n",
      "Yes - 111\n",
      "Yes - 112\n",
      "Yes - 113\n",
      "Yes - 114\n",
      "Yes - 115\n",
      "Yes - 116\n",
      "Yes - 117\n",
      "Yes - 118\n",
      "Yes - 119\n",
      "Yes - 120\n",
      "Yes - 121\n",
      "Yes - 122\n",
      "Yes - 123\n",
      "Yes - 124\n",
      "Yes - 125\n",
      "Yes - 126\n",
      "Yes - 127\n",
      "Yes - 128\n",
      "Yes - 129\n",
      "Yes - 130\n",
      "Yes - 131\n",
      "Yes - 132\n",
      "Yes - 133\n",
      "Yes - 134\n",
      "Yes - 135\n",
      "Yes - 136\n",
      "Yes - 137\n",
      "Yes - 138\n",
      "Yes - 139\n",
      "Yes - 140\n",
      "Yes - 141\n",
      "Yes - 142\n",
      "Yes - 143\n",
      "Yes - 144\n",
      "Yes - 145\n",
      "Yes - 146\n",
      "Yes - 147\n",
      "Yes - 148\n",
      "Yes - 149\n",
      "Yes - 150\n",
      "Yes - 151\n",
      "Yes - 152\n",
      "Yes - 153\n",
      "Yes - 154\n",
      "Yes - 155\n",
      "Yes - 156\n",
      "Yes - 157\n",
      "Yes - 158\n",
      "Yes - 159\n",
      "Yes - 160\n",
      "Yes - 161\n",
      "Yes - 162\n",
      "Yes - 163\n",
      "Yes - 164\n",
      "Yes - 165\n",
      "Yes - 166\n",
      "Yes - 167\n",
      "Yes - 168\n",
      "Yes - 169\n",
      "Yes - 170\n",
      "Yes - 171\n",
      "Yes - 172\n",
      "Yes - 173\n",
      "Yes - 174\n",
      "Yes - 175\n",
      "Yes - 176\n",
      "Yes - 177\n",
      "Yes - 178\n",
      "Yes - 179\n",
      "Yes - 180\n",
      "Yes - 181\n",
      "Yes - 182\n",
      "Yes - 183\n",
      "Yes - 184\n",
      "Yes - 185\n",
      "Yes - 186\n",
      "Yes - 187\n",
      "Yes - 188\n",
      "Yes - 189\n",
      "Yes - 190\n",
      "Yes - 191\n",
      "Yes - 192\n",
      "Yes - 193\n",
      "Yes - 194\n",
      "Yes - 195\n",
      "Yes - 196\n",
      "Yes - 197\n",
      "Yes - 198\n",
      "Yes - 199\n",
      "Yes - 200\n",
      "Yes - 201\n",
      "Yes - 202\n",
      "Yes - 203\n",
      "Yes - 204\n",
      "Yes - 205\n",
      "Yes - 206\n",
      "Yes - 207\n",
      "Yes - 208\n",
      "Yes - 209\n",
      "Yes - 210\n",
      "Yes - 211\n",
      "Yes - 212\n",
      "Yes - 213\n",
      "Yes - 214\n",
      "Yes - 215\n",
      "Yes - 216\n",
      "Yes - 217\n",
      "Yes - 218\n",
      "Yes - 219\n",
      "Yes - 220\n",
      "Yes - 221\n",
      "Yes - 222\n",
      "Yes - 223\n",
      "Yes - 224\n",
      "Yes - 225\n",
      "Yes - 226\n",
      "Yes - 227\n",
      "Yes - 228\n",
      "Yes - 229\n",
      "Yes - 230\n",
      "Yes - 231\n",
      "Yes - 232\n",
      "Yes - 233\n",
      "Yes - 234\n",
      "Yes - 235\n",
      "Yes - 236\n",
      "Yes - 237\n",
      "Yes - 238\n",
      "Yes - 239\n",
      "No - 0\n",
      "No - 1\n",
      "No - 2\n",
      "No - 3\n",
      "No - 4\n",
      "No - 5\n",
      "No - 6\n",
      "No - 7\n",
      "No - 8\n",
      "No - 9\n",
      "No - 10\n",
      "No - 11\n",
      "No - 12\n",
      "No - 13\n",
      "No - 14\n",
      "No - 15\n",
      "No - 16\n",
      "No - 17\n",
      "No - 18\n",
      "No - 19\n",
      "No - 20\n",
      "No - 21\n",
      "No - 22\n",
      "No - 23\n",
      "No - 24\n",
      "No - 25\n",
      "No - 26\n",
      "No - 27\n",
      "No - 28\n",
      "No - 29\n",
      "No - 30\n",
      "No - 31\n",
      "No - 32\n",
      "No - 33\n",
      "No - 34\n",
      "No - 35\n",
      "No - 36\n",
      "No - 37\n",
      "No - 38\n",
      "No - 39\n",
      "No - 40\n",
      "No - 41\n",
      "No - 42\n",
      "No - 43\n",
      "No - 44\n",
      "No - 45\n",
      "No - 46\n",
      "No - 47\n",
      "No - 48\n",
      "No - 49\n",
      "No - 50\n",
      "No - 51\n",
      "No - 52\n",
      "No - 53\n",
      "No - 54\n",
      "No - 55\n",
      "No - 56\n",
      "No - 57\n",
      "No - 58\n",
      "No - 59\n",
      "No - 60\n",
      "No - 61\n",
      "No - 62\n",
      "No - 63\n",
      "No - 64\n",
      "No - 65\n",
      "No - 66\n",
      "No - 67\n",
      "No - 68\n",
      "No - 69\n",
      "No - 70\n",
      "No - 71\n",
      "No - 72\n",
      "No - 73\n",
      "No - 74\n",
      "No - 75\n",
      "No - 76\n",
      "No - 77\n",
      "No - 78\n",
      "No - 79\n",
      "No - 80\n",
      "No - 81\n",
      "No - 82\n",
      "No - 83\n",
      "No - 84\n",
      "No - 85\n",
      "No - 86\n",
      "No - 87\n",
      "No - 88\n",
      "No - 89\n",
      "No - 90\n",
      "No - 91\n",
      "No - 92\n",
      "No - 93\n",
      "No - 94\n",
      "No - 95\n",
      "No - 96\n",
      "No - 97\n",
      "No - 98\n",
      "No - 99\n",
      "No - 100\n",
      "No - 101\n",
      "No - 102\n",
      "No - 103\n",
      "No - 104\n",
      "No - 105\n",
      "No - 106\n",
      "No - 107\n",
      "No - 108\n",
      "No - 109\n",
      "No - 110\n",
      "No - 111\n",
      "No - 112\n",
      "No - 113\n",
      "No - 114\n",
      "No - 115\n",
      "No - 116\n",
      "No - 117\n",
      "No - 118\n",
      "No - 119\n",
      "No - 120\n",
      "No - 121\n",
      "No - 122\n",
      "No - 123\n",
      "No - 124\n",
      "No - 125\n",
      "No - 126\n",
      "No - 127\n",
      "No - 128\n",
      "No - 129\n",
      "No - 130\n",
      "No - 131\n",
      "No - 132\n",
      "No - 133\n",
      "No - 134\n",
      "No - 135\n",
      "No - 136\n",
      "No - 137\n",
      "No - 138\n",
      "No - 139\n",
      "No - 140\n",
      "No - 141\n",
      "No - 142\n",
      "No - 143\n",
      "No - 144\n",
      "No - 145\n",
      "No - 146\n",
      "No - 147\n",
      "No - 148\n",
      "No - 149\n",
      "No - 150\n",
      "No - 151\n",
      "No - 152\n",
      "No - 153\n",
      "No - 154\n",
      "No - 155\n",
      "No - 156\n",
      "No - 157\n",
      "No - 158\n",
      "No - 159\n",
      "No - 160\n",
      "No - 161\n",
      "No - 162\n",
      "No - 163\n",
      "No - 164\n",
      "No - 165\n",
      "No - 166\n",
      "No - 167\n",
      "No - 168\n",
      "No - 169\n",
      "No - 170\n",
      "No - 171\n",
      "No - 172\n",
      "No - 173\n",
      "No - 174\n",
      "No - 175\n",
      "No - 176\n",
      "No - 177\n",
      "No - 178\n",
      "No - 179\n",
      "No - 180\n",
      "No - 181\n",
      "No - 182\n",
      "No - 183\n",
      "No - 184\n",
      "No - 185\n",
      "No - 186\n",
      "No - 187\n",
      "No - 188\n",
      "No - 189\n",
      "No - 190\n",
      "No - 191\n",
      "No - 192\n",
      "No - 193\n",
      "No - 194\n",
      "No - 195\n",
      "No - 196\n",
      "No - 197\n",
      "No - 198\n",
      "No - 199\n",
      "No - 200\n",
      "No - 201\n",
      "No - 202\n",
      "No - 203\n",
      "No - 204\n",
      "No - 205\n",
      "No - 206\n",
      "No - 207\n",
      "No - 208\n",
      "No - 209\n",
      "No - 210\n",
      "No - 211\n",
      "No - 212\n",
      "No - 213\n",
      "No - 214\n",
      "No - 215\n",
      "No - 216\n",
      "No - 217\n",
      "No - 218\n",
      "No - 219\n",
      "No - 220\n",
      "No - 221\n",
      "No - 222\n",
      "No - 223\n",
      "No - 224\n",
      "No - 225\n",
      "No - 226\n",
      "No - 227\n",
      "No - 228\n",
      "No - 229\n",
      "No - 230\n",
      "No - 231\n",
      "No - 232\n",
      "No - 233\n",
      "No - 234\n",
      "No - 235\n",
      "No - 236\n",
      "No - 237\n",
      "No - 238\n",
      "No - 239\n",
      "Help - 0\n",
      "Help - 1\n",
      "Help - 2\n",
      "Help - 3\n",
      "Help - 4\n",
      "Help - 5\n",
      "Help - 6\n",
      "Help - 7\n",
      "Help - 8\n",
      "Help - 9\n",
      "Help - 10\n",
      "Help - 11\n",
      "Help - 12\n",
      "Help - 13\n",
      "Help - 14\n",
      "Help - 15\n",
      "Help - 16\n",
      "Help - 17\n",
      "Help - 18\n",
      "Help - 19\n",
      "Help - 20\n",
      "Help - 21\n",
      "Help - 22\n",
      "Help - 23\n",
      "Help - 24\n",
      "Help - 25\n",
      "Help - 26\n",
      "Help - 27\n",
      "Help - 28\n",
      "Help - 29\n",
      "Help - 30\n",
      "Help - 31\n",
      "Help - 32\n",
      "Help - 33\n",
      "Help - 34\n",
      "Help - 35\n",
      "Help - 36\n",
      "Help - 37\n",
      "Help - 38\n",
      "Help - 39\n",
      "Help - 40\n",
      "Help - 41\n",
      "Help - 42\n",
      "Help - 43\n",
      "Help - 44\n",
      "Help - 45\n",
      "Help - 46\n",
      "Help - 47\n",
      "Help - 48\n",
      "Help - 49\n",
      "Help - 50\n",
      "Help - 51\n",
      "Help - 52\n",
      "Help - 53\n",
      "Help - 54\n",
      "Help - 55\n",
      "Help - 56\n",
      "Help - 57\n",
      "Help - 58\n",
      "Help - 59\n",
      "Help - 60\n",
      "Help - 61\n",
      "Help - 62\n",
      "Help - 63\n",
      "Help - 64\n",
      "Help - 65\n",
      "Help - 66\n",
      "Help - 67\n",
      "Help - 68\n",
      "Help - 69\n",
      "Help - 70\n",
      "Help - 71\n",
      "Help - 72\n",
      "Help - 73\n",
      "Help - 74\n",
      "Help - 75\n",
      "Help - 76\n",
      "Help - 77\n",
      "Help - 78\n",
      "Help - 79\n",
      "Help - 80\n",
      "Help - 81\n",
      "Help - 82\n",
      "Help - 83\n",
      "Help - 84\n",
      "Help - 85\n",
      "Help - 86\n",
      "Help - 87\n",
      "Help - 88\n",
      "Help - 89\n",
      "Help - 90\n",
      "Help - 91\n",
      "Help - 92\n",
      "Help - 93\n",
      "Help - 94\n",
      "Help - 95\n",
      "Help - 96\n",
      "Help - 97\n",
      "Help - 98\n",
      "Help - 99\n",
      "Help - 100\n",
      "Help - 101\n",
      "Help - 102\n",
      "Help - 103\n",
      "Help - 104\n",
      "Help - 105\n",
      "Help - 106\n",
      "Help - 107\n",
      "Help - 108\n",
      "Help - 109\n",
      "Help - 110\n",
      "Help - 111\n",
      "Help - 112\n",
      "Help - 113\n",
      "Help - 114\n",
      "Help - 115\n",
      "Help - 116\n",
      "Help - 117\n",
      "Help - 118\n",
      "Help - 119\n",
      "Help - 120\n",
      "Help - 121\n",
      "Help - 122\n",
      "Help - 123\n",
      "Help - 124\n",
      "Help - 125\n",
      "Help - 126\n",
      "Help - 127\n",
      "Help - 128\n",
      "Help - 129\n",
      "Help - 130\n",
      "Help - 131\n",
      "Help - 132\n",
      "Help - 133\n",
      "Help - 134\n",
      "Help - 135\n",
      "Help - 136\n",
      "Help - 137\n",
      "Help - 138\n",
      "Help - 139\n",
      "Help - 140\n",
      "Help - 141\n",
      "Help - 142\n",
      "Help - 143\n",
      "Help - 144\n",
      "Help - 145\n",
      "Help - 146\n",
      "Help - 147\n",
      "Help - 148\n",
      "Help - 149\n",
      "Help - 150\n",
      "Help - 151\n",
      "Help - 152\n",
      "Help - 153\n",
      "Help - 154\n",
      "Help - 155\n",
      "Help - 156\n",
      "Help - 157\n",
      "Help - 158\n",
      "Help - 159\n",
      "Help - 160\n",
      "Help - 161\n",
      "Help - 162\n",
      "Help - 163\n",
      "Help - 164\n",
      "Help - 165\n",
      "Help - 166\n",
      "Help - 167\n",
      "Help - 168\n",
      "Help - 169\n",
      "Help - 170\n",
      "Help - 171\n",
      "Help - 172\n",
      "Help - 173\n",
      "Help - 174\n",
      "Help - 175\n",
      "Help - 176\n",
      "Help - 177\n",
      "Help - 178\n",
      "Help - 179\n",
      "Help - 180\n",
      "Help - 181\n",
      "Help - 182\n",
      "Help - 183\n",
      "Help - 184\n",
      "Help - 185\n",
      "Help - 186\n",
      "Help - 187\n",
      "Help - 188\n",
      "Help - 189\n",
      "Help - 190\n",
      "Help - 191\n",
      "Help - 192\n",
      "Help - 193\n",
      "Help - 194\n",
      "Help - 195\n",
      "Help - 196\n",
      "Help - 197\n",
      "Help - 198\n",
      "Help - 199\n",
      "Help - 200\n",
      "Help - 201\n",
      "Help - 202\n",
      "Help - 203\n",
      "Help - 204\n",
      "Help - 205\n",
      "Help - 206\n",
      "Help - 207\n",
      "Help - 208\n",
      "Help - 209\n",
      "Help - 210\n",
      "Help - 211\n",
      "Help - 212\n",
      "Help - 213\n",
      "Help - 214\n",
      "Help - 215\n",
      "Help - 216\n",
      "Help - 217\n",
      "Help - 218\n",
      "Help - 219\n",
      "Help - 220\n",
      "Help - 221\n",
      "Help - 222\n",
      "Help - 223\n",
      "Help - 224\n",
      "Help - 225\n",
      "Help - 226\n",
      "Help - 227\n",
      "Help - 228\n",
      "Help - 229\n",
      "Help - 230\n",
      "Help - 231\n",
      "Help - 232\n",
      "Help - 233\n",
      "Help - 234\n",
      "Help - 235\n",
      "Help - 236\n",
      "Help - 237\n",
      "Help - 238\n",
      "Help - 239\n"
     ]
    }
   ],
   "source": [
    "def generate_bulk_dataset_and_load(augment=True):\n",
    "    sequences, labels = [], []\n",
    "\n",
    "    for action in ACTIONS:\n",
    "        window = []\n",
    "        window_labels = []\n",
    "\n",
    "        \"\"\"Iterates over each sequence for the current action\"\"\"\n",
    "        for sequence in range(videos_per_label):\n",
    "            \"\"\"\n",
    "            Frame Processing\n",
    "\n",
    "            Iterates over each frame in the current sequence, then constructs the file path to the numpy array for the current frame.\n",
    "            Prints the path to verify correctness, then loads the frame data from the numpy file.\n",
    "            \"\"\"\n",
    "            # construct the path to the numpy file for the current frame\n",
    "            npy_path = os.path.join(DATASET_PATH, action, \"{}.npy\".format(sequence))\n",
    "\n",
    "            # load the frame data from the numpy file\n",
    "            result = np.load(npy_path)\n",
    "\n",
    "            # append the completed sequence to the sequences list\n",
    "            window.append(result)\n",
    "\n",
    "            # append the corresponding label to the labels list\n",
    "            window_labels.append(labels_map[action])\n",
    "\n",
    "            if not augment:\n",
    "                continue\n",
    "\n",
    "            # number of augmented window to create per original sequence\n",
    "            num_augmented_sequences = int(0.1 * 60)  # 10% of total of video\n",
    "\n",
    "            for _ in range(num_augmented_sequences):\n",
    "                augmented_sequence = [\n",
    "                    augment_landmarks(frame, noise_level=0.047, shift_factor=0.47)\n",
    "                    for frame in window\n",
    "                ]\n",
    "\n",
    "                # append the augmented to the window list\n",
    "                window.append(augmented_sequence[0])\n",
    "\n",
    "                window_labels.append(labels_map[action])\n",
    "\n",
    "            print(f\"{action} - {sequence}\")\n",
    "\n",
    "        sequences.append(window)\n",
    "        labels.append(window_labels)\n",
    "\n",
    "    keypoints = np.concatenate([s for s in sequences])\n",
    "    key_label = np.concatenate([l for l in labels])\n",
    "\n",
    "    # save the original sequences and labels\n",
    "    np.save(seq_path, keypoints)\n",
    "    np.save(lab_path, key_label)\n",
    "\n",
    "    return keypoints, key_label\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    if os.path.exists(seq_path) and os.path.exists(lab_path):\n",
    "        print(\"DATA IS BEING LOADED\")\n",
    "\n",
    "        sequences = np.load(seq_path, allow_pickle=True)\n",
    "        labels = np.load(lab_path, allow_pickle=True)\n",
    "\n",
    "        return sequences, labels\n",
    "\n",
    "    print(\"DATA IS BEING GENERATED AND LOADED\")\n",
    "\n",
    "    return generate_bulk_dataset_and_load(augment=True)\n",
    "\n",
    "\n",
    "sequences, labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13440, 13440)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjusting the Augmentation Factor**\n",
    "\n",
    "If you want to achieve a specific total number of sequences, you can adjust N<sub>augmented_per_original</sub>\n",
    "\n",
    "- Desired N<sub>total</sub> = 1920\n",
    "- Original N<sub>original</sub> = 480 (without augmentation)\n",
    "\n",
    "Using the formula to find N<sub>augmented_per_original</sub> :\n",
    "- 1920 = 480 + (480 × N<sub>augmented_per_original</sub>)\n",
    "\n",
    "Subtract 480 from both sides :\n",
    "- 1440 = 480 × N<sub>augmented_per_original</sub>\n",
    "\n",
    "Divide both sides by 480 :\n",
    "- N<sub>augmented_per_original</sub> = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "datas = np.array(sequences)\n",
    "\n",
    "# convert labels list to a one-hot encoded NumPy array\n",
    "labels = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13440, 13440)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the length of the datas and labels should be the same\n",
    "len(datas), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapes of the datasets depend on the total number of sequences and the sequence length. Here we processes 120 sequence of videos for each of the 4 actions, we have:\n",
    "\n",
    "    Total sequences = 120 sequences/action × 4 actions = 480 sequences\n",
    "\n",
    "Given a test_size of 0.2, 20% of the data (approximately 96 sequences) will be in the test set, and 80% (approximately 384 sequences) will be in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10752, 60, 225) (2688, 60, 225) (10752, 8) (2688, 8)\n"
     ]
    }
   ],
   "source": [
    "# splits the dataset into training and testing sets\n",
    "\n",
    "# specifies that 20% of the data should be used as the test set,\n",
    "# and the remaining 80% should be used as the training set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(datas, labels, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrong Output Example : `(384, 60, 225) (96, 60, 225) (384, 4, 2) (96, 4, 2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # augment the training data\n",
    "# X_train_augmented, y_train_augmented = augment_train_test_data(X_train, y_train)\n",
    "\n",
    "# # convert the test data to the required format\n",
    "# X_test = np.array(X_test)\n",
    "# y_test = np.array(y_test)\n",
    "\n",
    "# print(X_train_augmented.shape, X_test.shape, y_train_augmented.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\tf_keras\\src\\backend.py:6644: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 60, 225)]         0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 60, 225)           900       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 58, 64)            43264     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 29, 64)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 27, 128)           24704     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 27, 64)            8256      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 27, 64)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 128)               66048     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 144204 (563.30 KB)\n",
      "Trainable params: 143754 (561.54 KB)\n",
      "Non-trainable params: 450 (1.76 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_cnn_rnn_model(input_shape, num_classes):\n",
    "    # the input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # BatchNormalization layer to normalize input data\n",
    "    batch = tf.keras.layers.BatchNormalization()(inputs)\n",
    "\n",
    "    # CNN tf.keras.layers to extract spatial features\n",
    "    cnn = tf.keras.layers.Conv1D(64, 3, activation=\"relu\", kernel_regularizer=l2(0.02))(\n",
    "        batch\n",
    "    )\n",
    "    x = tf.keras.layers.MaxPooling1D(2)(cnn)\n",
    "\n",
    "    # CNN tf.keras.layers to extract spatial features\n",
    "    cnn = tf.keras.layers.Conv1D(\n",
    "        128, 3, activation=\"relu\", kernel_regularizer=l2(0.02)\n",
    "    )(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(cnn)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=l2(0.02))(cnn)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    rnn = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation=\"relu\"))(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=l2(0.02))(rnn)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_regularizer=l2(0.02))(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(rnn)\n",
    "\n",
    "    # create the model\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# where 60 is the sequence length\n",
    "# and 225 is the number of features (keypoints) per frame\n",
    "input_shape = (60, 225)\n",
    "num_classes = ACTIONS.shape[0]  # N gesture classes\n",
    "\n",
    "# Create the model\n",
    "model = create_cnn_rnn_model(input_shape, num_classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up callbacks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new log directory: ../storage/logs\\train-20240611-153807\n"
     ]
    }
   ],
   "source": [
    "def create_log_dir(base_dir, use_time=False):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    # check existing log directories\n",
    "    existing_logs = [\n",
    "        d\n",
    "        for d in os.listdir(base_dir)\n",
    "        if os.path.isdir(os.path.join(base_dir, d)) and d.startswith(\"train-\")\n",
    "    ]\n",
    "\n",
    "    # determine the new log directory name\n",
    "    if existing_logs and not use_time:\n",
    "        latest_log = max(existing_logs)\n",
    "        log_num = int(latest_log.split(\"-\")[1]) + 1\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{str(log_num).zfill(3)}\")\n",
    "\n",
    "    if not existing_logs and not use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-001\")\n",
    "\n",
    "    if use_time:\n",
    "        new_log_dir = os.path.join(base_dir, f\"train-{current_time}\")\n",
    "\n",
    "    # create the new log directory\n",
    "    os.makedirs(new_log_dir)\n",
    "    print(f\"Created new log directory: {new_log_dir}\")\n",
    "\n",
    "    return new_log_dir\n",
    "\n",
    "# callback for logging\n",
    "log_dir = os.path.join(create_log_dir(os.path.join(\"../storage/logs\"), True))\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the optimizer with an initial learning rate\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "# compile the model with the optimizer\n",
    "model.compile(\n",
    "    optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=30, restore_best_weights=True\n",
    ")\n",
    "\n",
    "es_acc = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    min_delta=0,\n",
    "    patience=50,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From u:\\workspace\\bangkit\\capstone\\signa_lingua-vision-slr-public\\venv\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "336/336 [==============================] - 22s 14ms/step - loss: 5.9740 - accuracy: 0.5330 - val_loss: 4.8467 - val_accuracy: 0.7984 - lr: 1.0000e-04\n",
      "Epoch 2/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 4.2894 - accuracy: 0.8042 - val_loss: 3.7684 - val_accuracy: 0.8430 - lr: 1.0000e-04\n",
      "Epoch 3/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 3.5221 - accuracy: 0.8450 - val_loss: 3.1898 - val_accuracy: 0.8616 - lr: 1.0000e-04\n",
      "Epoch 4/500\n",
      "336/336 [==============================] - 4s 10ms/step - loss: 2.9928 - accuracy: 0.8652 - val_loss: 2.7415 - val_accuracy: 0.8828 - lr: 1.0000e-04\n",
      "Epoch 5/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 2.5857 - accuracy: 0.8840 - val_loss: 2.3935 - val_accuracy: 0.8873 - lr: 1.0000e-04\n",
      "Epoch 6/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 2.2340 - accuracy: 0.9009 - val_loss: 2.0764 - val_accuracy: 0.9010 - lr: 1.0000e-04\n",
      "Epoch 7/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 1.9683 - accuracy: 0.9105 - val_loss: 1.8941 - val_accuracy: 0.9051 - lr: 1.0000e-04\n",
      "Epoch 8/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 1.7417 - accuracy: 0.9188 - val_loss: 1.6559 - val_accuracy: 0.9115 - lr: 1.0000e-04\n",
      "Epoch 9/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 1.5355 - accuracy: 0.9342 - val_loss: 1.4462 - val_accuracy: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 10/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 1.3752 - accuracy: 0.9397 - val_loss: 1.2960 - val_accuracy: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 11/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 1.2160 - accuracy: 0.9507 - val_loss: 1.1571 - val_accuracy: 0.9487 - lr: 1.0000e-04\n",
      "Epoch 12/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 1.0955 - accuracy: 0.9510 - val_loss: 1.0568 - val_accuracy: 0.9520 - lr: 1.0000e-04\n",
      "Epoch 13/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.9832 - accuracy: 0.9562 - val_loss: 0.9470 - val_accuracy: 0.9580 - lr: 1.0000e-04\n",
      "Epoch 14/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.8872 - accuracy: 0.9583 - val_loss: 0.8796 - val_accuracy: 0.9516 - lr: 1.0000e-04\n",
      "Epoch 15/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.8052 - accuracy: 0.9620 - val_loss: 0.7883 - val_accuracy: 0.9628 - lr: 1.0000e-04\n",
      "Epoch 16/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.7340 - accuracy: 0.9654 - val_loss: 0.7625 - val_accuracy: 0.9557 - lr: 1.0000e-04\n",
      "Epoch 17/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.6661 - accuracy: 0.9711 - val_loss: 0.6510 - val_accuracy: 0.9632 - lr: 1.0000e-04\n",
      "Epoch 18/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.6117 - accuracy: 0.9695 - val_loss: 0.6058 - val_accuracy: 0.9680 - lr: 1.0000e-04\n",
      "Epoch 19/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.5683 - accuracy: 0.9689 - val_loss: 0.6299 - val_accuracy: 0.9505 - lr: 1.0000e-04\n",
      "Epoch 20/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.5253 - accuracy: 0.9742 - val_loss: 0.5482 - val_accuracy: 0.9650 - lr: 1.0000e-04\n",
      "Epoch 21/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.4795 - accuracy: 0.9759 - val_loss: 0.4996 - val_accuracy: 0.9658 - lr: 1.0000e-04\n",
      "Epoch 22/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.4472 - accuracy: 0.9745 - val_loss: 0.4671 - val_accuracy: 0.9680 - lr: 1.0000e-04\n",
      "Epoch 23/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.4067 - accuracy: 0.9810 - val_loss: 0.4365 - val_accuracy: 0.9721 - lr: 1.0000e-04\n",
      "Epoch 24/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.3931 - accuracy: 0.9781 - val_loss: 0.4244 - val_accuracy: 0.9710 - lr: 1.0000e-04\n",
      "Epoch 25/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.3587 - accuracy: 0.9816 - val_loss: 0.3938 - val_accuracy: 0.9699 - lr: 1.0000e-04\n",
      "Epoch 26/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.3398 - accuracy: 0.9823 - val_loss: 0.3908 - val_accuracy: 0.9639 - lr: 1.0000e-04\n",
      "Epoch 27/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.3245 - accuracy: 0.9799 - val_loss: 0.3443 - val_accuracy: 0.9740 - lr: 1.0000e-04\n",
      "Epoch 28/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.3004 - accuracy: 0.9835 - val_loss: 0.3416 - val_accuracy: 0.9702 - lr: 1.0000e-04\n",
      "Epoch 29/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.2897 - accuracy: 0.9818 - val_loss: 0.3252 - val_accuracy: 0.9714 - lr: 1.0000e-04\n",
      "Epoch 30/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.2654 - accuracy: 0.9866 - val_loss: 0.2973 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 31/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.2662 - accuracy: 0.9834 - val_loss: 0.2856 - val_accuracy: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 32/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.2486 - accuracy: 0.9855 - val_loss: 0.2823 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 33/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.2433 - accuracy: 0.9836 - val_loss: 0.2727 - val_accuracy: 0.9788 - lr: 1.0000e-04\n",
      "Epoch 34/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.2329 - accuracy: 0.9836 - val_loss: 0.2685 - val_accuracy: 0.9788 - lr: 1.0000e-04\n",
      "Epoch 35/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.2239 - accuracy: 0.9848 - val_loss: 0.2452 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 36/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.2091 - accuracy: 0.9878 - val_loss: 0.2510 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 37/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.2015 - accuracy: 0.9880 - val_loss: 0.2459 - val_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 38/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1956 - accuracy: 0.9875 - val_loss: 0.2609 - val_accuracy: 0.9721 - lr: 1.0000e-04\n",
      "Epoch 39/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1949 - accuracy: 0.9865 - val_loss: 0.2154 - val_accuracy: 0.9788 - lr: 1.0000e-04\n",
      "Epoch 40/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1898 - accuracy: 0.9853 - val_loss: 0.2119 - val_accuracy: 0.9810 - lr: 1.0000e-04\n",
      "Epoch 41/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1797 - accuracy: 0.9876 - val_loss: 0.2252 - val_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 42/500\n",
      "336/336 [==============================] - 4s 11ms/step - loss: 0.1765 - accuracy: 0.9879 - val_loss: 0.2011 - val_accuracy: 0.9814 - lr: 1.0000e-04\n",
      "Epoch 43/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1729 - accuracy: 0.9874 - val_loss: 0.2136 - val_accuracy: 0.9751 - lr: 1.0000e-04\n",
      "Epoch 44/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1762 - accuracy: 0.9850 - val_loss: 0.1971 - val_accuracy: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 45/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1630 - accuracy: 0.9890 - val_loss: 0.2513 - val_accuracy: 0.9661 - lr: 1.0000e-04\n",
      "Epoch 46/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1545 - accuracy: 0.9901 - val_loss: 0.2058 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 47/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1559 - accuracy: 0.9879 - val_loss: 0.2067 - val_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 48/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1541 - accuracy: 0.9885 - val_loss: 0.1934 - val_accuracy: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 49/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1501 - accuracy: 0.9881 - val_loss: 0.2000 - val_accuracy: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 50/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1438 - accuracy: 0.9898 - val_loss: 0.2153 - val_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 51/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1509 - accuracy: 0.9863 - val_loss: 0.2171 - val_accuracy: 0.9699 - lr: 1.0000e-04\n",
      "Epoch 52/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1455 - accuracy: 0.9881 - val_loss: 0.1978 - val_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 53/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1378 - accuracy: 0.9900 - val_loss: 0.1870 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 54/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1272 - accuracy: 0.9923 - val_loss: 0.2142 - val_accuracy: 0.9732 - lr: 1.0000e-04\n",
      "Epoch 55/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1407 - accuracy: 0.9871 - val_loss: 0.1865 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 56/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1366 - accuracy: 0.9889 - val_loss: 0.1898 - val_accuracy: 0.9751 - lr: 1.0000e-04\n",
      "Epoch 57/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1370 - accuracy: 0.9874 - val_loss: 0.2296 - val_accuracy: 0.9695 - lr: 1.0000e-04\n",
      "Epoch 58/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1326 - accuracy: 0.9891 - val_loss: 0.1806 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 59/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1325 - accuracy: 0.9886 - val_loss: 0.1834 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 60/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1300 - accuracy: 0.9897 - val_loss: 0.1863 - val_accuracy: 0.9747 - lr: 1.0000e-04\n",
      "Epoch 61/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1277 - accuracy: 0.9902 - val_loss: 0.1672 - val_accuracy: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 62/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1228 - accuracy: 0.9906 - val_loss: 0.1608 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 63/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1340 - accuracy: 0.9863 - val_loss: 0.1679 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 64/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1209 - accuracy: 0.9897 - val_loss: 0.1628 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 65/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1119 - accuracy: 0.9919 - val_loss: 0.1576 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 66/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1140 - accuracy: 0.9914 - val_loss: 0.1454 - val_accuracy: 0.9840 - lr: 1.0000e-04\n",
      "Epoch 67/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1134 - accuracy: 0.9908 - val_loss: 0.1585 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 68/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1186 - accuracy: 0.9888 - val_loss: 0.1561 - val_accuracy: 0.9814 - lr: 1.0000e-04\n",
      "Epoch 69/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1049 - accuracy: 0.9927 - val_loss: 0.1374 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 70/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1178 - accuracy: 0.9890 - val_loss: 0.1534 - val_accuracy: 0.9803 - lr: 1.0000e-04\n",
      "Epoch 71/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1167 - accuracy: 0.9892 - val_loss: 0.1487 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 72/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1163 - accuracy: 0.9886 - val_loss: 0.1642 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 73/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1159 - accuracy: 0.9898 - val_loss: 0.1605 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 74/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1047 - accuracy: 0.9923 - val_loss: 0.1673 - val_accuracy: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 75/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1057 - accuracy: 0.9913 - val_loss: 0.1427 - val_accuracy: 0.9862 - lr: 1.0000e-04\n",
      "Epoch 76/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1087 - accuracy: 0.9908 - val_loss: 0.1482 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 77/500\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.1083 - accuracy: 0.9914 - val_loss: 0.1288 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
      "Epoch 78/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1093 - accuracy: 0.9902 - val_loss: 0.1493 - val_accuracy: 0.9781 - lr: 1.0000e-04\n",
      "Epoch 79/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0999 - accuracy: 0.9927 - val_loss: 0.1544 - val_accuracy: 0.9847 - lr: 1.0000e-04\n",
      "Epoch 80/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1018 - accuracy: 0.9925 - val_loss: 0.1550 - val_accuracy: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 81/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1060 - accuracy: 0.9900 - val_loss: 0.1507 - val_accuracy: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 82/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1013 - accuracy: 0.9907 - val_loss: 0.1537 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 83/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1059 - accuracy: 0.9908 - val_loss: 0.1259 - val_accuracy: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 84/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0968 - accuracy: 0.9924 - val_loss: 0.1332 - val_accuracy: 0.9859 - lr: 1.0000e-04\n",
      "Epoch 85/500\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0979 - accuracy: 0.9916 - val_loss: 0.1473 - val_accuracy: 0.9840 - lr: 1.0000e-04\n",
      "Epoch 86/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1048 - accuracy: 0.9907 - val_loss: 0.1502 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 87/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.1035 - accuracy: 0.9896 - val_loss: 0.1525 - val_accuracy: 0.9751 - lr: 1.0000e-04\n",
      "Epoch 88/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0965 - accuracy: 0.9924 - val_loss: 0.1323 - val_accuracy: 0.9833 - lr: 1.0000e-04\n",
      "Epoch 89/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0958 - accuracy: 0.9926 - val_loss: 0.1446 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 90/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0990 - accuracy: 0.9903 - val_loss: 0.1246 - val_accuracy: 0.9859 - lr: 1.0000e-04\n",
      "Epoch 91/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0915 - accuracy: 0.9931 - val_loss: 0.1363 - val_accuracy: 0.9859 - lr: 1.0000e-04\n",
      "Epoch 92/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0932 - accuracy: 0.9929 - val_loss: 0.1158 - val_accuracy: 0.9862 - lr: 1.0000e-04\n",
      "Epoch 93/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0955 - accuracy: 0.9913 - val_loss: 0.1241 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
      "Epoch 94/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0983 - accuracy: 0.9911 - val_loss: 0.1334 - val_accuracy: 0.9829 - lr: 1.0000e-04\n",
      "Epoch 95/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0906 - accuracy: 0.9925 - val_loss: 0.1368 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 96/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0988 - accuracy: 0.9908 - val_loss: 0.1225 - val_accuracy: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 97/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0882 - accuracy: 0.9939 - val_loss: 0.1073 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
      "Epoch 98/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0965 - accuracy: 0.9900 - val_loss: 0.1080 - val_accuracy: 0.9888 - lr: 1.0000e-04\n",
      "Epoch 99/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0873 - accuracy: 0.9935 - val_loss: 0.1235 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 100/500\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0928 - accuracy: 0.9924 - val_loss: 0.1031 - val_accuracy: 0.9900 - lr: 1.0000e-04\n",
      "Epoch 101/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0996 - accuracy: 0.9905 - val_loss: 0.1147 - val_accuracy: 0.9836 - lr: 1.0000e-04\n",
      "Epoch 102/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0812 - accuracy: 0.9948 - val_loss: 0.1240 - val_accuracy: 0.9840 - lr: 1.0000e-04\n",
      "Epoch 103/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0921 - accuracy: 0.9921 - val_loss: 0.1144 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 104/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0891 - accuracy: 0.9921 - val_loss: 0.1194 - val_accuracy: 0.9862 - lr: 1.0000e-04\n",
      "Epoch 105/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0819 - accuracy: 0.9949 - val_loss: 0.1192 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 106/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0910 - accuracy: 0.9918 - val_loss: 0.1002 - val_accuracy: 0.9888 - lr: 1.0000e-04\n",
      "Epoch 107/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0863 - accuracy: 0.9934 - val_loss: 0.1190 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
      "Epoch 108/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0975 - accuracy: 0.9897 - val_loss: 0.1138 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
      "Epoch 109/500\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0815 - accuracy: 0.9945 - val_loss: 0.1376 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 110/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0836 - accuracy: 0.9936 - val_loss: 0.1146 - val_accuracy: 0.9877 - lr: 1.0000e-04\n",
      "Epoch 111/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0913 - accuracy: 0.9904 - val_loss: 0.1297 - val_accuracy: 0.9829 - lr: 1.0000e-04\n",
      "Epoch 112/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0951 - accuracy: 0.9906 - val_loss: 0.1516 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 113/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0905 - accuracy: 0.9912 - val_loss: 0.1150 - val_accuracy: 0.9847 - lr: 1.0000e-04\n",
      "Epoch 114/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0885 - accuracy: 0.9930 - val_loss: 0.1141 - val_accuracy: 0.9847 - lr: 1.0000e-04\n",
      "Epoch 115/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0928 - accuracy: 0.9914 - val_loss: 0.1347 - val_accuracy: 0.9814 - lr: 1.0000e-04\n",
      "Epoch 116/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0792 - accuracy: 0.9949 - val_loss: 0.1320 - val_accuracy: 0.9836 - lr: 1.0000e-04\n",
      "Epoch 117/500\n",
      "336/336 [==============================] - 5s 15ms/step - loss: 0.0754 - accuracy: 0.9957 - val_loss: 0.1196 - val_accuracy: 0.9866 - lr: 5.0000e-05\n",
      "Epoch 118/500\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0737 - accuracy: 0.9958 - val_loss: 0.1163 - val_accuracy: 0.9855 - lr: 5.0000e-05\n",
      "Epoch 119/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0729 - accuracy: 0.9958 - val_loss: 0.1208 - val_accuracy: 0.9866 - lr: 5.0000e-05\n",
      "Epoch 120/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0684 - accuracy: 0.9969 - val_loss: 0.1310 - val_accuracy: 0.9851 - lr: 5.0000e-05\n",
      "Epoch 121/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0695 - accuracy: 0.9952 - val_loss: 0.1130 - val_accuracy: 0.9866 - lr: 5.0000e-05\n",
      "Epoch 122/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0682 - accuracy: 0.9957 - val_loss: 0.1080 - val_accuracy: 0.9881 - lr: 5.0000e-05\n",
      "Epoch 123/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0648 - accuracy: 0.9967 - val_loss: 0.1057 - val_accuracy: 0.9870 - lr: 5.0000e-05\n",
      "Epoch 124/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0655 - accuracy: 0.9958 - val_loss: 0.1154 - val_accuracy: 0.9799 - lr: 5.0000e-05\n",
      "Epoch 125/500\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0633 - accuracy: 0.9967 - val_loss: 0.1184 - val_accuracy: 0.9862 - lr: 5.0000e-05\n",
      "Epoch 126/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0632 - accuracy: 0.9958 - val_loss: 0.1215 - val_accuracy: 0.9847 - lr: 5.0000e-05\n",
      "Epoch 127/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0572 - accuracy: 0.9975 - val_loss: 0.1136 - val_accuracy: 0.9844 - lr: 2.5000e-05\n",
      "Epoch 128/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0567 - accuracy: 0.9975 - val_loss: 0.1063 - val_accuracy: 0.9866 - lr: 2.5000e-05\n",
      "Epoch 129/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0596 - accuracy: 0.9967 - val_loss: 0.1041 - val_accuracy: 0.9859 - lr: 2.5000e-05\n",
      "Epoch 130/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0559 - accuracy: 0.9970 - val_loss: 0.1020 - val_accuracy: 0.9874 - lr: 2.5000e-05\n",
      "Epoch 131/500\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0553 - accuracy: 0.9971 - val_loss: 0.1048 - val_accuracy: 0.9844 - lr: 2.5000e-05\n",
      "Epoch 132/500\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0530 - accuracy: 0.9975 - val_loss: 0.1005 - val_accuracy: 0.9885 - lr: 2.5000e-05\n",
      "Epoch 133/500\n",
      "336/336 [==============================] - 4s 13ms/step - loss: 0.0541 - accuracy: 0.9967 - val_loss: 0.1152 - val_accuracy: 0.9840 - lr: 2.5000e-05\n",
      "Epoch 134/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0516 - accuracy: 0.9972 - val_loss: 0.1089 - val_accuracy: 0.9851 - lr: 2.5000e-05\n",
      "Epoch 135/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0511 - accuracy: 0.9973 - val_loss: 0.1027 - val_accuracy: 0.9855 - lr: 2.5000e-05\n",
      "Epoch 136/500\n",
      "336/336 [==============================] - 4s 12ms/step - loss: 0.0517 - accuracy: 0.9970 - val_loss: 0.1216 - val_accuracy: 0.9818 - lr: 2.5000e-05\n",
      "Restoring model weights from the end of the best epoch: 97.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# train the model with the callbacks\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=500,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[logging, early_stopping, es_acc, lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "# compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9991\n",
      "Test accuracy: 0.9990699291229248\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_train, y_train)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9906994047619048\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(ACTIONS))\n",
    "plt.xticks(tick_marks, ACTIONS, rotation=45)\n",
    "plt.yticks(tick_marks, ACTIONS)\n",
    "\n",
    "# add labels\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# compute and print accuracy score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_filename(directory, base_name, extension):\n",
    "    # list all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # filter files that start with the base_name and end with the extension\n",
    "    versions = [f for f in files if f.startswith(base_name) and f.endswith(extension)]\n",
    "\n",
    "    # if the models directory is empty, then use the\n",
    "    # default start version (001)\n",
    "    if not versions and base_name == \"singa_slr_v_\":\n",
    "        return f\"{base_name}001.{extension}\"\n",
    "\n",
    "    # if the fiven basename is different than the actual basename\n",
    "    # then save the model with given name\n",
    "    if not base_name == \"singa_slr_v_\":\n",
    "        return f\"{base_name}.{extension}\"\n",
    "\n",
    "    # extract version numbers from filenames\n",
    "    versions = [file.split(\"_\")[-1] for file in versions]\n",
    "\n",
    "    # convert version numbers to tuples of integers for comparison\n",
    "    versions_int = [int(v.split(\".\")[0]) for v in versions]\n",
    "\n",
    "    next_version = max(versions_int) + 1\n",
    "\n",
    "    # format the next number with leading zeros to maintain the same length\n",
    "    next_filename = f\"{base_name}{next_version:03d}.{extension}\"\n",
    "\n",
    "    return next_filename\n",
    "\n",
    "\n",
    "def save_as_tflite(_model, model_path):\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # export the model to the temporary directory\n",
    "        export_path = os.path.join(temp_dir, \"_tf_temp\")\n",
    "\n",
    "        _model.export(export_path)\n",
    "\n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
    "        # Enable resource variables and selective ops to handle the conversion issues\n",
    "        converter.experimental_enable_resource_variables = True\n",
    "        converter.target_spec.supported_ops = [\n",
    "            tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "            tf.lite.OpsSet.SELECT_TF_OPS,\n",
    "        ]\n",
    "        converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "        tflite_model = converter.convert()\n",
    "\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def save_as_keras(_model, model_path):\n",
    "    _model.save(model_path)\n",
    "\n",
    "\n",
    "def save_model(_model, extension=\"keras\", base_name=\"singa_slr_v_\"):\n",
    "    model_dir = \"../storage/models/\" + extension\n",
    "\n",
    "    next_filename = get_next_filename(model_dir, base_name, extension)\n",
    "    model_path = os.path.join(model_dir, next_filename)\n",
    "\n",
    "    match extension:\n",
    "        case \"tflite\":\n",
    "            save_as_tflite(_model, model_path)\n",
    "            print(f\"saved as tflite at {model_path}\")\n",
    "\n",
    "        case \"keras\":\n",
    "            save_as_keras(_model, model_path)\n",
    "            print(f\"saved as keras at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved as keras at ../storage/models/keras\\singa_slr_v_002.keras\n"
     ]
    }
   ],
   "source": [
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\acer\\AppData\\Local\\Temp\\tmp787zxqrr\\_tf_temp\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\acer\\AppData\\Local\\Temp\\tmp787zxqrr\\_tf_temp\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\acer\\AppData\\Local\\Temp\\tmp787zxqrr\\_tf_temp'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 60, 225), dtype=tf.float32, name='input_1')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2266830891744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2266830888048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2266830890512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2266830889280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2266830895264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2266830894032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2266432086336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099197248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099196192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099201120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099993552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099195136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099194784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099204640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099203584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099190560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272100005344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2272099994432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "saved as tflite at ../storage/models/tflite\\singa_slr_v_002.tflite\n"
     ]
    }
   ],
   "source": [
    "save_model(model, extension=\"tflite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
