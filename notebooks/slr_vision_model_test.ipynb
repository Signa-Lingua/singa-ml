{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVHDUj-rmgS7",
        "outputId": "1dc41b88-f4c8-44e6-8856-0d694fce1f80"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kNJg0rvmmTZ",
        "outputId": "8503fef8-43b4-4abe-dd92-5349b94b0561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.15.0)Note: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: mediapipe in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.14)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.8.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: jax in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.4.28)\n",
            "Requirement already satisfied: jaxlib in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.4.28)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (3.8.3)\n",
            "Requirement already satisfied: opencv-contrib-python in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.4.7)\n",
            "Requirement already satisfied: CFFI>=1.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: scipy>=1.9 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jax->mediapipe) (1.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.26.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.3.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow mediapipe opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E-_viZ26mYu-"
      },
      "outputs": [],
      "source": [
        "import cv2  # type: ignore\n",
        "import os\n",
        "import time\n",
        "import numpy as np  # type: ignore\n",
        "\n",
        "import mediapipe as mp  # type: ignore\n",
        "\n",
        "from matplotlib import pyplot as plt # type: ignore\n",
        "from mediapipe.tasks import python  # type: ignore\n",
        "from mediapipe.tasks.python import vision  # type: ignore\n",
        "from mediapipe.framework.formats import landmark_pb2 # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZpDGGhmimYvA"
      },
      "outputs": [],
      "source": [
        "drawer = mp.solutions.drawing_utils # drawing utilities\n",
        "VisionRunningMode = mp.tasks.vision.RunningMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J0MMKea0mYvA"
      },
      "outputs": [],
      "source": [
        "face_base_options = python.BaseOptions(model_asset_path=\"./tasks/face_landmarker.task\")\n",
        "hand_base_options = python.BaseOptions(model_asset_path=\"./tasks/hand_landmarker.task\")\n",
        "pose_base_options = python.BaseOptions(model_asset_path=\"./tasks/pose_landmarker.task\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3CNaEbeImYvA"
      },
      "outputs": [],
      "source": [
        "face_options = vision.FaceLandmarkerOptions(\n",
        "    base_options=face_base_options,\n",
        "    output_face_blendshapes=True,\n",
        "    output_facial_transformation_matrixes=True,\n",
        "    num_faces=1,\n",
        "    running_mode=VisionRunningMode.VIDEO,\n",
        ")\n",
        "\n",
        "hand_options = vision.HandLandmarkerOptions(\n",
        "    base_options=hand_base_options,\n",
        "    num_hands=2,\n",
        "    running_mode=VisionRunningMode.VIDEO,\n",
        ")\n",
        "\n",
        "pose_options = vision.PoseLandmarkerOptions(\n",
        "    base_options=pose_base_options,\n",
        "    output_segmentation_masks=True,\n",
        "    running_mode=VisionRunningMode.VIDEO,\n",
        ")\n",
        "\n",
        "\n",
        "face_detector = vision.FaceLandmarker.create_from_options(face_options)\n",
        "hand_detector = vision.HandLandmarker.create_from_options(hand_options)\n",
        "pose_detector = vision.PoseLandmarker.create_from_options(pose_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6_sXToKhmYvA"
      },
      "outputs": [],
      "source": [
        "LandmarkList = landmark_pb2.NormalizedLandmarkList\n",
        "NormalizedLandmark = landmark_pb2.NormalizedLandmark\n",
        "\n",
        "\n",
        "def create_landmark_list(landmarks, num_keypoints):\n",
        "    \"\"\"Creates a LandmarkList protocol buffer from a list of landmarks or fills with empty values if no landmarks are provided.\n",
        "\n",
        "    Args:\n",
        "        landmarks: A list of landmark objects, each containing x, y, z coordinates.\n",
        "        num_keypoints: The number of keypoints to be included in the LandmarkList.\n",
        "\n",
        "    Returns:\n",
        "        A LandmarkList containing the converted landmarks or empty values if no landmarks are provided.\n",
        "    \"\"\"\n",
        "    # generate empty landmarks with all coordinates set to 0.0\n",
        "    empty_landmarks = [\n",
        "        NormalizedLandmark(x=0.0, y=0.0, z=0.0) for _ in range(num_keypoints)\n",
        "    ]\n",
        "\n",
        "    return LandmarkList(\n",
        "        landmark=(\n",
        "            # convert provided landmarks to NormalizedLandmark objects or use empty landmarks\n",
        "            [NormalizedLandmark(x=lm.x, y=lm.y, z=lm.z) for lm in landmarks]\n",
        "            if landmarks\n",
        "            else empty_landmarks\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def extract_keypoints_for_drawing(face_results, pose_results, hand_results):\n",
        "    \"\"\"Converts face, pose, and hand landmarks to corresponding protocol buffer lists for drawing.\n",
        "\n",
        "    Args:\n",
        "        face_results: Object containing face landmark detection results.\n",
        "        pose_results: Object containing pose landmark detection results.\n",
        "        hand_results: Object containing hand landmark detection results.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing three LandmarkList messages: face_landmarks, pose_landmarks, and hand_landmarks.\n",
        "    \"\"\"\n",
        "    # convert face landmarks to LandmarkList, using empty values if no landmarks are present\n",
        "    face_landmarks_proto = create_landmark_list(\n",
        "        face_results.face_landmarks[0] if face_results.face_landmarks else None, 478 * 3\n",
        "    )\n",
        "\n",
        "    # convert pose landmarks to LandmarkList, using empty values if no landmarks are present\n",
        "    pose_landmarks_proto = create_landmark_list(\n",
        "        pose_results.pose_landmarks[0] if pose_results.pose_landmarks else None, 33 * 4\n",
        "    )\n",
        "\n",
        "    # convert hand landmarks to LandmarkList, using empty values if no landmarks are present\n",
        "    hand_landmarks_proto = [\n",
        "        create_landmark_list(hand_landmarks, 21 * 3)\n",
        "        for hand_landmarks in (\n",
        "            hand_results.hand_landmarks\n",
        "            if hand_results.hand_landmarks\n",
        "            else [None, None]  # two hands\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    return face_landmarks_proto, pose_landmarks_proto, hand_landmarks_proto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iktXTU9WmYvB"
      },
      "outputs": [],
      "source": [
        "def extract_keypoints(face_results, pose_results, hand_results):\n",
        "    \"\"\"Extracts keypoints from face, pose, and hand results for dataset creation.\n",
        "\n",
        "    Handles cases with zero, one, or two hands, assigning hand keypoints based\n",
        "    on handedness information.\n",
        "\n",
        "    Args:\n",
        "      face_results: Object containing face landmark data (if available), assumed to\n",
        "                    have a `face_landmarks` attribute with landmark data.\n",
        "      pose_results: Object containing pose landmark data (if available), assumed to\n",
        "                    have a `pose_landmarks` attribute with landmark data.\n",
        "      hand_results: Object containing hand landmark data (if available), assumed to\n",
        "                    have `hand_landmarks` and `handedness` attributes.\n",
        "\n",
        "    Returns:\n",
        "      A tuple containing three NumPy arrays representing flattened keypoints for face,\n",
        "      pose, and hand, respectively. Empty arrays are used for missing modalities.\n",
        "    \"\"\"\n",
        "\n",
        "    # extract face keypoints if available, otherwise return a zero-filled array\n",
        "    face_keypoints = (\n",
        "        np.array(\n",
        "            [\n",
        "                [landmark.x, landmark.y, landmark.z]\n",
        "                for landmark in face_results.face_landmarks[0]\n",
        "            ]\n",
        "        ).flatten()\n",
        "        if face_results.face_landmarks\n",
        "        else np.zeros(478 * 3)  # 478 landmarks with 3 coordinates each (x, y, z)\n",
        "    )\n",
        "\n",
        "    # extract pose keypoints if available, otherwise return a zero-filled array\n",
        "    pose_keypoints = (\n",
        "        np.array(\n",
        "            [\n",
        "                [landmark.x, landmark.y, landmark.z, landmark.visibility]\n",
        "                for landmark in pose_results.pose_landmarks[0]\n",
        "            ]\n",
        "        ).flatten()\n",
        "        if pose_results.pose_landmarks\n",
        "        else np.zeros(33 * 4)  # 33 landmarks with 4 values each (x, y, z, visibility)\n",
        "    )\n",
        "\n",
        "    # initialize hand keypoints with zeros for two hands (right and left),\n",
        "    # each with 21 landmarks and 3 coordinates\n",
        "    hand_keypoints = np.zeros((2, 21, 3))\n",
        "\n",
        "    # if no hand results are available, return the empty hand keypoints\n",
        "    # and concatenate it with face and pose keypoints\n",
        "    if not hand_results:\n",
        "        return np.concatenate(\n",
        "            [face_keypoints, pose_keypoints, hand_keypoints.flatten()]\n",
        "        )\n",
        "\n",
        "    # iterate over the detected hand landmarks\n",
        "    for idx in range(len(hand_results.hand_landmarks)):\n",
        "        # determine the hand index (0 for right hand, 1 for left hand) using handedness information\n",
        "        handedness = hand_results.handedness[idx][0].index\n",
        "\n",
        "        # extract the keypoints for the current hand and assign them to the appropriate index\n",
        "        hand_keypoints[handedness] = np.array(\n",
        "            [[lm.x, lm.y, lm.z] for lm in hand_results.hand_landmarks[idx]]\n",
        "        )\n",
        "\n",
        "    # flatten the hand keypoints array and concatenate it with face and pose keypoints\n",
        "    return np.concatenate([face_keypoints, pose_keypoints, hand_keypoints.flatten()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "shLcpsYOmYvB"
      },
      "outputs": [],
      "source": [
        "def draw_detection_landmark(\n",
        "    image,\n",
        "    face_landmarks_proto=None,\n",
        "    pose_landmarks_proto=None,\n",
        "    hand_landmarks_proto=None,\n",
        "):\n",
        "    # draw landmark face\n",
        "    drawer.draw_landmarks(\n",
        "        image,\n",
        "        face_landmarks_proto,\n",
        "        mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
        "        drawer.DrawingSpec(color=(80, 60, 20), thickness=1, circle_radius=1),\n",
        "        drawer.DrawingSpec(color=(80, 146, 241), thickness=1, circle_radius=1),\n",
        "    )\n",
        "\n",
        "    # draw landmark pose\n",
        "    drawer.draw_landmarks(\n",
        "        image,\n",
        "        pose_landmarks_proto,\n",
        "        mp.solutions.pose.POSE_CONNECTIONS,\n",
        "        drawer.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=3),\n",
        "        drawer.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2),\n",
        "    )\n",
        "\n",
        "    # draw landmark for both hand (right, left)\n",
        "    for idx in range(len(hand_landmarks_proto)):\n",
        "        drawer.draw_landmarks(\n",
        "            image,\n",
        "            hand_landmarks_proto[idx],\n",
        "            mp.solutions.hands.HAND_CONNECTIONS,\n",
        "            drawer.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=2),\n",
        "            drawer.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rKxWp-44mYvB"
      },
      "outputs": [],
      "source": [
        "def calculate_fps(start_time, frames):\n",
        "    elapsed_time = time.time() - start_time\n",
        "    return frames / elapsed_time if elapsed_time > 0 else 0\n",
        "\n",
        "\n",
        "def draw_fps(image, fps):\n",
        "    cv2.putText(\n",
        "        image,\n",
        "        f\"FPS: {round(fps, 2)}\",\n",
        "        (10, 40),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        1.5,\n",
        "        (0, 255, 0),\n",
        "        2,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Sa_lSLcQmYvC"
      },
      "outputs": [],
      "source": [
        "colors = [(245, 117, 16), (117, 245, 16), (16, 117, 245),\n",
        "          (117, 117, 16), (16, 245, 117), (245, 117, 245)]\n",
        "\n",
        "def confidence_bar(res, actions, input_frame, colors):\n",
        "    output_frame = input_frame.copy()\n",
        "\n",
        "    for num, prob in enumerate(res):\n",
        "        cv2.rectangle(\n",
        "            output_frame,\n",
        "            (0, 60 + num * 40),\n",
        "            (int(prob * 100), 90 + num * 40),\n",
        "            colors[num],\n",
        "            -1,\n",
        "        )\n",
        "\n",
        "        cv2.putText(\n",
        "            output_frame,\n",
        "            actions[num],\n",
        "            (0, 85 + num * 40),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            1,\n",
        "            (255, 255, 255),\n",
        "            2,\n",
        "            cv2.LINE_AA,\n",
        "        )\n",
        "\n",
        "    return output_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R0OwHQnsmYvC"
      },
      "outputs": [],
      "source": [
        "# sign action to be detected\n",
        "ACTIONS = np.array(\n",
        "    [\n",
        "        \"hello\",\n",
        "        \"thanks\",\n",
        "        \"i-love-you\",\n",
        "        \"see-you-later\",\n",
        "        \"I\",\n",
        "        \"Father\",\n",
        "        \"Mother\",\n",
        "        \"Yes\",\n",
        "        \"No\",\n",
        "        \"Help\",\n",
        "        \"Please\",\n",
        "        \"Want\",\n",
        "        \"What\",\n",
        "        \"Again\",\n",
        "        \"Eat\",\n",
        "        \"Milk\",\n",
        "        \"More\",\n",
        "        \"Go To\",\n",
        "        \"Bathroom\",\n",
        "        \"Fine\",\n",
        "        \"Like\",\n",
        "        \"Learn\",\n",
        "        \"Sign\",\n",
        "        \"Done\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "ACTIONS = ACTIONS[:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwqafXTbmYvC",
        "outputId": "2f41554a-9ad2-4640-d3ce-58b3c0634e05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['hello', 'thanks', 'i-love-you', 'see-you-later', 'I', 'Father'],\n",
              "      dtype='<U13')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ACTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oR5Lc6NlmYvC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential  # type: ignore\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LSTM, TimeDistributed, Reshape, Bidirectional  # type: ignore\n",
        "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau  # type: ignore\n",
        "from tensorflow.keras.regularizers import l2  # type: ignore\n",
        "from tensorflow.keras.optimizers import Adam # type: ignore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9aF4iijZmYvD"
      },
      "outputs": [],
      "source": [
        "# the input shape (30, 1692) where 30 is the sequence length and 1692 is the number of features per frame\n",
        "input_shape = (30, 1692)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U3HIEeTmYvD",
        "outputId": "62aa9bc5-dc66-4f94-df12-f4f0152ec75c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\ivena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\ivena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# data normalization\n",
        "model.add(BatchNormalization(input_shape=input_shape, name='batch_normalization'))\n",
        "\n",
        "# convolutional layers to extract spatial features\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', name='conv1d'))\n",
        "model.add(MaxPooling1D(pool_size=2, name='max_pooling1d'))\n",
        "model.add(Dropout(0.3, name='dropout1'))\n",
        "\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', name='conv1d_1'))\n",
        "model.add(MaxPooling1D(pool_size=2, name='max_pooling1d_1'))\n",
        "model.add(Dropout(0.3, name='dropout2'))\n",
        "\n",
        "model.add(Conv1D(filters=256, kernel_size=3, activation='relu', name='conv1d_2'))\n",
        "model.add(MaxPooling1D(pool_size=2, name='max_pooling1d_2'))\n",
        "model.add(Dropout(0.4, name='dropout3'))\n",
        "\n",
        "# dense layer before LSTM\n",
        "model.add(Dense(64, activation='relu', name='dense'))\n",
        "model.add(Dropout(0.5, name='dropout4'))\n",
        "\n",
        "# single Bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(512, return_sequences=False), name='bidirectional'))\n",
        "\n",
        "# fully connected layers for classification\n",
        "model.add(Dense(128, activation='relu', name='dense_1'))\n",
        "model.add(Dropout(0.5, name='dropout5'))\n",
        "\n",
        "model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "model.add(Dropout(0.3, name='dropout6'))\n",
        "\n",
        "# output layer with softmax activation for classification\n",
        "model.add(Dense(6, activation='softmax', name='dense_3'))\n",
        "\n",
        "# Load pre-trained weights\n",
        "model.load_weights(\"../models/legacy/asl-action-cnn-lstm_1l-6a-es_p30__rlr_f05_p10_lr1e5-2.9M.h5\")\n",
        "\n",
        "# Freeze all layers except the last few\n",
        "# for layer in model.layers[:-6]:\n",
        "#     layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (Batch  (None, 30, 1692)          6768      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 28, 64)            324928    \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 14, 64)            0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout1 (Dropout)          (None, 14, 64)            0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 12, 128)           24704     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 6, 128)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout2 (Dropout)          (None, 6, 128)            0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 4, 256)            98560     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 2, 256)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout3 (Dropout)          (None, 2, 256)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2, 64)             16448     \n",
            "                                                                 \n",
            " dropout4 (Dropout)          (None, 2, 64)             0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 1024)              2363392   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               131200    \n",
            "                                                                 \n",
            " dropout5 (Dropout)          (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout6 (Dropout)          (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2974646 (11.35 MB)\n",
            "Trainable params: 2971262 (11.33 MB)\n",
            "Non-trainable params: 3384 (13.22 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20.3)\n",
            "Requirement already satisfied: pydot in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.0)\n",
            "Requirement already satisfied: pyparsing>=3 in c:\\users\\ivena\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydot) (3.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install graphviz pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN-y1HDVmYvD",
        "outputId": "1fc7085c-39e3-4291-cb86-6a2299b9884f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "i-love-you\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "window = []\n",
        "\n",
        "for i in range(30):\n",
        "    npy_path = os.path.join(os.path.join(\"./datasets\"), \"i-love-you\", \"5\", f\"{i}.npy\")\n",
        "\n",
        "    # load the frame data from the numpy file\n",
        "    seq = np.load(npy_path)\n",
        "\n",
        "    window.append(seq)\n",
        "\n",
        "action = np.array(window)\n",
        "\n",
        "pred = model.predict(np.expand_dims(action, axis=0))[0]\n",
        "\n",
        "print(ACTIONS[np.argmax(pred)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yscolCOumYvD"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "sequence = []\n",
        "\n",
        "sentence = []\n",
        "predictions = []\n",
        "\n",
        "sequence_length = 30\n",
        "threshold = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTi6PQoZmYvD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ivena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 12ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# set capture properties\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 600)  # set width to 600 pixels\n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 600)  # set height to 600 pixels\n",
        "cap.set(cv2.CAP_PROP_FPS, 60)  # set frame rate to 60 FPS\n",
        "\n",
        "start_time = time.time()\n",
        "isQuit = False\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, image = cap.read()\n",
        "\n",
        "    if not success:\n",
        "        print(\"Ignoring empty camera frame.\")\n",
        "        continue\n",
        "\n",
        "    # NOTE: using flip image will screw'ed up some of the keypoints\n",
        "    #       data for training the model later\n",
        "    # image = cv2.flip(image, 1) # flip the image horizontally for a selfie-view display.\n",
        "\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # get current frame timestamp in milliseconds\n",
        "    timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
        "\n",
        "    # convert cv image to mediapipe image format before being\n",
        "    # passed to face, pose and hand detector\n",
        "    annotated_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)\n",
        "\n",
        "    face_results = face_detector.detect_for_video(\n",
        "        image=annotated_image, timestamp_ms=timestamp_ms\n",
        "    )\n",
        "\n",
        "    hand_results = hand_detector.detect_for_video(\n",
        "        image=annotated_image, timestamp_ms=timestamp_ms + 1\n",
        "    )\n",
        "\n",
        "    pose_results = pose_detector.detect_for_video(\n",
        "        image=annotated_image, timestamp_ms=timestamp_ms + 2\n",
        "    )\n",
        "\n",
        "    keypoints = extract_keypoints(face_results, pose_results, hand_results)\n",
        "    sequences.append(keypoints)\n",
        "    sequence = sequences[-30:]\n",
        "\n",
        "    face_proto, pose_proto, hand_proto = extract_keypoints_for_drawing(\n",
        "        face_results, pose_results, hand_results\n",
        "    )\n",
        "\n",
        "    draw_detection_landmark(\n",
        "        image_rgb,\n",
        "        face_landmarks_proto=face_proto,\n",
        "        pose_landmarks_proto=pose_proto,\n",
        "        hand_landmarks_proto=hand_proto,\n",
        "    )\n",
        "\n",
        "    if len(sequence) == sequence_length:\n",
        "        # predict the action label based on the sequence of keypoints\n",
        "        result = model.predict(\n",
        "            np.expand_dims(\n",
        "                sequence, axis=0\n",
        "            )  # expanded to include a batch dimension before fed to the model\n",
        "        )[0]\n",
        "\n",
        "        # action class with the highest confidence score\n",
        "        predictions.append(np.argmax(result))\n",
        "\n",
        "        # NOTE: If the current prediction matches the most common prediction over the last 20 frames,\n",
        "        #       it suggests that the current action is likely intentional and\n",
        "        #       consistent with recent actions, rather than a momentary anomaly.\n",
        "        if np.unique(predictions[-10:])[0] == np.argmax(result):\n",
        "\n",
        "            # check if the confidence score of the current prediction index is above the threshold.\n",
        "            if result[np.argmax(result)] > threshold:\n",
        "\n",
        "                # checks if there are any elements in the sentence list.\n",
        "                # If it's not empty, it means there are already recognized actions in the sentence.\n",
        "                if len(sentence) > 0:\n",
        "                    # compares the current predicted action\n",
        "                    if ACTIONS[np.argmax(result)] != sentence[-1]:\n",
        "                        sentence.append(ACTIONS[np.argmax(result)])\n",
        "                else:\n",
        "                    # no recognized actions yet\n",
        "                    sentence.append(ACTIONS[np.argmax(result)])\n",
        "\n",
        "        # limit the length of the recognized action sentence to 5 elements by\n",
        "        # keeping only the last two elements so it does not exceed the text box\n",
        "        if len(sentence) > 3:\n",
        "            sentence = sentence[-3:]\n",
        "\n",
        "        # overlay the predicted action on the image\n",
        "        image_rgb = confidence_bar(result, ACTIONS, image_rgb, colors)\n",
        "\n",
        "    cv2.rectangle(image_rgb, (0, 0), (640, 40), (245, 117, 16), -1)\n",
        "    cv2.putText(\n",
        "        image_rgb,\n",
        "        \" \".join(sentence),\n",
        "        (3, 30),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        1,\n",
        "        (255, 255, 255),\n",
        "        2,\n",
        "        cv2.LINE_AA,\n",
        "    )\n",
        "\n",
        "    cv2.imshow(\n",
        "        \"MediaPipe Detection\",\n",
        "        cv2.cvtColor(image_rgb, cv2.COLOR_BGR2RGB),\n",
        "    )\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI9ZFlSdmYvD",
        "outputId": "5b0f009d-8bee-432d-e87c-37c1cea66984"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0., 0., 0., ..., 0., 0., 0.]),\n",
              " array([ 0.6738947 ,  1.04895377, -0.01673681, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.67149955,  1.03560805, -0.01615892, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.66170722,  1.03462029, -0.01478392, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.66107965,  1.02624309, -0.01210512, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.66148943,  1.03649485, -0.01243832, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65855277,  1.03850925, -0.00988946, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65870565,  1.0386132 , -0.00974403, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65872282,  1.03686655, -0.00771972, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.66121763,  1.03527975, -0.006984  , ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.66111922,  1.03363144, -0.00708904, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65718883,  1.03680551, -0.00715512, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65746421,  1.03678   , -0.00716676, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65471137,  1.0371567 , -0.00616351, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65716016,  1.03628612, -0.00640096, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65976709,  1.03423011, -0.00654809, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65988296,  1.03184414, -0.00706499, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65957713,  1.02755308, -0.00710499, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.66722715,  1.02809441, -0.00739691, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.66260058,  1.03095269, -0.00435161, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.66095519,  1.0319128 , -0.00457172, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65854049,  1.03158724, -0.00461525, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.6576106 ,  1.03103316, -0.00525904, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65932196,  1.03263354, -0.0067862 , ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65937036,  1.03197181, -0.00660632, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65797609,  1.03761137, -0.00735471, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65391612,  1.0365299 , -0.00734984, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65416449,  1.03456581, -0.00616941, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.65913767,  1.03440619, -0.00702739, ...,  0.        ,\n",
              "         0.        ,  0.        ]),\n",
              " array([ 0.66058707,  1.02879596, -0.00652295, ...,  0.        ,\n",
              "         0.        ,  0.        ])]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences[:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[ 0.57280719,  0.52622569, -0.03732424, ...,  0.57391572,\n",
              "          0.58559418, -0.10670094],\n",
              "        [ 0.57030427,  0.52614331, -0.03747835, ...,  0.57410204,\n",
              "          0.58424765, -0.10982773],\n",
              "        [ 0.5687421 ,  0.52671403, -0.03601618, ...,  0.57232231,\n",
              "          0.58869779, -0.10868381],\n",
              "        ...,\n",
              "        [ 0.60675806,  0.57286114, -0.04001639, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.60902882,  0.57445043, -0.03971909, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.60947293,  0.57736653, -0.04024295, ...,  0.        ,\n",
              "          0.        ,  0.        ]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.expand_dims(sequence, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "enuGreNUmYvE",
        "outputId": "75af0ef2-ad69-42c0-a90c-3839b57f2a7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n",
            "i-love-you\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
        "\n",
        "print(ACTIONS[np.argmax(pred)])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
